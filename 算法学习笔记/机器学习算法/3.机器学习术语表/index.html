



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Curren's Notes">
      
      
      
        <meta name="author" content="Curren">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1, mkdocs-material-4.6.3">
    
    
      
        <title>3.机器学习术语表 - Curren's Notes</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.adb8469c.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#ff7043">
      
    
    
      <script src="../../../assets/javascripts/modernizr.86422ebf.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../../../css/katex.min.css">
    
      <link rel="stylesheet" href="../../../css/copy-tex.min.css">
    
      <link rel="stylesheet" href="../../../css/view.mindmap.css">
    
      <link rel="stylesheet" href="../../../css/atom-one-dark-reasonable.css">
    
      <link rel="stylesheet" href="../../../css/font-awesome-all.min.css">
    
      <link rel="stylesheet" href="../../../css/emoji.css">
    
      <link rel="stylesheet" href="../../../css/extra.css">
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="deep-orange" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#google" tabindex="0" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../.." title="Curren's Notes" aria-label="Curren's Notes" class="md-header-nav__button md-logo">
          
            <i class="md-icon">star</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Curren's Notes
            </span>
            <span class="md-header-nav__topic">
              
                3.机器学习术语表
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" aria-label="search" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/CurrenWong/Mkdoc/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    currenwong/Mkdoc
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="../../.." class="md-tabs__link">
        Welcome to Curren's Notes
      </a>
    
  </li>

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/Linux/1.%E7%AE%A1%E9%81%93%E4%B8%8E%E8%BF%9E%E6%8E%A5%E7%AC%A6%E5%8F%B7/" class="md-tabs__link">
          工具使用笔记
        </a>
      
    </li>
  

  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../../%E6%97%85%E8%A1%8C%E7%AC%94%E8%AE%B0/%E6%B1%9F%E8%A5%BF/1.2020_7_14_%E8%90%8D%E4%B9%A1%E6%AD%A6%E5%8A%9F%E5%B1%B1/" class="md-tabs__link">
          旅行笔记
        </a>
      
    </li>
  

  

      
        
  
  
    
    
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/INSERT/1.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_34_%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE/" class="md-tabs__link">
          算法学习笔记
        </a>
      
    </li>
  

  

  

      
        
  
  
    
    
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_August/" class="md-tabs__link">
          考研笔记
        </a>
      
    </li>
  

  

  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%95%86%E4%B8%9A/1.%E6%AF%8F%E5%91%A8%E5%95%86%E4%B8%9A%E8%AF%84%E8%AE%BA_%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/" class="md-tabs__link">
          读书笔记
        </a>
      
    </li>
  

  

      
        
  
  
    
    
  
  
    <li class="md-tabs__item">
      
        <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/Java%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/1.Java%E4%B8%AD%E7%9A%84%E6%B3%9B%E5%9E%8B/" class="md-tabs__link">
          课程笔记
        </a>
      
    </li>
  

  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../.." title="Curren's Notes" class="md-nav__button md-logo">
      
        <i class="md-icon">star</i>
      
    </a>
    Curren's Notes
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/CurrenWong/Mkdoc/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    currenwong/Mkdoc
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../.." title="Welcome to Curren's Notes" class="md-nav__link">
      Welcome to Curren's Notes
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      工具使用笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        工具使用笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-1" type="checkbox" id="nav-2-1">
    
    <label class="md-nav__link" for="nav-2-1">
      Linux
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-1">
        Linux
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/Linux/1.%E7%AE%A1%E9%81%93%E4%B8%8E%E8%BF%9E%E6%8E%A5%E7%AC%A6%E5%8F%B7/" title="1.管道与连接符号" class="md-nav__link">
      1.管道与连接符号
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-2" type="checkbox" id="nav-2-2">
    
    <label class="md-nav__link" for="nav-2-2">
      Spark
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-2">
        Spark
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/Spark/1.%E5%9D%87%E5%80%BC_%E6%9C%80%E5%80%BC_%E6%96%B9%E5%B7%AE/" title="1.均值 最值 方差" class="md-nav__link">
      1.均值 最值 方差
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-3" type="checkbox" id="nav-2-3">
    
    <label class="md-nav__link" for="nav-2-3">
      TensorFlow
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-3">
        TensorFlow
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-3-1" type="checkbox" id="nav-2-3-1">
    
    <label class="md-nav__link" for="nav-2-3-1">
      TroubleShoot
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-2-3-1">
        TroubleShoot
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/TensorFlow/TroubleShoot/1.Version_GLIBC_Not_Found/" title="1.Version GLIBC Not Found" class="md-nav__link">
      1.Version GLIBC Not Found
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-4" type="checkbox" id="nav-2-4">
    
    <label class="md-nav__link" for="nav-2-4">
      Tomcat
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-4">
        Tomcat
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-4-1" type="checkbox" id="nav-2-4-1">
    
    <label class="md-nav__link" for="nav-2-4-1">
      TroubleShoot
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-2-4-1">
        TroubleShoot
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/Tomcat/TroubleShoot/1.Illegal_Access/" title="1.Illegal Access" class="md-nav__link">
      1.Illegal Access
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-5" type="checkbox" id="nav-2-5">
    
    <label class="md-nav__link" for="nav-2-5">
      得到APP
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-5">
        得到APP
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/%E5%BE%97%E5%88%B0APP/1.%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E6%8E%A8%E8%8D%90%E7%A8%8B%E5%BA%8F%E5%91%98%E6%9C%8B%E5%8F%8B%E4%BD%BF%E7%94%A8%E5%BE%97%E5%88%B0APP/" title="1.我为什么推荐程序员朋友使用得到APP" class="md-nav__link">
      1.我为什么推荐程序员朋友使用得到APP
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2-6" type="checkbox" id="nav-2-6">
    
    <label class="md-nav__link" for="nav-2-6">
      网络爬虫
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-2-6">
        网络爬虫
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/1.Python%E7%88%AC%E5%8F%96CodeForces%E9%A2%98%E7%9B%AE/" title="1.Python爬取CodeForces题目" class="md-nav__link">
      1.Python爬取CodeForces题目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/2.Python%E7%88%AC%E5%8F%96%E7%89%9B%E5%AE%A2%E7%BD%91%E9%A2%98%E7%9B%AE/" title="2.Python爬取牛客网题目" class="md-nav__link">
      2.Python爬取牛客网题目
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      旅行笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        旅行笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3-1" type="checkbox" id="nav-3-1">
    
    <label class="md-nav__link" for="nav-3-1">
      江西
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-3-1">
        江西
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E6%97%85%E8%A1%8C%E7%AC%94%E8%AE%B0/%E6%B1%9F%E8%A5%BF/1.2020_7_14_%E8%90%8D%E4%B9%A1%E6%AD%A6%E5%8A%9F%E5%B1%B1/" title="1.2020 7 14 萍乡武功山" class="md-nav__link">
      1.2020 7 14 萍乡武功山
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      算法学习笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        算法学习笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-1" type="checkbox" id="nav-4-1">
    
    <label class="md-nav__link" for="nav-4-1">
      SQL刷题笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-1">
        SQL刷题笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-1-1" type="checkbox" id="nav-4-1-1">
    
    <label class="md-nav__link" for="nav-4-1-1">
      INSERT
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-1-1">
        INSERT
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/INSERT/1.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_34_%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE/" title="1.牛客网 SQL实战 34 批量插入数据" class="md-nav__link">
      1.牛客网 SQL实战 34 批量插入数据
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-1-2" type="checkbox" id="nav-4-1-2">
    
    <label class="md-nav__link" for="nav-4-1-2">
      JOIN
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-1-2">
        JOIN
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/JOIN/1.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_3_%E6%9F%A5%E6%89%BE%E5%BD%93%E5%89%8D%E8%96%AA%E6%B0%B4%E8%AF%A6%E6%83%85/" title="1.牛客网 SQL实战 3 查找当前薪水详情" class="md-nav__link">
      1.牛客网 SQL实战 3 查找当前薪水详情
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/JOIN/2.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_4_%E6%9F%A5%E6%89%BE%E6%89%80%E6%9C%89%E5%B7%B2%E7%BB%8F%E5%88%86%E9%85%8D%E9%83%A8%E9%97%A8%E7%9A%84%E5%91%98%E5%B7%A5/" title="2.牛客网 SQL实战 4 查找所有已经分配部门的员工" class="md-nav__link">
      2.牛客网 SQL实战 4 查找所有已经分配部门的员工
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/JOIN/3.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_5_%E6%9F%A5%E6%89%BE%E6%89%80%E6%9C%89%E5%91%98%E5%B7%A5%E7%9A%84last_name%E5%92%8Cfirst_name/" title="3.牛客网 SQL实战 5 查找所有员工的last name和first name" class="md-nav__link">
      3.牛客网 SQL实战 5 查找所有员工的last name和first name
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/JOIN/5.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_6_%E6%9F%A5%E6%89%BE%E6%89%80%E6%9C%89%E5%91%98%E5%B7%A5%E5%85%A5%E8%81%8C%E6%97%B6%E5%80%99%E7%9A%84%E8%96%AA%E6%B0%B4%E6%83%85%E5%86%B5/" title="5.牛客网 SQL实战 6 查找所有员工入职时候的薪水情况" class="md-nav__link">
      5.牛客网 SQL实战 6 查找所有员工入职时候的薪水情况
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-1-3" type="checkbox" id="nav-4-1-3">
    
    <label class="md-nav__link" for="nav-4-1-3">
      Subquery
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-1-3">
        Subquery
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/Subquery/1.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_1_%E6%9F%A5%E6%89%BE%E6%9C%80%E6%99%9A%E5%85%A5%E8%81%8C%E5%91%98%E5%B7%A5/" title="1.牛客网 SQL实战 1 查找最晚入职员工" class="md-nav__link">
      1.牛客网 SQL实战 1 查找最晚入职员工
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../SQL%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/Subquery/2.%E7%89%9B%E5%AE%A2%E7%BD%91_SQL%E5%AE%9E%E6%88%98_2_%E6%9F%A5%E6%89%BE%E5%85%A5%E8%81%8C%E5%91%98%E5%B7%A5%E6%97%B6%E9%97%B4%E6%8E%92%E5%90%8D%E5%80%92%E6%95%B0%E7%AC%AC%E4%B8%89%E7%9A%84%E5%91%98%E5%B7%A5/" title="2.牛客网 SQL实战 2 查找入职员工时间排名倒数第三的员工" class="md-nav__link">
      2.牛客网 SQL实战 2 查找入职员工时间排名倒数第三的员工
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-2" type="checkbox" id="nav-4-2">
    
    <label class="md-nav__link" for="nav-4-2">
      传统算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-2">
        传统算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/1.%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7/" title="1.算法设计中的常用技巧" class="md-nav__link">
      1.算法设计中的常用技巧
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/2.%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" title="2.归并排序" class="md-nav__link">
      2.归并排序
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/3.%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E9%80%9F%E6%9F%A5%E8%A1%A8/" title="3.算法复杂度速查表" class="md-nav__link">
      3.算法复杂度速查表
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3" type="checkbox" id="nav-4-3">
    
    <label class="md-nav__link" for="nav-4-3">
      刷题笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-3">
        刷题笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-1" type="checkbox" id="nav-4-3-1">
    
    <label class="md-nav__link" for="nav-4-3-1">
      AC自动机
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-1">
        AC自动机
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/AC%E8%87%AA%E5%8A%A8%E6%9C%BA/1.HDU_2222_Keywords_Search/" title="1.HDU 2222 Keywords Search" class="md-nav__link">
      1.HDU 2222 Keywords Search
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-2" type="checkbox" id="nav-4-3-2">
    
    <label class="md-nav__link" for="nav-4-3-2">
      DFS
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-2">
        DFS
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/DFS/1.%E7%89%9B%E5%AE%A2%E7%BD%91_NC14132_%E8%B4%9D%E4%BC%A6%E5%8D%A1%E6%96%AF%E6%B3%B0%E9%9C%B2/" title="1.牛客网 NC14132 贝伦卡斯泰露" class="md-nav__link">
      1.牛客网 NC14132 贝伦卡斯泰露
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-3" type="checkbox" id="nav-4-3-3">
    
    <label class="md-nav__link" for="nav-4-3-3">
      KMP算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-3">
        KMP算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/KMP%E7%AE%97%E6%B3%95/1.%E7%89%9B%E5%AE%A2%E7%BD%91_NC207429_%E6%9C%80%E5%A4%A7%E5%80%BC/" title="1.牛客网 NC207429 最大值" class="md-nav__link">
      1.牛客网 NC207429 最大值
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-4" type="checkbox" id="nav-4-3-4">
    
    <label class="md-nav__link" for="nav-4-3-4">
      STL基本用法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-4">
        STL基本用法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/STL%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/1.51Nod_2160_%E6%95%B0%E5%AD%97%E6%B8%B8%E6%88%8F/" title="1.51Nod 2160 数字游戏" class="md-nav__link">
      1.51Nod 2160 数字游戏
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/STL%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/2.51Nod_2142_%E7%AC%ACm%E5%A4%A7%E7%9A%84%E8%BA%AB%E4%BB%BD%E8%AF%81%E5%8F%B7%E7%A0%81/" title="2.51Nod 2142 第m大的身份证号码" class="md-nav__link">
      2.51Nod 2142 第m大的身份证号码
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/STL%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/3.%E8%AE%A1%E8%92%9C%E5%AE%A2_T1989_%E8%BF%9E%E7%BB%AD%E8%87%AA%E7%84%B6%E6%95%B0%E5%92%8C/" title="3.计蒜客 T1989 连续自然数和" class="md-nav__link">
      3.计蒜客 T1989 连续自然数和
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/STL%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/4.%E8%AE%A1%E8%92%9C%E5%AE%A2_T3057_%E5%8D%A1%E7%89%8C%E6%B8%B8%E6%88%8F_III/" title="4.计蒜客 T3057 卡牌游戏 III" class="md-nav__link">
      4.计蒜客 T3057 卡牌游戏 III
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/STL%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/5.%E8%AE%A1%E8%92%9C%E5%AE%A2_T3058_%E5%8D%A1%E7%89%8C%E6%B8%B8%E6%88%8F_IV/" title="5.计蒜客 T3058 卡牌游戏 IV" class="md-nav__link">
      5.计蒜客 T3058 卡牌游戏 IV
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/STL%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/6.%E8%AE%A1%E8%92%9C%E5%AE%A2_39857_%E8%9C%97%E7%89%9B%E6%97%85%E6%B8%B8/" title="6.计蒜客 39857 蜗牛旅游" class="md-nav__link">
      6.计蒜客 39857 蜗牛旅游
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/STL%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/7.%E7%89%9B%E5%AE%A2%E7%BD%91_NC207028_%E7%AC%ACk%E5%B0%8F%E6%95%B0/" title="7.牛客网 NC207028 第k小数" class="md-nav__link">
      7.牛客网 NC207028 第k小数
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-5" type="checkbox" id="nav-4-3-5">
    
    <label class="md-nav__link" for="nav-4-3-5">
      二分查找
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-5">
        二分查找
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/1.CodeForces_1345_B_Card_Constructions/" title="1.CodeForces 1345 B Card Constructions" class="md-nav__link">
      1.CodeForces 1345 B Card Constructions
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-6" type="checkbox" id="nav-4-3-6">
    
    <label class="md-nav__link" for="nav-4-3-6">
      几何
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-6">
        几何
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%87%A0%E4%BD%95/1.CodeForces_1345_A_Puzzle_Pieces/" title="1.CodeForces 1345 A Puzzle Pieces" class="md-nav__link">
      1.CodeForces 1345 A Puzzle Pieces
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-7" type="checkbox" id="nav-4-3-7">
    
    <label class="md-nav__link" for="nav-4-3-7">
      动态规划
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-7">
        动态规划
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/1.51Nod_1009_%E6%95%B0%E5%AD%971%E7%9A%84%E6%95%B0%E9%87%8F/" title="1.51Nod 1009 数字1的数量" class="md-nav__link">
      1.51Nod 1009 数字1的数量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/2.51Nod_2080_%E6%9C%80%E9%95%BF%E4%B8%8A%E5%8D%87%E5%AD%90%E5%BA%8F%E5%88%97/" title="2.51Nod 2080 最长上升子序列" class="md-nav__link">
      2.51Nod 2080 最长上升子序列
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/3.%E7%89%9B%E5%AE%A2%E7%BD%91_NC205036_%E7%AD%94%E9%A2%98%E5%8D%A1/" title="3.牛客网 NC205036 答题卡" class="md-nav__link">
      3.牛客网 NC205036 答题卡
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/4.CodeForces_1353_C_Board_Moves/" title="4.CodeForces 1353 C Board Moves" class="md-nav__link">
      4.CodeForces 1353 C Board Moves
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/5.CodeForces_1353_E_K-periodic_Garland/" title="5.CodeForces 1353 E K periodic Garland" class="md-nav__link">
      5.CodeForces 1353 E K periodic Garland
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-8" type="checkbox" id="nav-4-3-8">
    
    <label class="md-nav__link" for="nav-4-3-8">
      区间DP
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-8">
        区间DP
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%8C%BA%E9%97%B4DP/1.%E7%89%9B%E5%AE%A2%E7%BD%91_NC205087_%E7%89%9B%E5%A6%B9%E7%88%B1%E6%95%B0%E5%88%97/" title="1.牛客网 NC205087 牛妹爱数列" class="md-nav__link">
      1.牛客网 NC205087 牛妹爱数列
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-9" type="checkbox" id="nav-4-3-9">
    
    <label class="md-nav__link" for="nav-4-3-9">
      堆排序
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-9">
        堆排序
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%A0%86%E6%8E%92%E5%BA%8F/1.CodeForces_1353_D_Constructing_the_Array/" title="1.CodeForces 1353 D Constructing the Array" class="md-nav__link">
      1.CodeForces 1353 D Constructing the Array
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-10" type="checkbox" id="nav-4-3-10">
    
    <label class="md-nav__link" for="nav-4-3-10">
      字典树
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-10">
        字典树
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%AD%97%E5%85%B8%E6%A0%91/1.2020_%E6%B8%B8%E6%97%8F%E6%9D%AF_F/" title="1.2020 游族杯 F" class="md-nav__link">
      1.2020 游族杯 F
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-11" type="checkbox" id="nav-4-3-11">
    
    <label class="md-nav__link" for="nav-4-3-11">
      字符串
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-11">
        字符串
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%AD%97%E7%AC%A6%E4%B8%B2/1.%E8%AE%A1%E8%92%9C%E5%AE%A2_T1112_%E5%8A%A0%E5%AF%86%E7%9A%84%E7%97%85%E5%8E%86%E5%8D%95/" title="1.计蒜客 T1112 加密的病历单" class="md-nav__link">
      1.计蒜客 T1112 加密的病历单
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%AD%97%E7%AC%A6%E4%B8%B2/2.CodeForces_591_B_Rebranding/" title="2.CodeForces 591 B Rebranding" class="md-nav__link">
      2.CodeForces 591 B Rebranding
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%AD%97%E7%AC%A6%E4%B8%B2/3.%E7%89%9B%E5%AE%A2%E7%BD%91_NC205084_%E7%89%9B%E7%89%9B%E7%88%B1%E5%AD%97%E7%AC%A6%E4%B8%B2/" title="3.牛客网 NC205084 牛牛爱字符串" class="md-nav__link">
      3.牛客网 NC205084 牛牛爱字符串
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%AD%97%E7%AC%A6%E4%B8%B2/4.%E7%89%9B%E5%AE%A2%E7%BD%91_NC20859_%E5%85%94%E5%AD%90%E7%9A%84%E5%90%8D%E5%AD%97/" title="4.牛客网 NC20859 兔子的名字" class="md-nav__link">
      4.牛客网 NC20859 兔子的名字
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%AD%97%E7%AC%A6%E4%B8%B2/5.%E7%89%9B%E5%AE%A2%E7%BD%91_%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A82019_%E8%81%AA%E6%98%8E%E7%9A%84%E7%BC%96%E8%BE%91/" title="5.牛客网 字节跳动2019 聪明的编辑" class="md-nav__link">
      5.牛客网 字节跳动2019 聪明的编辑
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-12" type="checkbox" id="nav-4-3-12">
    
    <label class="md-nav__link" for="nav-4-3-12">
      并查集
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-12">
        并查集
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%B9%B6%E6%9F%A5%E9%9B%86/1.%E7%89%9B%E5%AE%A2%E7%BD%91_NC200435_%E6%89%BE%E6%9C%8B%E5%8F%8B/" title="1.牛客网 NC200435 找朋友" class="md-nav__link">
      1.牛客网 NC200435 找朋友
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-13" type="checkbox" id="nav-4-3-13">
    
    <label class="md-nav__link" for="nav-4-3-13">
      归并排序
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-13">
        归并排序
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/1.51Nod-2134_%E9%80%86%E5%BA%8F%E5%AF%B9%E4%B8%AA%E6%95%B01000/" title="1.51Nod 2134 逆序对个数1000" class="md-nav__link">
      1.51Nod 2134 逆序对个数1000
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-14" type="checkbox" id="nav-4-3-14">
    
    <label class="md-nav__link" for="nav-4-3-14">
      思维题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-14">
        思维题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%80%9D%E7%BB%B4%E9%A2%98/1.AtCoder_4804_Teleporter/" title="1.AtCoder 4804 Teleporter" class="md-nav__link">
      1.AtCoder 4804 Teleporter
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%80%9D%E7%BB%B4%E9%A2%98/2.CodeForces_D_Riana_and_Distribution_of_Pie/" title="2.CodeForces D Riana and Distribution of Pie" class="md-nav__link">
      2.CodeForces D Riana and Distribution of Pie
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%80%9D%E7%BB%B4%E9%A2%98/3.%E7%89%9B%E5%AE%A2%E7%BD%91_NC205086_%E7%89%9B%E7%89%9B%E7%88%B1%E5%8D%9A%E5%BC%88/" title="3.牛客网 NC205086 牛牛爱博弈" class="md-nav__link">
      3.牛客网 NC205086 牛牛爱博弈
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-15" type="checkbox" id="nav-4-3-15">
    
    <label class="md-nav__link" for="nav-4-3-15">
      数学
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-15">
        数学
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/1.51Nod_2059_%E4%B8%8A%E5%8F%B0%E9%98%B6_easy/" title="1.51Nod 2059 上台阶 easy" class="md-nav__link">
      1.51Nod 2059 上台阶 easy
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/2.51Nod_2175_ProjectEuler_5/" title="2.51Nod 2175 ProjectEuler 5" class="md-nav__link">
      2.51Nod 2175 ProjectEuler 5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/3.51Nod_2456_%E6%9C%80%E5%B0%8F%E7%BA%A6%E6%95%B0_V2/" title="3.51Nod 2456 最小约数 V2" class="md-nav__link">
      3.51Nod 2456 最小约数 V2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/4.HDU_4135_Co-prime/" title="4.HDU 4135 Co prime" class="md-nav__link">
      4.HDU 4135 Co prime
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/5.51Nod_2656_%E9%98%BF%E5%85%8B%E6%9B%BC%E5%87%BD%E6%95%B0/" title="5.51Nod 2656 阿克曼函数" class="md-nav__link">
      5.51Nod 2656 阿克曼函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/6.51Nod_2653_%E5%8C%BA%E9%97%B4xor/" title="6.51Nod 2653 区间xor" class="md-nav__link">
      6.51Nod 2653 区间xor
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/7.%E7%89%9B%E5%AE%A2%E7%BD%91_NC14503_%E6%99%A8%E8%B7%91/" title="7.牛客网 NC14503 晨跑" class="md-nav__link">
      7.牛客网 NC14503 晨跑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/8.CodeForces_1344_A_Hilbert%27s_Hotel/" title="8.CodeForces 1344 A Hilbert's Hotel" class="md-nav__link">
      8.CodeForces 1344 A Hilbert's Hotel
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/9.%E7%89%9B%E5%AE%A2%E7%BD%91_NC200607_A-%E8%A7%A3%E9%94%81%E4%B8%93%E5%AE%B6/" title="9.牛客网 NC200607 A 解锁专家" class="md-nav__link">
      9.牛客网 NC200607 A 解锁专家
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-16" type="checkbox" id="nav-4-3-16">
    
    <label class="md-nav__link" for="nav-4-3-16">
      暴力剪枝
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-16">
        暴力剪枝
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%9A%B4%E5%8A%9B%E5%89%AA%E6%9E%9D/1.CodeForces_1355_B_Young_Explorers/" title="1.CodeForces 1355 B Young Explorers" class="md-nav__link">
      1.CodeForces 1355 B Young Explorers
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%9A%B4%E5%8A%9B%E5%89%AA%E6%9E%9D/2.CodeForces_1355_A_Sequence_with_Digits/" title="2.CodeForces 1355 A Sequence with Digits" class="md-nav__link">
      2.CodeForces 1355 A Sequence with Digits
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%9A%B4%E5%8A%9B%E5%89%AA%E6%9E%9D/3.%E7%89%9B%E5%AE%A2%E7%BD%91_NC14520_%E6%9C%89%E8%B6%A3%E7%9A%84%E6%95%B0%E5%AD%A6/" title="3.牛客网 NC14520 有趣的数学" class="md-nav__link">
      3.牛客网 NC14520 有趣的数学
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-17" type="checkbox" id="nav-4-3-17">
    
    <label class="md-nav__link" for="nav-4-3-17">
      最长上升子序列
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-17">
        最长上升子序列
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%9C%80%E9%95%BF%E4%B8%8A%E5%8D%87%E5%AD%90%E5%BA%8F%E5%88%97/1.%E7%89%9B%E5%AE%A2%E7%BD%91_NC26156_%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E9%95%BF%E5%BA%A6/" title="1.牛客网 NC26156 最长递增长度" class="md-nav__link">
      1.牛客网 NC26156 最长递增长度
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-18" type="checkbox" id="nav-4-3-18">
    
    <label class="md-nav__link" for="nav-4-3-18">
      滑动窗口
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-18">
        滑动窗口
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/1.%E7%89%9B%E5%AE%A2%E7%BD%91_NC204859_%E7%BB%84%E9%98%9F/" title="1.牛客网 NC204859 组队" class="md-nav__link">
      1.牛客网 NC204859 组队
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-19" type="checkbox" id="nav-4-3-19">
    
    <label class="md-nav__link" for="nav-4-3-19">
      矩阵操作
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-19">
        矩阵操作
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%9F%A9%E9%98%B5%E6%93%8D%E4%BD%9C/1.2020%E8%81%94%E6%83%B3%E6%9D%AF_H_Hay_Mower/" title="1.2020联想杯 H Hay Mower" class="md-nav__link">
      1.2020联想杯 H Hay Mower
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-20" type="checkbox" id="nav-4-3-20">
    
    <label class="md-nav__link" for="nav-4-3-20">
      笔试题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-20">
        笔试题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AC%94%E8%AF%95%E9%A2%98/1.2021%E5%B1%8ABiliBili_%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/" title="1.2021届BiliBili 数据分析 后端开发" class="md-nav__link">
      1.2021届BiliBili 数据分析 后端开发
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-21" type="checkbox" id="nav-4-3-21">
    
    <label class="md-nav__link" for="nav-4-3-21">
      简单题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-21">
        简单题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/1.51Nod_2409_%E5%90%AF%E8%92%99%E7%BB%83%E4%B9%A0-%E5%80%8D%E6%95%B0%E7%9A%84%E4%B8%AA%E6%95%B0/" title="1.51Nod 2409 启蒙练习 倍数的个数" class="md-nav__link">
      1.51Nod 2409 启蒙练习 倍数的个数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/2.51Nod_2414_%E5%90%AF%E8%92%99%E7%BB%83%E4%B9%A0-%E5%9B%BE%E5%BD%A2%E8%BE%93%E5%87%BA2/" title="2.51Nod 2414 启蒙练习 图形输出2" class="md-nav__link">
      2.51Nod 2414 启蒙练习 图形输出2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/3.51Node_2070_%E6%9C%80%E5%B0%8F%E7%BD%9A%E6%AC%BE/" title="3.51Node 2070 最小罚款" class="md-nav__link">
      3.51Node 2070 最小罚款
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/4.51Nod_3063_%E5%B0%8F%E6%98%8E%E7%88%B1%E6%AD%A3%E6%96%B9%E5%BD%A2/" title="4.51Nod 3063 小明爱正方形" class="md-nav__link">
      4.51Nod 3063 小明爱正方形
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/5.HDU4858_%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" title="5.HDU4858 项目管理" class="md-nav__link">
      5.HDU4858 项目管理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/6.%E7%89%9B%E5%AE%A2%E7%BD%91_NC13812_Another_Server/" title="6.牛客网 NC13812 Another Server" class="md-nav__link">
      6.牛客网 NC13812 Another Server
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/7.%E7%89%9B%E5%AE%A2%E7%BD%91_NC200611_F-%E5%8F%82%E8%B5%9B/" title="7.牛客网 NC200611 F 参赛" class="md-nav__link">
      7.牛客网 NC200611 F 参赛
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/8.CodeForces_1353_A_Most_Unstable_Array/" title="8.CodeForces 1353 A Most Unstable Array" class="md-nav__link">
      8.CodeForces 1353 A Most Unstable Array
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%95%E9%A2%98/9.CodeForces_591_A_Wizards_Duel/" title="9.CodeForces 591 A Wizards Duel" class="md-nav__link">
      9.CodeForces 591 A Wizards Duel
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-22" type="checkbox" id="nav-4-3-22">
    
    <label class="md-nav__link" for="nav-4-3-22">
      贪心
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-22">
        贪心
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E8%B4%AA%E5%BF%83/1.CodeForces_1353_B_Two_Arrays_And_Swaps/" title="1.CodeForces 1353 B Two Arrays And Swaps" class="md-nav__link">
      1.CodeForces 1353 B Two Arrays And Swaps
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E8%B4%AA%E5%BF%83/2.%E7%89%9B%E5%AE%A2%E7%BD%91_NC207078_%E4%BA%A4%E6%8D%A2/" title="2.牛客网 NC207078 交换" class="md-nav__link">
      2.牛客网 NC207078 交换
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-3-23" type="checkbox" id="nav-4-3-23">
    
    <label class="md-nav__link" for="nav-4-3-23">
      高精度
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-3-23">
        高精度
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%B2%BE%E5%BA%A6/1.%E7%89%9B%E5%AE%A2%E7%BD%91_NC207427_%E7%9B%B4%E7%BA%BF/" title="1.牛客网 NC207427 直线" class="md-nav__link">
      1.牛客网 NC207427 直线
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-4" type="checkbox" id="nav-4-4" checked>
    
    <label class="md-nav__link" for="nav-4-4">
      机器学习算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-4">
        机器学习算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../1.XGBoost%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B/" title="1.XGBoost原理简介" class="md-nav__link">
      1.XGBoost原理简介
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../2.XGBoost%E7%9A%84%E7%BA%AFPython%E5%AE%9E%E7%8E%B0/" title="2.XGBoost的纯Python实现" class="md-nav__link">
      2.XGBoost的纯Python实现
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        3.机器学习术语表
      </label>
    
    <a href="./" title="3.机器学习术语表" class="md-nav__link md-nav__link--active">
      3.机器学习术语表
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1. 背景
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    目录
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-a" class="md-nav__link">
    2. A
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-ab-ab-testing" class="md-nav__link">
    2.1. A/B 测试 (A/B testing)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-accuracy" class="md-nav__link">
    2.2. 准确率 (accuracy)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-activation-function" class="md-nav__link">
    2.3. 激活函数 (activation function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-adagrad" class="md-nav__link">
    2.4. AdaGrad
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25-roc-auc-area-under-the-roc-curve" class="md-nav__link">
    2.5. ROC 曲线下面积 (AUC, Area under the ROC Curve)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-b" class="md-nav__link">
    3. B
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-backpropagation" class="md-nav__link">
    3.1. 反向传播算法 (backpropagation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-baseline" class="md-nav__link">
    3.2. 基准 (baseline)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-batch" class="md-nav__link">
    3.3. 批次 (batch)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-batch-size" class="md-nav__link">
    3.4. 批次大小 (batch size)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-bias" class="md-nav__link">
    3.5. 偏差 (bias)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-binary-classification" class="md-nav__link">
    3.6. 二元分类 (binary classification)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#37-binning" class="md-nav__link">
    3.7. 分箱 (binning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#38-bucketing" class="md-nav__link">
    3.8. 分桶 (bucketing)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-c" class="md-nav__link">
    4. C
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-calibration-layer" class="md-nav__link">
    4.1. 校准层 (calibration layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-candidate-sampling" class="md-nav__link">
    4.2. 候选采样 (candidate sampling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-categorical-data" class="md-nav__link">
    4.3. 分类数据 (categorical data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-centroid" class="md-nav__link">
    4.4. 形心 (centroid)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-checkpoint" class="md-nav__link">
    4.5. 检查点 (checkpoint)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46-class" class="md-nav__link">
    4.6. 类别 (class)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#47-class-imbalanced-data-set" class="md-nav__link">
    4.7. 分类不平衡的数据集 (class-imbalanced data set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#48-classification-model" class="md-nav__link">
    4.8. 分类模型 (classification model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#49-classification-threshold" class="md-nav__link">
    4.9. 分类阈值 (classification threshold)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#410-clustering" class="md-nav__link">
    4.10. 聚类 (clustering)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#411-collaborative-filtering" class="md-nav__link">
    4.11. 协同过滤 (collaborative filtering)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#412-confusion-matrix" class="md-nav__link">
    4.12. 混淆矩阵 (confusion matrix)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#413-continuous-feature" class="md-nav__link">
    4.13. 连续特征 (continuous feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#414-convergence" class="md-nav__link">
    4.14. 收敛 (convergence)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#415-convex-function" class="md-nav__link">
    4.15. 凸函数 (convex function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#416-convex-optimization" class="md-nav__link">
    4.16. 凸优化 (convex optimization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#417-convex-set" class="md-nav__link">
    4.17. 凸集 (convex set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#418-convolution" class="md-nav__link">
    4.18. 卷积 (convolution)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#419-convolutional-filter" class="md-nav__link">
    4.19. 卷积过滤器 (convolutional filter)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#420-convolutional-layer" class="md-nav__link">
    4.20. 卷积层 (convolutional layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#421-convolutional-neural-network" class="md-nav__link">
    4.21. 卷积神经网络 (convolutional neural network)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#422-convolutional-operation" class="md-nav__link">
    4.22. 卷积运算 (convolutional operation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#423-cost" class="md-nav__link">
    4.23. 成本 (cost)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#424-cross-entropy" class="md-nav__link">
    4.24. 交叉熵 (cross-entropy)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#425-estimator-custom-estimator" class="md-nav__link">
    4.25. 自定义 Estimator (custom Estimator)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-d" class="md-nav__link">
    5. D
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-data-analysis" class="md-nav__link">
    5.1. 数据分析 (data analysis)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-dataframe" class="md-nav__link">
    5.2. DataFrame
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-data-set" class="md-nav__link">
    5.3. 数据集 (data set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54-dataset-api-tfdata" class="md-nav__link">
    5.4. Dataset API (tf.data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55-decision-boundary" class="md-nav__link">
    5.5. 决策边界 (decision boundary)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56-dense-layer" class="md-nav__link">
    5.6. 密集层 (dense layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#57-deep-model" class="md-nav__link">
    5.7. 深度模型 (deep model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#58-dense-feature" class="md-nav__link">
    5.8. 密集特征 (dense feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#59-device" class="md-nav__link">
    5.9. 设备 (device)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#510-discrete-feature" class="md-nav__link">
    5.10. 离散特征 (discrete feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#511-dropout-regularization" class="md-nav__link">
    5.11. 丢弃正则化 (dropout regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#512-dynamic-model" class="md-nav__link">
    5.12. 动态模型 (dynamic model)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-e" class="md-nav__link">
    6. E
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-early-stopping" class="md-nav__link">
    6.1. 早停法 (early stopping)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-embeddings" class="md-nav__link">
    6.2. 嵌套 (embeddings)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-erm-empirical-risk-minimization" class="md-nav__link">
    6.3. 经验风险最小化 (ERM, empirical risk minimization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-ensemble" class="md-nav__link">
    6.4. 集成学习 (ensemble)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-epoch" class="md-nav__link">
    6.5. 周期 (epoch)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66-estimator" class="md-nav__link">
    6.6. Estimator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#67-example" class="md-nav__link">
    6.7. 样本 (example)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-f" class="md-nav__link">
    7. F
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-fn-false-negative" class="md-nav__link">
    7.1. 假负例 (FN, false negative)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-fp-false-positive" class="md-nav__link">
    7.2. 假正例 (FP, false positive)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-false-positive-rate-fp" class="md-nav__link">
    7.3. 假正例率（false positive rate, 简称 FP 率）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-feature" class="md-nav__link">
    7.4. 特征 (feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75-tffeature_column" class="md-nav__link">
    7.5. 特征列 (tf.feature_column)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76-feature-cross" class="md-nav__link">
    7.6. 特征组合 (feature cross)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#77-feature-engineering" class="md-nav__link">
    7.7. 特征工程 (feature engineering)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#78-feature-set" class="md-nav__link">
    7.8. 特征集 (feature set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#79-feature-spec" class="md-nav__link">
    7.9. 特征规范 (feature spec)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#710-few-shot-learning" class="md-nav__link">
    7.10. 少量样本学习 (few-shot learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#711-softmax-full-softmax" class="md-nav__link">
    7.11. 完整 softmax (full softmax)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#712-fully-connected-layer" class="md-nav__link">
    7.12. 全连接层 (fully connected layer)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-g" class="md-nav__link">
    8. G
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-generalization" class="md-nav__link">
    8.1. 泛化 (generalization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-generalized-linear-model" class="md-nav__link">
    8.2. 广义线性模型 (generalized linear model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-gradient" class="md-nav__link">
    8.3. 梯度 (gradient)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-gradient-clipping" class="md-nav__link">
    8.4. 梯度裁剪 (gradient clipping)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-gradient-descent" class="md-nav__link">
    8.5. 梯度下降法 (gradient descent)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86-graph" class="md-nav__link">
    8.6. 图 (graph)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-h" class="md-nav__link">
    9. H
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-heuristic" class="md-nav__link">
    9.1. 启发法 (heuristic)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-hidden-layer" class="md-nav__link">
    9.2. 隐藏层 (hidden layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-hinge-loss" class="md-nav__link">
    9.3. 合页损失函数 (hinge loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-holdout-data" class="md-nav__link">
    9.4. 维持数据 (holdout data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#95-hyperparameter" class="md-nav__link">
    9.5. 超参数 (hyperparameter)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#96-hyperplane" class="md-nav__link">
    9.6. 超平面 (hyperplane)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-i" class="md-nav__link">
    10. I
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-iid-independently-and-identically-distributed" class="md-nav__link">
    10.1. 独立同等分布 (i.i.d, independently and identically distributed)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-inference" class="md-nav__link">
    10.2. 推断 (inference)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-input-function" class="md-nav__link">
    10.3. 输入函数 (input function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-input-layer" class="md-nav__link">
    10.4. 输入层 (input layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-instance" class="md-nav__link">
    10.5. 实例 (instance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-interpretability" class="md-nav__link">
    10.6. 可解释性 (interpretability)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#107-inter-rater-agreement" class="md-nav__link">
    10.7. 评分者间一致性信度 (inter-rater agreement)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#108-iteration" class="md-nav__link">
    10.8. 迭代 (iteration)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-k" class="md-nav__link">
    11. K
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-k-means" class="md-nav__link">
    11.1. k-means
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-k-median" class="md-nav__link">
    11.2. k-median
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-keras" class="md-nav__link">
    11.3. Keras
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-ksvm-kernel-support-vector-machines" class="md-nav__link">
    11.4. 核支持向量机 (KSVM, Kernel Support Vector Machines)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-l" class="md-nav__link">
    12. L
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121-l_1-l_1-loss" class="md-nav__link">
    12.1. L_1 损失函数 (L_1 loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122-l_1-l_1-regularization" class="md-nav__link">
    12.2. L_1 正则化 (L_1 regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#123-l_2-l_2-loss" class="md-nav__link">
    12.3. L_2 损失函数 (L_2 loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#124-l_2-l_2-regularization" class="md-nav__link">
    12.4. L_2 正则化 (L_2 regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#125-label" class="md-nav__link">
    12.5. 标签 (label)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#126-labeled-example" class="md-nav__link">
    12.6. 有标签样本 (labeled example)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#127-lambda" class="md-nav__link">
    12.7. lambda
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#128-layer" class="md-nav__link">
    12.8. 层 (layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#129-layers-api-tflayers" class="md-nav__link">
    12.9. Layers API (tf.layers)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1210-learning-rate" class="md-nav__link">
    12.10. 学习速率 (learning rate)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1211-least-squares-regression" class="md-nav__link">
    12.11. 最小二乘回归 (least squares regression)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1212-linear-regression" class="md-nav__link">
    12.12. 线性回归 (linear regression)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1213-logistic-regression" class="md-nav__link">
    12.13. 逻辑回归 (logistic regression)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1214-logits" class="md-nav__link">
    12.14. 对数 (logits)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1215-log-loss" class="md-nav__link">
    12.15. 对数损失函数 (Log Loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1216-log-odds" class="md-nav__link">
    12.16. 对数几率 (log-odds)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1217-loss" class="md-nav__link">
    12.17. 损失 (Loss)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-m" class="md-nav__link">
    13. M
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131-machine-learning" class="md-nav__link">
    13.1. 机器学习 (machine learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132-mse-mean-squared-error" class="md-nav__link">
    13.2. 均方误差 (MSE, Mean Squared Error)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133-metric" class="md-nav__link">
    13.3. 指标 (metric)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134-metrics-api-tfmetrics" class="md-nav__link">
    13.4. Metrics API (tf.metrics)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#135-mini-batch" class="md-nav__link">
    13.5. 小批次 (mini-batch)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#136-sgd-mini-batch-stochastic-gradient-descent" class="md-nav__link">
    13.6. 小批次随机梯度下降法 (SGD, mini-batch stochastic gradient descent)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#137-ml" class="md-nav__link">
    13.7. ML
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#138-model" class="md-nav__link">
    13.8. 模型 (model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#139-model-function" class="md-nav__link">
    13.9. 模型函数 (model function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1310-model-training" class="md-nav__link">
    13.10. 模型训练 (model training)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1311-momentum" class="md-nav__link">
    13.11. 动量 (Momentum)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1312-multi-class-classification" class="md-nav__link">
    13.12. 多类别分类 (multi-class classification)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1313-multinomial-classification" class="md-nav__link">
    13.13. 多项分类 (multinomial classification)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-n" class="md-nav__link">
    14. N
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141-nan-nan-trap" class="md-nav__link">
    14.1. NaN 陷阱 (NaN trap)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142-negative-class" class="md-nav__link">
    14.2. 负类别 (negative class)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143-neural-network" class="md-nav__link">
    14.3. 神经网络 (neural network)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144-neuron" class="md-nav__link">
    14.4. 神经元 (neuron)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145-node" class="md-nav__link">
    14.5. 节点 (node)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146-normalization" class="md-nav__link">
    14.6. 标准化 (normalization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#147-numerical-data" class="md-nav__link">
    14.7. 数值数据 (numerical data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#148-numpy" class="md-nav__link">
    14.8. Numpy
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-o" class="md-nav__link">
    15. O
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#151-objective" class="md-nav__link">
    15.1. 目标 (objective)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#152-offline-inference" class="md-nav__link">
    15.2. 离线推断 (offline inference)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#153-one-hot-encoding" class="md-nav__link">
    15.3. 独热编码 (one-hot encoding)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#154-one-shot-learning" class="md-nav__link">
    15.4. 单样本学习（one-shot learning，通常用于对象分类）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#155-one-vs-all" class="md-nav__link">
    15.5. 一对多 (one-vs.-all)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#156-online-inference" class="md-nav__link">
    15.6. 在线推断 (online inference)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#157-op-operation" class="md-nav__link">
    15.7. 操作 (op, Operation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#158-optimizer" class="md-nav__link">
    15.8. 优化器 (optimizer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#159-outlier" class="md-nav__link">
    15.9. 离群值 (outlier)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1510-output-layer" class="md-nav__link">
    15.10. 输出层 (output layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1511-overfitting" class="md-nav__link">
    15.11. 过拟合 (overfitting)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-p" class="md-nav__link">
    16. P
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#161-pandas" class="md-nav__link">
    16.1. Pandas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#162-parameter" class="md-nav__link">
    16.2. 参数 (parameter)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#163-ps-parameter-server" class="md-nav__link">
    16.3. 参数服务器 (PS, Parameter Server)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#164-parameter-update" class="md-nav__link">
    16.4. 参数更新 (parameter update)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#165-partial-derivative" class="md-nav__link">
    16.5. 偏导数 (partial derivative)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#166-partitioning-strategy" class="md-nav__link">
    16.6. 划分策略 (partitioning strategy)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#167-performance" class="md-nav__link">
    16.7. 性能 (performance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#168-perplexity" class="md-nav__link">
    16.8. 困惑度 (perplexity)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#169-pipeline" class="md-nav__link">
    16.9. 流水线 (pipeline)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1610-pooling" class="md-nav__link">
    16.10. 池化 (pooling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1611-positive-class" class="md-nav__link">
    16.11. 正类别 (positive class)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1612-precision" class="md-nav__link">
    16.12. 精确率 (precision)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1613-prediction" class="md-nav__link">
    16.13. 预测 (prediction)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1614-prediction-bias" class="md-nav__link">
    16.14. 预测偏差 (prediction bias)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1615-estimator-pre-made-estimator" class="md-nav__link">
    16.15. 预创建的 Estimator (pre-made Estimator)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1616-pre-trained-model" class="md-nav__link">
    16.16. 预训练模型 (pre-trained model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1617-prior-belief" class="md-nav__link">
    16.17. 先验信念 (prior belief)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-q" class="md-nav__link">
    17. Q
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#171-queue" class="md-nav__link">
    17.1. 队列 (queue)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-r" class="md-nav__link">
    18. R
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#181-rank" class="md-nav__link">
    18.1. 等级 (rank)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#182-rater" class="md-nav__link">
    18.2. 评分者 (rater)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#183-recall" class="md-nav__link">
    18.3. 召回率 (recall)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#184-relu-rectified-linear-unit" class="md-nav__link">
    18.4. 修正线性单元 (ReLU, Rectified Linear Unit)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#185-regression-model" class="md-nav__link">
    18.5. 回归模型 (regression model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#186-regularization" class="md-nav__link">
    18.6. 正则化 (regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#187-regularization-rate" class="md-nav__link">
    18.7. 正则化率 (regularization rate)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#188-representation" class="md-nav__link">
    18.8. 表示法 (representation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#189-receiver-operating-characteristic-roc" class="md-nav__link">
    18.9. 受试者工作特征曲线（receiver operating characteristic，简称 ROC 曲线）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1810-root-directory" class="md-nav__link">
    18.10. 根目录 (root directory)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1811-rmse-root-mean-squared-error" class="md-nav__link">
    18.11. 均方根误差 (RMSE, Root Mean Squared Error)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1812-rotational-invariance" class="md-nav__link">
    18.12. 旋转不变性 (rotational invariance)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-s" class="md-nav__link">
    19. S
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#191-savedmodel" class="md-nav__link">
    19.1. SavedModel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#192-saver" class="md-nav__link">
    19.2. Saver
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#193-scaling" class="md-nav__link">
    19.3. 缩放 (scaling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#194-scikit-learn" class="md-nav__link">
    19.4. scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#195-semi-supervised-learning" class="md-nav__link">
    19.5. 半监督式学习 (semi-supervised learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#196-sequence-model" class="md-nav__link">
    19.6. 序列模型 (sequence model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#197-tfsession" class="md-nav__link">
    19.7. 会话 (tf.session)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#198-s-sigmoid-function" class="md-nav__link">
    19.8. S 型函数 (sigmoid function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#199-size-invariance" class="md-nav__link">
    19.9. 大小不变性 (size invariance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1910-softmax" class="md-nav__link">
    19.10. softmax
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1911-sparse-feature" class="md-nav__link">
    19.11. 稀疏特征 (sparse feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1912-sparse-representation" class="md-nav__link">
    19.12. 稀疏表示法 (sparse representation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1913-sparsity" class="md-nav__link">
    19.13. 稀疏性 (sparsity)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1914-spatial-pooling" class="md-nav__link">
    19.14. 空间池化 (spatial pooling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1915-squared-hinge-loss" class="md-nav__link">
    19.15. 平方合页损失函数 (squared hinge loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1916-squared-loss" class="md-nav__link">
    19.16. 平方损失函数 (squared loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1917-static-model" class="md-nav__link">
    19.17. 静态模型 (static model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1918-stationarity" class="md-nav__link">
    19.18. 平稳性 (stationarity)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1919-step" class="md-nav__link">
    19.19. 步 (step)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1920-step-size" class="md-nav__link">
    19.20. 步长 (step size)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1921-sgd-stochastic-gradient-descent" class="md-nav__link">
    19.21. 随机梯度下降法 (SGD, stochastic gradient descent)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1922-srm-structural-risk-minimization" class="md-nav__link">
    19.22. 结构风险最小化 (SRM, structural risk minimization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1923-stride" class="md-nav__link">
    19.23. 步长 (stride)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1924-subsampling" class="md-nav__link">
    19.24. 下采样 (subsampling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1925-summary" class="md-nav__link">
    19.25. 总结 (summary)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1926-supervised-machine-learning" class="md-nav__link">
    19.26. 监督式机器学习 (supervised machine learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1927-synthetic-feature" class="md-nav__link">
    19.27. 合成特征 (synthetic feature)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-t" class="md-nav__link">
    20. T
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#201-target" class="md-nav__link">
    20.1. 目标 (target)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#202-temporal-data" class="md-nav__link">
    20.2. 时态数据 (temporal data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#203-tensor" class="md-nav__link">
    20.3. 张量 (Tensor)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#204-tpu-tensor-processing-unit" class="md-nav__link">
    20.4. 张量处理单元 (TPU, Tensor Processing Unit)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#205-tensor-rank" class="md-nav__link">
    20.5. 张量等级 (Tensor rank)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#206-tensor-shape" class="md-nav__link">
    20.6. 张量形状 (Tensor shape)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#207-tensor-size" class="md-nav__link">
    20.7. 张量大小 (Tensor size)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#208-tensorboard" class="md-nav__link">
    20.8. TensorBoard
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#209-tensorflow" class="md-nav__link">
    20.9. TensorFlow
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2010-tensorflow-playground" class="md-nav__link">
    20.10. TensorFlow Playground
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2011-tensorflow-serving" class="md-nav__link">
    20.11. TensorFlow Serving
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2012-test-set" class="md-nav__link">
    20.12. 测试集 (test set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2013-tfexample" class="md-nav__link">
    20.13. tf.Example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2014-time-series-analysis" class="md-nav__link">
    20.14. 时间序列分析 (time series analysis)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2015-training" class="md-nav__link">
    20.15. 训练 (training)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2016-training-set" class="md-nav__link">
    20.16. 训练集 (training set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2017-transfer-learning" class="md-nav__link">
    20.17. 迁移学习 (transfer learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2018-translational-invariance" class="md-nav__link">
    20.18. 平移不变性 (translational invariance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2019-tn-true-negative" class="md-nav__link">
    20.19. 负例 (TN, true negative)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2020-tp-true-positive" class="md-nav__link">
    20.20. 正例 (TP, true positive)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2021-true-positive-rate-tp" class="md-nav__link">
    20.21. 正例率（true positive rate, 简称 TP 率）
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-u" class="md-nav__link">
    21. U
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#211-unlabeled-example" class="md-nav__link">
    21.1. 无标签样本 (unlabeled example)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#212-unsupervised-machine-learning" class="md-nav__link">
    21.2. 非监督式机器学习 (unsupervised machine learning)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#22-v" class="md-nav__link">
    22. V
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#221-validation-set" class="md-nav__link">
    22.1. 验证集 (validation set)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-w" class="md-nav__link">
    23. W
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#231-weight" class="md-nav__link">
    23.1. 权重 (weight)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#232-wide-model" class="md-nav__link">
    23.2. 宽度模型 (wide model)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5" type="checkbox" id="nav-4-5">
    
    <label class="md-nav__link" for="nav-4-5">
      算法模板
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-4-5">
        算法模板
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-1" type="checkbox" id="nav-4-5-1">
    
    <label class="md-nav__link" for="nav-4-5-1">
      其他
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-1">
        其他
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E5%85%B6%E4%BB%96/1.%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/" title="1.输入输出" class="md-nav__link">
      1.输入输出
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-2" type="checkbox" id="nav-4-5-2">
    
    <label class="md-nav__link" for="nav-4-5-2">
      动态规划
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-2">
        动态规划
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/1.%E6%9C%80%E9%95%BF%E4%B8%8A%E5%8D%87%E5%AD%90%E5%BA%8F%E5%88%97/" title="1.最长上升子序列" class="md-nav__link">
      1.最长上升子序列
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-3" type="checkbox" id="nav-4-5-3">
    
    <label class="md-nav__link" for="nav-4-5-3">
      图论
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-3">
        图论
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E5%9B%BE%E8%AE%BA/1.%E6%9C%80%E7%9F%AD%E8%B7%AF/" title="1.最短路" class="md-nav__link">
      1.最短路
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-4" type="checkbox" id="nav-4-5-4">
    
    <label class="md-nav__link" for="nav-4-5-4">
      字符串
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-4">
        字符串
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E5%AD%97%E7%AC%A6%E4%B8%B2/1.%E5%AD%97%E5%85%B8%E6%A0%91/" title="1.字典树" class="md-nav__link">
      1.字典树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E5%AD%97%E7%AC%A6%E4%B8%B2/2.KMP/" title="2.KMP" class="md-nav__link">
      2.KMP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E5%AD%97%E7%AC%A6%E4%B8%B2/3.AC%E8%87%AA%E5%8A%A8%E6%9C%BA/" title="3.AC自动机" class="md-nav__link">
      3.AC自动机
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-5" type="checkbox" id="nav-4-5-5">
    
    <label class="md-nav__link" for="nav-4-5-5">
      排序
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-5">
        排序
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E6%8E%92%E5%BA%8F/1.%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" title="1.归并排序" class="md-nav__link">
      1.归并排序
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-6" type="checkbox" id="nav-4-5-6">
    
    <label class="md-nav__link" for="nav-4-5-6">
      数学
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-6">
        数学
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E6%95%B0%E5%AD%A6/1.%E6%9C%80%E5%A4%A7%E5%85%AC%E7%BA%A6%E6%95%B0/" title="1.最大公约数" class="md-nav__link">
      1.最大公约数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E6%95%B0%E5%AD%A6/2.%E9%AB%98%E7%B2%BE%E5%BA%A6/" title="2.高精度" class="md-nav__link">
      2.高精度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E6%95%B0%E5%AD%A6/3.%E5%9F%83%E6%B0%8F%E7%AD%9B/" title="3.埃氏筛" class="md-nav__link">
      3.埃氏筛
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-7" type="checkbox" id="nav-4-5-7">
    
    <label class="md-nav__link" for="nav-4-5-7">
      查找
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-7">
        查找
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E6%9F%A5%E6%89%BE/1.%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/" title="1.二分查找" class="md-nav__link">
      1.二分查找
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4-5-8" type="checkbox" id="nav-4-5-8">
    
    <label class="md-nav__link" for="nav-4-5-8">
      高级数据结构
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-4-5-8">
        高级数据结构
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1.%E5%B9%B6%E6%9F%A5%E9%9B%86/" title="1.并查集" class="md-nav__link">
      1.并查集
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      考研笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        考研笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1">
    
    <label class="md-nav__link" for="nav-5-1">
      操作系统习题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        操作系统习题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-1" type="checkbox" id="nav-5-1-1">
    
    <label class="md-nav__link" for="nav-5-1-1">
      每日一题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-1">
        每日一题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_August/" title="2020 August" class="md-nav__link">
      2020 August
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_July/" title="2020 July" class="md-nav__link">
      2020 July
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-2" type="checkbox" id="nav-5-2">
    
    <label class="md-nav__link" for="nav-5-2">
      数据结构习题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-2">
        数据结构习题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-2-1" type="checkbox" id="nav-5-2-1">
    
    <label class="md-nav__link" for="nav-5-2-1">
      每日一题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-2-1">
        每日一题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_August/" title="2020 August" class="md-nav__link">
      2020 August
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_July/" title="2020 July" class="md-nav__link">
      2020 July
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-3" type="checkbox" id="nav-5-3">
    
    <label class="md-nav__link" for="nav-5-3">
      概率论与数理统计
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-3">
        概率论与数理统计
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/1.%E7%AC%AC%E4%B8%80%E7%AB%A0_%E9%9A%8F%E6%9C%BA%E4%BA%8B%E4%BB%B6%E4%B8%8E%E6%A6%82%E7%8E%87/" title="1.第一章 随机事件与概率" class="md-nav__link">
      1.第一章 随机事件与概率
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-4" type="checkbox" id="nav-5-4">
    
    <label class="md-nav__link" for="nav-5-4">
      经济学人
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-4">
        经济学人
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-4-1" type="checkbox" id="nav-5-4-1">
    
    <label class="md-nav__link" for="nav-5-4-1">
      商论
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-4-1">
        商论
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/%E5%95%86%E8%AE%BA/2020_July/" title="2020 July" class="md-nav__link">
      2020 July
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-4-2" type="checkbox" id="nav-5-4-2">
    
    <label class="md-nav__link" for="nav-5-4-2">
      学人习语
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-4-2">
        学人习语
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%BA%BA/%E5%AD%A6%E4%BA%BA%E4%B9%A0%E8%AF%AD/Economist_2020/" title="Economist 2020" class="md-nav__link">
      Economist 2020
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-5" type="checkbox" id="nav-5-5">
    
    <label class="md-nav__link" for="nav-5-5">
      考研政治习题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-5">
        考研政治习题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-5-1" type="checkbox" id="nav-5-5-1">
    
    <label class="md-nav__link" for="nav-5-5-1">
      每日知识点
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-5-1">
        每日知识点
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E8%80%83%E7%A0%94%E6%94%BF%E6%B2%BB%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E7%9F%A5%E8%AF%86%E7%82%B9/1.%E6%AF%8F%E6%97%A5%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AC%AC%E4%B8%80%E5%AD%A3/" title="1.每日知识点第一季" class="md-nav__link">
      1.每日知识点第一季
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E8%80%83%E7%A0%94%E6%94%BF%E6%B2%BB%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E7%9F%A5%E8%AF%86%E7%82%B9/2.%E6%AF%8F%E6%97%A5%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AC%AC%E4%BA%8C%E5%AD%A3/" title="2.每日知识点第二季" class="md-nav__link">
      2.每日知识点第二季
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E8%80%83%E7%A0%94%E6%94%BF%E6%B2%BB%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E7%9F%A5%E8%AF%86%E7%82%B9/3.%E6%AF%8F%E6%97%A5%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AC%AC%E4%B8%89%E5%AD%A3/" title="3.每日知识点第三季" class="md-nav__link">
      3.每日知识点第三季
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-6" type="checkbox" id="nav-5-6">
    
    <label class="md-nav__link" for="nav-5-6">
      计算机组成习题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-6">
        计算机组成习题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-6-1" type="checkbox" id="nav-5-6-1">
    
    <label class="md-nav__link" for="nav-5-6-1">
      每日一题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-6-1">
        每日一题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_August/" title="2020 August" class="md-nav__link">
      2020 August
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_July/" title="2020 July" class="md-nav__link">
      2020 July
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-7" type="checkbox" id="nav-5-7">
    
    <label class="md-nav__link" for="nav-5-7">
      计算机网络习题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-7">
        计算机网络习题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-7-1" type="checkbox" id="nav-5-7-1">
    
    <label class="md-nav__link" for="nav-5-7-1">
      每日一题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-7-1">
        每日一题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_August/" title="2020 August" class="md-nav__link">
      2020 August
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B9%A0%E9%A2%98/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/2020_July/" title="2020 July" class="md-nav__link">
      2020 July
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-8" type="checkbox" id="nav-5-8">
    
    <label class="md-nav__link" for="nav-5-8">
      高等数学
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-8">
        高等数学
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/1.%E7%AC%AC%E4%B8%80%E7%AB%A0_%E5%87%BD%E6%95%B0_%E6%9E%81%E9%99%90_%E8%BF%9E%E7%BB%AD/" title="1.第一章 函数 极限 连续" class="md-nav__link">
      1.第一章 函数 极限 连续
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/2.%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E5%AF%BC%E6%95%B0%E4%B8%8E%E5%BE%AE%E5%88%86/" title="2.第二章 导数与微分" class="md-nav__link">
      2.第二章 导数与微分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/3.%E7%AC%AC%E4%B8%89%E7%AB%A0_%E5%BE%AE%E5%88%86%E4%B8%AD%E5%80%BC%E5%AE%9A%E7%90%86%E5%8F%8A%E5%AF%BC%E6%95%B0%E5%BA%94%E7%94%A8/" title="3.第三章 微分中值定理及导数应用" class="md-nav__link">
      3.第三章 微分中值定理及导数应用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/4.%E7%AC%AC%E5%9B%9B%E7%AB%A0_%E4%B8%8D%E5%AE%9A%E7%A7%AF%E5%88%86/" title="4.第四章 不定积分" class="md-nav__link">
      4.第四章 不定积分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/5.%E7%AC%AC%E4%BA%94%E7%AB%A0_%E5%AE%9A%E7%A7%AF%E5%88%86%E4%B8%8E%E5%8F%8D%E5%B8%B8%E7%A7%AF%E5%88%86/" title="5.第五章 定积分与反常积分" class="md-nav__link">
      5.第五章 定积分与反常积分
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6/6.%E7%AC%AC%E5%85%AD%E7%AB%A0_%E5%AE%9A%E7%A7%AF%E5%88%86%E7%9A%84%E5%BA%94%E7%94%A8/" title="6.第六章 定积分的应用" class="md-nav__link">
      6.第六章 定积分的应用
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-9" type="checkbox" id="nav-5-9">
    
    <label class="md-nav__link" for="nav-5-9">
      高等数学习题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-9">
        高等数学习题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%80%83%E7%A0%94%E7%AC%94%E8%AE%B0/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E4%B9%A0%E9%A2%98/1.%E7%AC%AC%E4%B8%80%E7%AB%A0_%E5%87%BD%E6%95%B0_%E6%9E%81%E9%99%90_%E8%BF%9E%E7%BB%AD_%E9%94%99%E9%A2%98/" title="1.第一章 函数 极限 连续 错题" class="md-nav__link">
      1.第一章 函数 极限 连续 错题
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      读书笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        读书笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-1" type="checkbox" id="nav-6-1">
    
    <label class="md-nav__link" for="nav-6-1">
      商业
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-1">
        商业
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%95%86%E4%B8%9A/1.%E6%AF%8F%E5%91%A8%E5%95%86%E4%B8%9A%E8%AF%84%E8%AE%BA_%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8/" title="1.每周商业评论 字节跳动" class="md-nav__link">
      1.每周商业评论 字节跳动
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-2" type="checkbox" id="nav-6-2">
    
    <label class="md-nav__link" for="nav-6-2">
      数学
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-2">
        数学
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%A6/1.%E6%95%B0%E5%AD%A6%E5%A5%B3%E5%AD%A9/" title="1.数学女孩" class="md-nav__link">
      1.数学女孩
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-3" type="checkbox" id="nav-6-3">
    
    <label class="md-nav__link" for="nav-6-3">
      机器学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-3">
        机器学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E5%AF%BC%E5%BC%95/" title="1.机器学习理论导引" class="md-nav__link">
      1.机器学习理论导引
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6-4" type="checkbox" id="nav-6-4">
    
    <label class="md-nav__link" for="nav-6-4">
      管理学
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-6-4">
        管理学
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E7%AE%A1%E7%90%86%E5%AD%A6/1.%E7%AE%A1%E7%90%86%E7%9A%84%E5%AE%9E%E8%B7%B5/" title="1.管理的实践" class="md-nav__link">
      1.管理的实践
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      课程笔记
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        课程笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-1" type="checkbox" id="nav-7-1">
    
    <label class="md-nav__link" for="nav-7-1">
      Java分布式系统
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-1">
        Java分布式系统
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/Java%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/1.Java%E4%B8%AD%E7%9A%84%E6%B3%9B%E5%9E%8B/" title="1.Java中的泛型" class="md-nav__link">
      1.Java中的泛型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/Java%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/8.Java%E4%B8%AD%E7%9A%84%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8%28RPC%29/" title="8.Java中的远程过程调用(RPC)" class="md-nav__link">
      8.Java中的远程过程调用(RPC)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/Java%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/9.Java%E8%BF%9C%E7%A8%8B%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%28RMI%29/" title="9.Java远程方法调用(RMI)" class="md-nav__link">
      9.Java远程方法调用(RMI)
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-2" type="checkbox" id="nav-7-2">
    
    <label class="md-nav__link" for="nav-7-2">
      大学物理
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-2">
        大学物理
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86/1.%E7%AC%AC%E4%B8%80%E7%AB%A0_%E8%BF%90%E5%8A%A8%E5%92%8C%E5%8A%9B/" title="1.第一章 运动和力" class="md-nav__link">
      1.第一章 运动和力
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-3" type="checkbox" id="nav-7-3">
    
    <label class="md-nav__link" for="nav-7-3">
      嵌入式系统
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-3">
        嵌入式系统
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/1.uCos%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" title="1.uCos环境配置" class="md-nav__link">
      1.uCos环境配置
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/10.uCos-ii%E4%B8%AD%E7%9A%84%E4%BB%BB%E5%8A%A1%E4%BB%A3%E7%A0%81/" title="10.uCos ii中的任务代码" class="md-nav__link">
      10.uCos ii中的任务代码
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/2.%E4%BC%98%E5%85%88%E7%BA%A7%E5%8F%8D%E8%BD%AC%E4%B8%8E%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6/" title="2.优先级反转与中断机制" class="md-nav__link">
      2.优先级反转与中断机制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/3.uCos%E4%B8%AD%E9%94%81%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AF%94%E5%85%B3%E4%B8%AD%E6%96%AD%E6%95%88%E7%8E%87%E6%9B%B4%E9%AB%98/" title="3.uCos中锁调度器为什么比关中断效率更高" class="md-nav__link">
      3.uCos中锁调度器为什么比关中断效率更高
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/4.uCos%E7%9A%84%E5%BB%B6%E8%BF%9F%E4%B8%AD%E6%96%AD%E6%8F%90%E4%BA%A4%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E6%8F%90%E9%AB%98%E6%95%88%E7%8E%87/" title="4.uCos的延迟中断提交为什么能提高效率" class="md-nav__link">
      4.uCos的延迟中断提交为什么能提高效率
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/5.uCos%E4%B8%AD%E7%9A%84%E4%BB%BB%E5%8A%A1%E6%9C%BA%E5%88%B6%E5%92%8C%E4%BC%98%E5%85%88%E7%BA%A7%E4%BD%8D%E5%9B%BE%E7%AE%97%E6%B3%95/" title="5.uCos中的任务机制和优先级位图算法" class="md-nav__link">
      5.uCos中的任务机制和优先级位图算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/6.uCos%E4%B8%AD%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6/" title="6.uCos中的信号量机制" class="md-nav__link">
      6.uCos中的信号量机制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/7.uCos%E4%B8%AD%E7%9A%84%E4%B8%AD%E6%96%AD%E6%97%B6%E9%97%B4%E5%92%8C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" title="7.uCos中的中断时间和内存管理" class="md-nav__link">
      7.uCos中的中断时间和内存管理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/8.%E5%A4%8D%E4%B9%A0%E9%A2%98/" title="8.复习题" class="md-nav__link">
      8.复习题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F/9.%E9%82%AE%E7%AE%B1%E5%92%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" title="9.邮箱和消息队列" class="md-nav__link">
      9.邮箱和消息队列
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-4" type="checkbox" id="nav-7-4">
    
    <label class="md-nav__link" for="nav-7-4">
      数字电子技术
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-4">
        数字电子技术
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E7%94%B5%E5%AD%90%E6%8A%80%E6%9C%AF/1.%E5%A4%8D%E4%B9%A0%E5%A4%A7%E7%BA%B2/" title="1.复习大纲" class="md-nav__link">
      1.复习大纲
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-5" type="checkbox" id="nav-7-5">
    
    <label class="md-nav__link" for="nav-7-5">
      移动应用开发
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-5">
        移动应用开发
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%A7%BB%E5%8A%A8%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/1.%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="1.复习笔记" class="md-nav__link">
      1.复习笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-6" type="checkbox" id="nav-7-6">
    
    <label class="md-nav__link" for="nav-7-6">
      编译原理
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-6">
        编译原理
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/1.%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95/" title="1.上下文无关文法" class="md-nav__link">
      1.上下文无关文法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/2.%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%E6%A6%82%E8%BF%B0/" title="2.词法分析概述" class="md-nav__link">
      2.词法分析概述
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/3.%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90-%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E5%88%86%E6%9E%90%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/" title="3.语法分析 自上而下分析的基本问题" class="md-nav__link">
      3.语法分析 自上而下分析的基本问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/4.%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90-%E8%AF%8D%E6%B3%95%E8%A7%84%E5%88%99%E7%9A%84%E5%BD%A2%E5%BC%8F%E5%8C%96/" title="4.词法分析 词法规则的形式化" class="md-nav__link">
      4.词法分析 词法规则的形式化
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/5.%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2/" title="5.复习提纲" class="md-nav__link">
      5.复习提纲
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-7" type="checkbox" id="nav-7-7">
    
    <label class="md-nav__link" for="nav-7-7">
      网络安全
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-7">
        网络安全
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-7-1" type="checkbox" id="nav-7-7-1">
    
    <label class="md-nav__link" for="nav-7-7-1">
      BUUCTF
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-7-7-1">
        BUUCTF
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/BUUCTF/1.BUUCTF_Pwn_test_your_nc/" title="1.BUUCTF Pwn test your nc" class="md-nav__link">
      1.BUUCTF Pwn test your nc
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-7-2" type="checkbox" id="nav-7-7-2">
    
    <label class="md-nav__link" for="nav-7-7-2">
      DVWA训练
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-7-7-2">
        DVWA训练
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/DVWA%E8%AE%AD%E7%BB%83/1.DVWA_Brute_Force_Low/" title="1.DVWA Brute Force Low" class="md-nav__link">
      1.DVWA Brute Force Low
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/DVWA%E8%AE%AD%E7%BB%83/2.DVWA_Command_Injection_All/" title="2.DVWA Command Injection All" class="md-nav__link">
      2.DVWA Command Injection All
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/DVWA%E8%AE%AD%E7%BB%83/3.DVWA_XSS_DOM_All/" title="3.DVWA XSS DOM All" class="md-nav__link">
      3.DVWA XSS DOM All
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/DVWA%E8%AE%AD%E7%BB%83/4.DVWA_CSRF_All/" title="4.DVWA CSRF All" class="md-nav__link">
      4.DVWA CSRF All
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/DVWA%E8%AE%AD%E7%BB%83/5.DVWA_File_Inclusion_All/" title="5.DVWA File Inclusion All" class="md-nav__link">
      5.DVWA File Inclusion All
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-8" type="checkbox" id="nav-7-8">
    
    <label class="md-nav__link" for="nav-7-8">
      计算机专业课程设计
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-8">
        计算机专业课程设计
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/1.%E4%BD%BF%E7%94%A8Node.js%E6%90%AD%E5%BB%BA%E8%81%8A%E5%A4%A9%E7%B3%BB%E7%BB%9F/" title="1.使用Node.js搭建聊天系统" class="md-nav__link">
      1.使用Node.js搭建聊天系统
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%93%E4%B8%9A%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/2.%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90/" title="2.需求分析" class="md-nav__link">
      2.需求分析
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7-9" type="checkbox" id="nav-7-9">
    
    <label class="md-nav__link" for="nav-7-9">
      软件协同设计
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-7-9">
        软件协同设计
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%BD%AF%E4%BB%B6%E5%8D%8F%E5%90%8C%E8%AE%BE%E8%AE%A1/1.%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E6%80%9D%E8%80%83%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="1.前后端分离的思考与实践" class="md-nav__link">
      1.前后端分离的思考与实践
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%BD%AF%E4%BB%B6%E5%8D%8F%E5%90%8C%E8%AE%BE%E8%AE%A1/2.%E4%BD%BF%E7%94%A8Express%E9%83%A8%E7%BD%B2Vue%E9%A1%B9%E7%9B%AE/" title="2.使用Express部署Vue项目" class="md-nav__link">
      2.使用Express部署Vue项目
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%BD%AF%E4%BB%B6%E5%8D%8F%E5%90%8C%E8%AE%BE%E8%AE%A1/3.NESMA%E5%8A%9F%E8%83%BD%E7%82%B9%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95/" title="3.NESMA功能点估计方法" class="md-nav__link">
      3.NESMA功能点估计方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%BD%AF%E4%BB%B6%E5%8D%8F%E5%90%8C%E8%AE%BE%E8%AE%A1/4.WBS%E5%B7%A5%E4%BD%9C%E7%BB%93%E6%9E%84%E5%88%86%E8%A7%A3%E6%96%B9%E6%B3%95/" title="4.WBS工作结构分解方法" class="md-nav__link">
      4.WBS工作结构分解方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%BD%AF%E4%BB%B6%E5%8D%8F%E5%90%8C%E8%AE%BE%E8%AE%A1/5.%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="5.复习笔记" class="md-nav__link">
      5.复习笔记
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%BD%AF%E4%BB%B6%E5%8D%8F%E5%90%8C%E8%AE%BE%E8%AE%A1/6.COCOMO%E5%B7%A5%E4%BD%9C%E9%87%8F%E4%BC%B0%E8%AE%A1%E6%A8%A1%E5%9E%8B/" title="6.COCOMO工作量估计模型" class="md-nav__link">
      6.COCOMO工作量估计模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../../%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E8%BD%AF%E4%BB%B6%E5%8D%8F%E5%90%8C%E8%AE%BE%E8%AE%A1/7.UML%E5%9B%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="7.UML图学习笔记" class="md-nav__link">
      7.UML图学习笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1. 背景
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    目录
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-a" class="md-nav__link">
    2. A
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-ab-ab-testing" class="md-nav__link">
    2.1. A/B 测试 (A/B testing)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-accuracy" class="md-nav__link">
    2.2. 准确率 (accuracy)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-activation-function" class="md-nav__link">
    2.3. 激活函数 (activation function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-adagrad" class="md-nav__link">
    2.4. AdaGrad
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#25-roc-auc-area-under-the-roc-curve" class="md-nav__link">
    2.5. ROC 曲线下面积 (AUC, Area under the ROC Curve)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-b" class="md-nav__link">
    3. B
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-backpropagation" class="md-nav__link">
    3.1. 反向传播算法 (backpropagation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-baseline" class="md-nav__link">
    3.2. 基准 (baseline)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-batch" class="md-nav__link">
    3.3. 批次 (batch)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-batch-size" class="md-nav__link">
    3.4. 批次大小 (batch size)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-bias" class="md-nav__link">
    3.5. 偏差 (bias)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-binary-classification" class="md-nav__link">
    3.6. 二元分类 (binary classification)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#37-binning" class="md-nav__link">
    3.7. 分箱 (binning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#38-bucketing" class="md-nav__link">
    3.8. 分桶 (bucketing)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-c" class="md-nav__link">
    4. C
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-calibration-layer" class="md-nav__link">
    4.1. 校准层 (calibration layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-candidate-sampling" class="md-nav__link">
    4.2. 候选采样 (candidate sampling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-categorical-data" class="md-nav__link">
    4.3. 分类数据 (categorical data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-centroid" class="md-nav__link">
    4.4. 形心 (centroid)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-checkpoint" class="md-nav__link">
    4.5. 检查点 (checkpoint)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46-class" class="md-nav__link">
    4.6. 类别 (class)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#47-class-imbalanced-data-set" class="md-nav__link">
    4.7. 分类不平衡的数据集 (class-imbalanced data set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#48-classification-model" class="md-nav__link">
    4.8. 分类模型 (classification model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#49-classification-threshold" class="md-nav__link">
    4.9. 分类阈值 (classification threshold)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#410-clustering" class="md-nav__link">
    4.10. 聚类 (clustering)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#411-collaborative-filtering" class="md-nav__link">
    4.11. 协同过滤 (collaborative filtering)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#412-confusion-matrix" class="md-nav__link">
    4.12. 混淆矩阵 (confusion matrix)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#413-continuous-feature" class="md-nav__link">
    4.13. 连续特征 (continuous feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#414-convergence" class="md-nav__link">
    4.14. 收敛 (convergence)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#415-convex-function" class="md-nav__link">
    4.15. 凸函数 (convex function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#416-convex-optimization" class="md-nav__link">
    4.16. 凸优化 (convex optimization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#417-convex-set" class="md-nav__link">
    4.17. 凸集 (convex set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#418-convolution" class="md-nav__link">
    4.18. 卷积 (convolution)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#419-convolutional-filter" class="md-nav__link">
    4.19. 卷积过滤器 (convolutional filter)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#420-convolutional-layer" class="md-nav__link">
    4.20. 卷积层 (convolutional layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#421-convolutional-neural-network" class="md-nav__link">
    4.21. 卷积神经网络 (convolutional neural network)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#422-convolutional-operation" class="md-nav__link">
    4.22. 卷积运算 (convolutional operation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#423-cost" class="md-nav__link">
    4.23. 成本 (cost)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#424-cross-entropy" class="md-nav__link">
    4.24. 交叉熵 (cross-entropy)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#425-estimator-custom-estimator" class="md-nav__link">
    4.25. 自定义 Estimator (custom Estimator)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-d" class="md-nav__link">
    5. D
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-data-analysis" class="md-nav__link">
    5.1. 数据分析 (data analysis)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-dataframe" class="md-nav__link">
    5.2. DataFrame
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-data-set" class="md-nav__link">
    5.3. 数据集 (data set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54-dataset-api-tfdata" class="md-nav__link">
    5.4. Dataset API (tf.data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55-decision-boundary" class="md-nav__link">
    5.5. 决策边界 (decision boundary)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56-dense-layer" class="md-nav__link">
    5.6. 密集层 (dense layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#57-deep-model" class="md-nav__link">
    5.7. 深度模型 (deep model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#58-dense-feature" class="md-nav__link">
    5.8. 密集特征 (dense feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#59-device" class="md-nav__link">
    5.9. 设备 (device)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#510-discrete-feature" class="md-nav__link">
    5.10. 离散特征 (discrete feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#511-dropout-regularization" class="md-nav__link">
    5.11. 丢弃正则化 (dropout regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#512-dynamic-model" class="md-nav__link">
    5.12. 动态模型 (dynamic model)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-e" class="md-nav__link">
    6. E
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-early-stopping" class="md-nav__link">
    6.1. 早停法 (early stopping)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-embeddings" class="md-nav__link">
    6.2. 嵌套 (embeddings)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-erm-empirical-risk-minimization" class="md-nav__link">
    6.3. 经验风险最小化 (ERM, empirical risk minimization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-ensemble" class="md-nav__link">
    6.4. 集成学习 (ensemble)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-epoch" class="md-nav__link">
    6.5. 周期 (epoch)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66-estimator" class="md-nav__link">
    6.6. Estimator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#67-example" class="md-nav__link">
    6.7. 样本 (example)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-f" class="md-nav__link">
    7. F
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-fn-false-negative" class="md-nav__link">
    7.1. 假负例 (FN, false negative)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-fp-false-positive" class="md-nav__link">
    7.2. 假正例 (FP, false positive)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-false-positive-rate-fp" class="md-nav__link">
    7.3. 假正例率（false positive rate, 简称 FP 率）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-feature" class="md-nav__link">
    7.4. 特征 (feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75-tffeature_column" class="md-nav__link">
    7.5. 特征列 (tf.feature_column)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76-feature-cross" class="md-nav__link">
    7.6. 特征组合 (feature cross)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#77-feature-engineering" class="md-nav__link">
    7.7. 特征工程 (feature engineering)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#78-feature-set" class="md-nav__link">
    7.8. 特征集 (feature set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#79-feature-spec" class="md-nav__link">
    7.9. 特征规范 (feature spec)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#710-few-shot-learning" class="md-nav__link">
    7.10. 少量样本学习 (few-shot learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#711-softmax-full-softmax" class="md-nav__link">
    7.11. 完整 softmax (full softmax)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#712-fully-connected-layer" class="md-nav__link">
    7.12. 全连接层 (fully connected layer)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-g" class="md-nav__link">
    8. G
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-generalization" class="md-nav__link">
    8.1. 泛化 (generalization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-generalized-linear-model" class="md-nav__link">
    8.2. 广义线性模型 (generalized linear model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-gradient" class="md-nav__link">
    8.3. 梯度 (gradient)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-gradient-clipping" class="md-nav__link">
    8.4. 梯度裁剪 (gradient clipping)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-gradient-descent" class="md-nav__link">
    8.5. 梯度下降法 (gradient descent)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86-graph" class="md-nav__link">
    8.6. 图 (graph)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-h" class="md-nav__link">
    9. H
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-heuristic" class="md-nav__link">
    9.1. 启发法 (heuristic)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-hidden-layer" class="md-nav__link">
    9.2. 隐藏层 (hidden layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-hinge-loss" class="md-nav__link">
    9.3. 合页损失函数 (hinge loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-holdout-data" class="md-nav__link">
    9.4. 维持数据 (holdout data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#95-hyperparameter" class="md-nav__link">
    9.5. 超参数 (hyperparameter)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#96-hyperplane" class="md-nav__link">
    9.6. 超平面 (hyperplane)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-i" class="md-nav__link">
    10. I
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-iid-independently-and-identically-distributed" class="md-nav__link">
    10.1. 独立同等分布 (i.i.d, independently and identically distributed)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-inference" class="md-nav__link">
    10.2. 推断 (inference)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-input-function" class="md-nav__link">
    10.3. 输入函数 (input function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-input-layer" class="md-nav__link">
    10.4. 输入层 (input layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-instance" class="md-nav__link">
    10.5. 实例 (instance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-interpretability" class="md-nav__link">
    10.6. 可解释性 (interpretability)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#107-inter-rater-agreement" class="md-nav__link">
    10.7. 评分者间一致性信度 (inter-rater agreement)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#108-iteration" class="md-nav__link">
    10.8. 迭代 (iteration)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-k" class="md-nav__link">
    11. K
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-k-means" class="md-nav__link">
    11.1. k-means
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-k-median" class="md-nav__link">
    11.2. k-median
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-keras" class="md-nav__link">
    11.3. Keras
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-ksvm-kernel-support-vector-machines" class="md-nav__link">
    11.4. 核支持向量机 (KSVM, Kernel Support Vector Machines)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-l" class="md-nav__link">
    12. L
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#121-l_1-l_1-loss" class="md-nav__link">
    12.1. L_1 损失函数 (L_1 loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#122-l_1-l_1-regularization" class="md-nav__link">
    12.2. L_1 正则化 (L_1 regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#123-l_2-l_2-loss" class="md-nav__link">
    12.3. L_2 损失函数 (L_2 loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#124-l_2-l_2-regularization" class="md-nav__link">
    12.4. L_2 正则化 (L_2 regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#125-label" class="md-nav__link">
    12.5. 标签 (label)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#126-labeled-example" class="md-nav__link">
    12.6. 有标签样本 (labeled example)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#127-lambda" class="md-nav__link">
    12.7. lambda
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#128-layer" class="md-nav__link">
    12.8. 层 (layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#129-layers-api-tflayers" class="md-nav__link">
    12.9. Layers API (tf.layers)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1210-learning-rate" class="md-nav__link">
    12.10. 学习速率 (learning rate)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1211-least-squares-regression" class="md-nav__link">
    12.11. 最小二乘回归 (least squares regression)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1212-linear-regression" class="md-nav__link">
    12.12. 线性回归 (linear regression)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1213-logistic-regression" class="md-nav__link">
    12.13. 逻辑回归 (logistic regression)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1214-logits" class="md-nav__link">
    12.14. 对数 (logits)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1215-log-loss" class="md-nav__link">
    12.15. 对数损失函数 (Log Loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1216-log-odds" class="md-nav__link">
    12.16. 对数几率 (log-odds)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1217-loss" class="md-nav__link">
    12.17. 损失 (Loss)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-m" class="md-nav__link">
    13. M
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#131-machine-learning" class="md-nav__link">
    13.1. 机器学习 (machine learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#132-mse-mean-squared-error" class="md-nav__link">
    13.2. 均方误差 (MSE, Mean Squared Error)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#133-metric" class="md-nav__link">
    13.3. 指标 (metric)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#134-metrics-api-tfmetrics" class="md-nav__link">
    13.4. Metrics API (tf.metrics)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#135-mini-batch" class="md-nav__link">
    13.5. 小批次 (mini-batch)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#136-sgd-mini-batch-stochastic-gradient-descent" class="md-nav__link">
    13.6. 小批次随机梯度下降法 (SGD, mini-batch stochastic gradient descent)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#137-ml" class="md-nav__link">
    13.7. ML
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#138-model" class="md-nav__link">
    13.8. 模型 (model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#139-model-function" class="md-nav__link">
    13.9. 模型函数 (model function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1310-model-training" class="md-nav__link">
    13.10. 模型训练 (model training)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1311-momentum" class="md-nav__link">
    13.11. 动量 (Momentum)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1312-multi-class-classification" class="md-nav__link">
    13.12. 多类别分类 (multi-class classification)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1313-multinomial-classification" class="md-nav__link">
    13.13. 多项分类 (multinomial classification)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-n" class="md-nav__link">
    14. N
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#141-nan-nan-trap" class="md-nav__link">
    14.1. NaN 陷阱 (NaN trap)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#142-negative-class" class="md-nav__link">
    14.2. 负类别 (negative class)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#143-neural-network" class="md-nav__link">
    14.3. 神经网络 (neural network)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#144-neuron" class="md-nav__link">
    14.4. 神经元 (neuron)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#145-node" class="md-nav__link">
    14.5. 节点 (node)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#146-normalization" class="md-nav__link">
    14.6. 标准化 (normalization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#147-numerical-data" class="md-nav__link">
    14.7. 数值数据 (numerical data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#148-numpy" class="md-nav__link">
    14.8. Numpy
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-o" class="md-nav__link">
    15. O
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#151-objective" class="md-nav__link">
    15.1. 目标 (objective)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#152-offline-inference" class="md-nav__link">
    15.2. 离线推断 (offline inference)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#153-one-hot-encoding" class="md-nav__link">
    15.3. 独热编码 (one-hot encoding)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#154-one-shot-learning" class="md-nav__link">
    15.4. 单样本学习（one-shot learning，通常用于对象分类）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#155-one-vs-all" class="md-nav__link">
    15.5. 一对多 (one-vs.-all)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#156-online-inference" class="md-nav__link">
    15.6. 在线推断 (online inference)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#157-op-operation" class="md-nav__link">
    15.7. 操作 (op, Operation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#158-optimizer" class="md-nav__link">
    15.8. 优化器 (optimizer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#159-outlier" class="md-nav__link">
    15.9. 离群值 (outlier)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1510-output-layer" class="md-nav__link">
    15.10. 输出层 (output layer)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1511-overfitting" class="md-nav__link">
    15.11. 过拟合 (overfitting)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-p" class="md-nav__link">
    16. P
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#161-pandas" class="md-nav__link">
    16.1. Pandas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#162-parameter" class="md-nav__link">
    16.2. 参数 (parameter)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#163-ps-parameter-server" class="md-nav__link">
    16.3. 参数服务器 (PS, Parameter Server)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#164-parameter-update" class="md-nav__link">
    16.4. 参数更新 (parameter update)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#165-partial-derivative" class="md-nav__link">
    16.5. 偏导数 (partial derivative)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#166-partitioning-strategy" class="md-nav__link">
    16.6. 划分策略 (partitioning strategy)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#167-performance" class="md-nav__link">
    16.7. 性能 (performance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#168-perplexity" class="md-nav__link">
    16.8. 困惑度 (perplexity)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#169-pipeline" class="md-nav__link">
    16.9. 流水线 (pipeline)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1610-pooling" class="md-nav__link">
    16.10. 池化 (pooling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1611-positive-class" class="md-nav__link">
    16.11. 正类别 (positive class)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1612-precision" class="md-nav__link">
    16.12. 精确率 (precision)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1613-prediction" class="md-nav__link">
    16.13. 预测 (prediction)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1614-prediction-bias" class="md-nav__link">
    16.14. 预测偏差 (prediction bias)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1615-estimator-pre-made-estimator" class="md-nav__link">
    16.15. 预创建的 Estimator (pre-made Estimator)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1616-pre-trained-model" class="md-nav__link">
    16.16. 预训练模型 (pre-trained model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1617-prior-belief" class="md-nav__link">
    16.17. 先验信念 (prior belief)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-q" class="md-nav__link">
    17. Q
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#171-queue" class="md-nav__link">
    17.1. 队列 (queue)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#18-r" class="md-nav__link">
    18. R
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#181-rank" class="md-nav__link">
    18.1. 等级 (rank)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#182-rater" class="md-nav__link">
    18.2. 评分者 (rater)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#183-recall" class="md-nav__link">
    18.3. 召回率 (recall)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#184-relu-rectified-linear-unit" class="md-nav__link">
    18.4. 修正线性单元 (ReLU, Rectified Linear Unit)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#185-regression-model" class="md-nav__link">
    18.5. 回归模型 (regression model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#186-regularization" class="md-nav__link">
    18.6. 正则化 (regularization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#187-regularization-rate" class="md-nav__link">
    18.7. 正则化率 (regularization rate)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#188-representation" class="md-nav__link">
    18.8. 表示法 (representation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#189-receiver-operating-characteristic-roc" class="md-nav__link">
    18.9. 受试者工作特征曲线（receiver operating characteristic，简称 ROC 曲线）
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1810-root-directory" class="md-nav__link">
    18.10. 根目录 (root directory)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1811-rmse-root-mean-squared-error" class="md-nav__link">
    18.11. 均方根误差 (RMSE, Root Mean Squared Error)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1812-rotational-invariance" class="md-nav__link">
    18.12. 旋转不变性 (rotational invariance)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#19-s" class="md-nav__link">
    19. S
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#191-savedmodel" class="md-nav__link">
    19.1. SavedModel
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#192-saver" class="md-nav__link">
    19.2. Saver
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#193-scaling" class="md-nav__link">
    19.3. 缩放 (scaling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#194-scikit-learn" class="md-nav__link">
    19.4. scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#195-semi-supervised-learning" class="md-nav__link">
    19.5. 半监督式学习 (semi-supervised learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#196-sequence-model" class="md-nav__link">
    19.6. 序列模型 (sequence model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#197-tfsession" class="md-nav__link">
    19.7. 会话 (tf.session)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#198-s-sigmoid-function" class="md-nav__link">
    19.8. S 型函数 (sigmoid function)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#199-size-invariance" class="md-nav__link">
    19.9. 大小不变性 (size invariance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1910-softmax" class="md-nav__link">
    19.10. softmax
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1911-sparse-feature" class="md-nav__link">
    19.11. 稀疏特征 (sparse feature)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1912-sparse-representation" class="md-nav__link">
    19.12. 稀疏表示法 (sparse representation)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1913-sparsity" class="md-nav__link">
    19.13. 稀疏性 (sparsity)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1914-spatial-pooling" class="md-nav__link">
    19.14. 空间池化 (spatial pooling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1915-squared-hinge-loss" class="md-nav__link">
    19.15. 平方合页损失函数 (squared hinge loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1916-squared-loss" class="md-nav__link">
    19.16. 平方损失函数 (squared loss)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1917-static-model" class="md-nav__link">
    19.17. 静态模型 (static model)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1918-stationarity" class="md-nav__link">
    19.18. 平稳性 (stationarity)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1919-step" class="md-nav__link">
    19.19. 步 (step)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1920-step-size" class="md-nav__link">
    19.20. 步长 (step size)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1921-sgd-stochastic-gradient-descent" class="md-nav__link">
    19.21. 随机梯度下降法 (SGD, stochastic gradient descent)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1922-srm-structural-risk-minimization" class="md-nav__link">
    19.22. 结构风险最小化 (SRM, structural risk minimization)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1923-stride" class="md-nav__link">
    19.23. 步长 (stride)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1924-subsampling" class="md-nav__link">
    19.24. 下采样 (subsampling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1925-summary" class="md-nav__link">
    19.25. 总结 (summary)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1926-supervised-machine-learning" class="md-nav__link">
    19.26. 监督式机器学习 (supervised machine learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1927-synthetic-feature" class="md-nav__link">
    19.27. 合成特征 (synthetic feature)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#20-t" class="md-nav__link">
    20. T
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#201-target" class="md-nav__link">
    20.1. 目标 (target)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#202-temporal-data" class="md-nav__link">
    20.2. 时态数据 (temporal data)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#203-tensor" class="md-nav__link">
    20.3. 张量 (Tensor)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#204-tpu-tensor-processing-unit" class="md-nav__link">
    20.4. 张量处理单元 (TPU, Tensor Processing Unit)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#205-tensor-rank" class="md-nav__link">
    20.5. 张量等级 (Tensor rank)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#206-tensor-shape" class="md-nav__link">
    20.6. 张量形状 (Tensor shape)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#207-tensor-size" class="md-nav__link">
    20.7. 张量大小 (Tensor size)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#208-tensorboard" class="md-nav__link">
    20.8. TensorBoard
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#209-tensorflow" class="md-nav__link">
    20.9. TensorFlow
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2010-tensorflow-playground" class="md-nav__link">
    20.10. TensorFlow Playground
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2011-tensorflow-serving" class="md-nav__link">
    20.11. TensorFlow Serving
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2012-test-set" class="md-nav__link">
    20.12. 测试集 (test set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2013-tfexample" class="md-nav__link">
    20.13. tf.Example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2014-time-series-analysis" class="md-nav__link">
    20.14. 时间序列分析 (time series analysis)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2015-training" class="md-nav__link">
    20.15. 训练 (training)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2016-training-set" class="md-nav__link">
    20.16. 训练集 (training set)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2017-transfer-learning" class="md-nav__link">
    20.17. 迁移学习 (transfer learning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2018-translational-invariance" class="md-nav__link">
    20.18. 平移不变性 (translational invariance)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2019-tn-true-negative" class="md-nav__link">
    20.19. 负例 (TN, true negative)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2020-tp-true-positive" class="md-nav__link">
    20.20. 正例 (TP, true positive)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2021-true-positive-rate-tp" class="md-nav__link">
    20.21. 正例率（true positive rate, 简称 TP 率）
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#21-u" class="md-nav__link">
    21. U
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#211-unlabeled-example" class="md-nav__link">
    21.1. 无标签样本 (unlabeled example)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#212-unsupervised-machine-learning" class="md-nav__link">
    21.2. 非监督式机器学习 (unsupervised machine learning)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#22-v" class="md-nav__link">
    22. V
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#221-validation-set" class="md-nav__link">
    22.1. 验证集 (validation set)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#23-w" class="md-nav__link">
    23. W
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#231-weight" class="md-nav__link">
    23.1. 权重 (weight)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#232-wide-model" class="md-nav__link">
    23.2. 宽度模型 (wide model)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/CurrenWong/Mkdoc/edit/master/docs/算法学习笔记/机器学习算法/3.机器学习术语表.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="google"><a class="toclink" href="#google">Google 机器学习术语表</a><a class="headerlink" href="#google" title="Permanent link">#</a></h1>
<h2 id="1"><a class="toclink" href="#1">1. 背景</a><a class="headerlink" href="#1" title="Permanent link">#</a></h2>
<p>Google出了一份机器学习术语表，列出了一般的机器学习术语和 TensorFlow 专用术语的定义，并且翻译成了中文，对理解机器学习中的术语很有帮助，于是我把它转载过来，方便学习和记录。</p>
<p>原文链接：<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN">https://developers.google.cn/machine-learning/glossary/?hl=zh-CN</a></p>
<h2 id="_1"><a class="toclink" href="#_1">目录</a><a class="headerlink" href="#_1" title="Permanent link">#</a></h2>
<div class="toc">
<ul>
<li><a href="#google">Google 机器学习术语表</a><ul>
<li><a href="#1">1. 背景</a></li>
<li><a href="#_1">目录</a></li>
<li><a href="#2-a">2. A</a><ul>
<li><a href="#21-ab-ab-testing">2.1. A/B 测试 (A/B testing)</a></li>
<li><a href="#22-accuracy">2.2. 准确率 (accuracy)</a></li>
<li><a href="#23-activation-function">2.3. 激活函数 (activation function)</a></li>
<li><a href="#24-adagrad">2.4. AdaGrad</a></li>
<li><a href="#25-roc-auc-area-under-the-roc-curve">2.5. ROC 曲线下面积 (AUC, Area under the ROC Curve)</a></li>
</ul>
</li>
<li><a href="#3-b">3. B</a><ul>
<li><a href="#31-backpropagation">3.1. 反向传播算法 (backpropagation)</a></li>
<li><a href="#32-baseline">3.2. 基准 (baseline)</a></li>
<li><a href="#33-batch">3.3. 批次 (batch)</a></li>
<li><a href="#34-batch-size">3.4. 批次大小 (batch size)</a></li>
<li><a href="#35-bias">3.5. 偏差 (bias)</a></li>
<li><a href="#36-binary-classification">3.6. 二元分类 (binary classification)</a></li>
<li><a href="#37-binning">3.7. 分箱 (binning)</a></li>
<li><a href="#38-bucketing">3.8. 分桶 (bucketing)</a></li>
</ul>
</li>
<li><a href="#4-c">4. C</a><ul>
<li><a href="#41-calibration-layer">4.1. 校准层 (calibration layer)</a></li>
<li><a href="#42-candidate-sampling">4.2. 候选采样 (candidate sampling)</a></li>
<li><a href="#43-categorical-data">4.3. 分类数据 (categorical data)</a></li>
<li><a href="#44-centroid">4.4. 形心 (centroid)</a></li>
<li><a href="#45-checkpoint">4.5. 检查点 (checkpoint)</a></li>
<li><a href="#46-class">4.6. 类别 (class)</a></li>
<li><a href="#47-class-imbalanced-data-set">4.7. 分类不平衡的数据集 (class-imbalanced data set)</a></li>
<li><a href="#48-classification-model">4.8. 分类模型 (classification model)</a></li>
<li><a href="#49-classification-threshold">4.9. 分类阈值 (classification threshold)</a></li>
<li><a href="#410-clustering">4.10. 聚类 (clustering)</a></li>
<li><a href="#411-collaborative-filtering">4.11. 协同过滤 (collaborative filtering)</a></li>
<li><a href="#412-confusion-matrix">4.12. 混淆矩阵 (confusion matrix)</a></li>
<li><a href="#413-continuous-feature">4.13. 连续特征 (continuous feature)</a></li>
<li><a href="#414-convergence">4.14. 收敛 (convergence)</a></li>
<li><a href="#415-convex-function">4.15. 凸函数 (convex function)</a></li>
<li><a href="#416-convex-optimization">4.16. 凸优化 (convex optimization)</a></li>
<li><a href="#417-convex-set">4.17. 凸集 (convex set)</a></li>
<li><a href="#418-convolution">4.18. 卷积 (convolution)</a></li>
<li><a href="#419-convolutional-filter">4.19. 卷积过滤器 (convolutional filter)</a></li>
<li><a href="#420-convolutional-layer">4.20. 卷积层 (convolutional layer)</a></li>
<li><a href="#421-convolutional-neural-network">4.21. 卷积神经网络 (convolutional neural network)</a></li>
<li><a href="#422-convolutional-operation">4.22. 卷积运算 (convolutional operation)</a></li>
<li><a href="#423-cost">4.23. 成本 (cost)</a></li>
<li><a href="#424-cross-entropy">4.24. 交叉熵 (cross-entropy)</a></li>
<li><a href="#425-estimator-custom-estimator">4.25. 自定义 Estimator (custom Estimator)</a></li>
</ul>
</li>
<li><a href="#5-d">5. D</a><ul>
<li><a href="#51-data-analysis">5.1. 数据分析 (data analysis)</a></li>
<li><a href="#52-dataframe">5.2. DataFrame</a></li>
<li><a href="#53-data-set">5.3. 数据集 (data set)</a></li>
<li><a href="#54-dataset-api-tfdata">5.4. Dataset API (tf.data)</a></li>
<li><a href="#55-decision-boundary">5.5. 决策边界 (decision boundary)</a></li>
<li><a href="#56-dense-layer">5.6. 密集层 (dense layer)</a></li>
<li><a href="#57-deep-model">5.7. 深度模型 (deep model)</a></li>
<li><a href="#58-dense-feature">5.8. 密集特征 (dense feature)</a></li>
<li><a href="#59-device">5.9. 设备 (device)</a></li>
<li><a href="#510-discrete-feature">5.10. 离散特征 (discrete feature)</a></li>
<li><a href="#511-dropout-regularization">5.11. 丢弃正则化 (dropout regularization)</a></li>
<li><a href="#512-dynamic-model">5.12. 动态模型 (dynamic model)</a></li>
</ul>
</li>
<li><a href="#6-e">6. E</a><ul>
<li><a href="#61-early-stopping">6.1. 早停法 (early stopping)</a></li>
<li><a href="#62-embeddings">6.2. 嵌套 (embeddings)</a></li>
<li><a href="#63-erm-empirical-risk-minimization">6.3. 经验风险最小化 (ERM, empirical risk minimization)</a></li>
<li><a href="#64-ensemble">6.4. 集成学习 (ensemble)</a></li>
<li><a href="#65-epoch">6.5. 周期 (epoch)</a></li>
<li><a href="#66-estimator">6.6. Estimator</a></li>
<li><a href="#67-example">6.7. 样本 (example)</a></li>
</ul>
</li>
<li><a href="#7-f">7. F</a><ul>
<li><a href="#71-fn-false-negative">7.1. 假负例 (FN, false negative)</a></li>
<li><a href="#72-fp-false-positive">7.2. 假正例 (FP, false positive)</a></li>
<li><a href="#73-false-positive-rate-fp">7.3. 假正例率（false positive rate, 简称 FP 率）</a></li>
<li><a href="#74-feature">7.4. 特征 (feature)</a></li>
<li><a href="#75-tffeature_column">7.5. 特征列 (tf.feature_column)</a></li>
<li><a href="#76-feature-cross">7.6. 特征组合 (feature cross)</a></li>
<li><a href="#77-feature-engineering">7.7. 特征工程 (feature engineering)</a></li>
<li><a href="#78-feature-set">7.8. 特征集 (feature set)</a></li>
<li><a href="#79-feature-spec">7.9. 特征规范 (feature spec)</a></li>
<li><a href="#710-few-shot-learning">7.10. 少量样本学习 (few-shot learning)</a></li>
<li><a href="#711-softmax-full-softmax">7.11. 完整 softmax (full softmax)</a></li>
<li><a href="#712-fully-connected-layer">7.12. 全连接层 (fully connected layer)</a></li>
</ul>
</li>
<li><a href="#8-g">8. G</a><ul>
<li><a href="#81-generalization">8.1. 泛化 (generalization)</a></li>
<li><a href="#82-generalized-linear-model">8.2. 广义线性模型 (generalized linear model)</a></li>
<li><a href="#83-gradient">8.3. 梯度 (gradient)</a></li>
<li><a href="#84-gradient-clipping">8.4. 梯度裁剪 (gradient clipping)</a></li>
<li><a href="#85-gradient-descent">8.5. 梯度下降法 (gradient descent)</a></li>
<li><a href="#86-graph">8.6. 图 (graph)</a></li>
</ul>
</li>
<li><a href="#9-h">9. H</a><ul>
<li><a href="#91-heuristic">9.1. 启发法 (heuristic)</a></li>
<li><a href="#92-hidden-layer">9.2. 隐藏层 (hidden layer)</a></li>
<li><a href="#93-hinge-loss">9.3. 合页损失函数 (hinge loss)</a></li>
<li><a href="#94-holdout-data">9.4. 维持数据 (holdout data)</a></li>
<li><a href="#95-hyperparameter">9.5. 超参数 (hyperparameter)</a></li>
<li><a href="#96-hyperplane">9.6. 超平面 (hyperplane)</a></li>
</ul>
</li>
<li><a href="#10-i">10. I</a><ul>
<li><a href="#101-iid-independently-and-identically-distributed">10.1. 独立同等分布 (i.i.d, independently and identically distributed)</a></li>
<li><a href="#102-inference">10.2. 推断 (inference)</a></li>
<li><a href="#103-input-function">10.3. 输入函数 (input function)</a></li>
<li><a href="#104-input-layer">10.4. 输入层 (input layer)</a></li>
<li><a href="#105-instance">10.5. 实例 (instance)</a></li>
<li><a href="#106-interpretability">10.6. 可解释性 (interpretability)</a></li>
<li><a href="#107-inter-rater-agreement">10.7. 评分者间一致性信度 (inter-rater agreement)</a></li>
<li><a href="#108-iteration">10.8. 迭代 (iteration)</a></li>
</ul>
</li>
<li><a href="#11-k">11. K</a><ul>
<li><a href="#111-k-means">11.1. k-means</a></li>
<li><a href="#112-k-median">11.2. k-median</a></li>
<li><a href="#113-keras">11.3. Keras</a></li>
<li><a href="#114-ksvm-kernel-support-vector-machines">11.4. 核支持向量机 (KSVM, Kernel Support Vector Machines)</a></li>
</ul>
</li>
<li><a href="#12-l">12. L</a><ul>
<li><a href="#121-l_1-l_1-loss">12.1. L_1 损失函数 (L_1 loss)</a></li>
<li><a href="#122-l_1-l_1-regularization">12.2. L_1 正则化 (L_1 regularization)</a></li>
<li><a href="#123-l_2-l_2-loss">12.3. L_2 损失函数 (L_2 loss)</a></li>
<li><a href="#124-l_2-l_2-regularization">12.4. L_2 正则化 (L_2 regularization)</a></li>
<li><a href="#125-label">12.5. 标签 (label)</a></li>
<li><a href="#126-labeled-example">12.6. 有标签样本 (labeled example)</a></li>
<li><a href="#127-lambda">12.7. lambda</a></li>
<li><a href="#128-layer">12.8. 层 (layer)</a></li>
<li><a href="#129-layers-api-tflayers">12.9. Layers API (tf.layers)</a></li>
<li><a href="#1210-learning-rate">12.10. 学习速率 (learning rate)</a></li>
<li><a href="#1211-least-squares-regression">12.11. 最小二乘回归 (least squares regression)</a></li>
<li><a href="#1212-linear-regression">12.12. 线性回归 (linear regression)</a></li>
<li><a href="#1213-logistic-regression">12.13. 逻辑回归 (logistic regression)</a></li>
<li><a href="#1214-logits">12.14. 对数 (logits)</a></li>
<li><a href="#1215-log-loss">12.15. 对数损失函数 (Log Loss)</a></li>
<li><a href="#1216-log-odds">12.16. 对数几率 (log-odds)</a></li>
<li><a href="#1217-loss">12.17. 损失 (Loss)</a></li>
</ul>
</li>
<li><a href="#13-m">13. M</a><ul>
<li><a href="#131-machine-learning">13.1. 机器学习 (machine learning)</a></li>
<li><a href="#132-mse-mean-squared-error">13.2. 均方误差 (MSE, Mean Squared Error)</a></li>
<li><a href="#133-metric">13.3. 指标 (metric)</a></li>
<li><a href="#134-metrics-api-tfmetrics">13.4. Metrics API (tf.metrics)</a></li>
<li><a href="#135-mini-batch">13.5. 小批次 (mini-batch)</a></li>
<li><a href="#136-sgd-mini-batch-stochastic-gradient-descent">13.6. 小批次随机梯度下降法 (SGD, mini-batch stochastic gradient descent)</a></li>
<li><a href="#137-ml">13.7. ML</a></li>
<li><a href="#138-model">13.8. 模型 (model)</a></li>
<li><a href="#139-model-function">13.9. 模型函数 (model function)</a></li>
<li><a href="#1310-model-training">13.10. 模型训练 (model training)</a></li>
<li><a href="#1311-momentum">13.11. 动量 (Momentum)</a></li>
<li><a href="#1312-multi-class-classification">13.12. 多类别分类 (multi-class classification)</a></li>
<li><a href="#1313-multinomial-classification">13.13. 多项分类 (multinomial classification)</a></li>
</ul>
</li>
<li><a href="#14-n">14. N</a><ul>
<li><a href="#141-nan-nan-trap">14.1. NaN 陷阱 (NaN trap)</a></li>
<li><a href="#142-negative-class">14.2. 负类别 (negative class)</a></li>
<li><a href="#143-neural-network">14.3. 神经网络 (neural network)</a></li>
<li><a href="#144-neuron">14.4. 神经元 (neuron)</a></li>
<li><a href="#145-node">14.5. 节点 (node)</a></li>
<li><a href="#146-normalization">14.6. 标准化 (normalization)</a></li>
<li><a href="#147-numerical-data">14.7. 数值数据 (numerical data)</a></li>
<li><a href="#148-numpy">14.8. Numpy</a></li>
</ul>
</li>
<li><a href="#15-o">15. O</a><ul>
<li><a href="#151-objective">15.1. 目标 (objective)</a></li>
<li><a href="#152-offline-inference">15.2. 离线推断 (offline inference)</a></li>
<li><a href="#153-one-hot-encoding">15.3. 独热编码 (one-hot encoding)</a></li>
<li><a href="#154-one-shot-learning">15.4. 单样本学习（one-shot learning，通常用于对象分类）</a></li>
<li><a href="#155-one-vs-all">15.5. 一对多 (one-vs.-all)</a></li>
<li><a href="#156-online-inference">15.6. 在线推断 (online inference)</a></li>
<li><a href="#157-op-operation">15.7. 操作 (op, Operation)</a></li>
<li><a href="#158-optimizer">15.8. 优化器 (optimizer)</a></li>
<li><a href="#159-outlier">15.9. 离群值 (outlier)</a></li>
<li><a href="#1510-output-layer">15.10. 输出层 (output layer)</a></li>
<li><a href="#1511-overfitting">15.11. 过拟合 (overfitting)</a></li>
</ul>
</li>
<li><a href="#16-p">16. P</a><ul>
<li><a href="#161-pandas">16.1. Pandas</a></li>
<li><a href="#162-parameter">16.2. 参数 (parameter)</a></li>
<li><a href="#163-ps-parameter-server">16.3. 参数服务器 (PS, Parameter Server)</a></li>
<li><a href="#164-parameter-update">16.4. 参数更新 (parameter update)</a></li>
<li><a href="#165-partial-derivative">16.5. 偏导数 (partial derivative)</a></li>
<li><a href="#166-partitioning-strategy">16.6. 划分策略 (partitioning strategy)</a></li>
<li><a href="#167-performance">16.7. 性能 (performance)</a></li>
<li><a href="#168-perplexity">16.8. 困惑度 (perplexity)</a></li>
<li><a href="#169-pipeline">16.9. 流水线 (pipeline)</a></li>
<li><a href="#1610-pooling">16.10. 池化 (pooling)</a></li>
<li><a href="#1611-positive-class">16.11. 正类别 (positive class)</a></li>
<li><a href="#1612-precision">16.12. 精确率 (precision)</a></li>
<li><a href="#1613-prediction">16.13. 预测 (prediction)</a></li>
<li><a href="#1614-prediction-bias">16.14. 预测偏差 (prediction bias)</a></li>
<li><a href="#1615-estimator-pre-made-estimator">16.15. 预创建的 Estimator (pre-made Estimator)</a></li>
<li><a href="#1616-pre-trained-model">16.16. 预训练模型 (pre-trained model)</a></li>
<li><a href="#1617-prior-belief">16.17. 先验信念 (prior belief)</a></li>
</ul>
</li>
<li><a href="#17-q">17. Q</a><ul>
<li><a href="#171-queue">17.1. 队列 (queue)</a></li>
</ul>
</li>
<li><a href="#18-r">18. R</a><ul>
<li><a href="#181-rank">18.1. 等级 (rank)</a></li>
<li><a href="#182-rater">18.2. 评分者 (rater)</a></li>
<li><a href="#183-recall">18.3. 召回率 (recall)</a></li>
<li><a href="#184-relu-rectified-linear-unit">18.4. 修正线性单元 (ReLU, Rectified Linear Unit)</a></li>
<li><a href="#185-regression-model">18.5. 回归模型 (regression model)</a></li>
<li><a href="#186-regularization">18.6. 正则化 (regularization)</a></li>
<li><a href="#187-regularization-rate">18.7. 正则化率 (regularization rate)</a></li>
<li><a href="#188-representation">18.8. 表示法 (representation)</a></li>
<li><a href="#189-receiver-operating-characteristic-roc">18.9. 受试者工作特征曲线（receiver operating characteristic，简称 ROC 曲线）</a></li>
<li><a href="#1810-root-directory">18.10. 根目录 (root directory)</a></li>
<li><a href="#1811-rmse-root-mean-squared-error">18.11. 均方根误差 (RMSE, Root Mean Squared Error)</a></li>
<li><a href="#1812-rotational-invariance">18.12. 旋转不变性 (rotational invariance)</a></li>
</ul>
</li>
<li><a href="#19-s">19. S</a><ul>
<li><a href="#191-savedmodel">19.1. SavedModel</a></li>
<li><a href="#192-saver">19.2. Saver</a></li>
<li><a href="#193-scaling">19.3. 缩放 (scaling)</a></li>
<li><a href="#194-scikit-learn">19.4. scikit-learn</a></li>
<li><a href="#195-semi-supervised-learning">19.5. 半监督式学习 (semi-supervised learning)</a></li>
<li><a href="#196-sequence-model">19.6. 序列模型 (sequence model)</a></li>
<li><a href="#197-tfsession">19.7. 会话 (tf.session)</a></li>
<li><a href="#198-s-sigmoid-function">19.8. S 型函数 (sigmoid function)</a></li>
<li><a href="#199-size-invariance">19.9. 大小不变性 (size invariance)</a></li>
<li><a href="#1910-softmax">19.10. softmax</a></li>
<li><a href="#1911-sparse-feature">19.11. 稀疏特征 (sparse feature)</a></li>
<li><a href="#1912-sparse-representation">19.12. 稀疏表示法 (sparse representation)</a></li>
<li><a href="#1913-sparsity">19.13. 稀疏性 (sparsity)</a></li>
<li><a href="#1914-spatial-pooling">19.14. 空间池化 (spatial pooling)</a></li>
<li><a href="#1915-squared-hinge-loss">19.15. 平方合页损失函数 (squared hinge loss)</a></li>
<li><a href="#1916-squared-loss">19.16. 平方损失函数 (squared loss)</a></li>
<li><a href="#1917-static-model">19.17. 静态模型 (static model)</a></li>
<li><a href="#1918-stationarity">19.18. 平稳性 (stationarity)</a></li>
<li><a href="#1919-step">19.19. 步 (step)</a></li>
<li><a href="#1920-step-size">19.20. 步长 (step size)</a></li>
<li><a href="#1921-sgd-stochastic-gradient-descent">19.21. 随机梯度下降法 (SGD, stochastic gradient descent)</a></li>
<li><a href="#1922-srm-structural-risk-minimization">19.22. 结构风险最小化 (SRM, structural risk minimization)</a></li>
<li><a href="#1923-stride">19.23. 步长 (stride)</a></li>
<li><a href="#1924-subsampling">19.24. 下采样 (subsampling)</a></li>
<li><a href="#1925-summary">19.25. 总结 (summary)</a></li>
<li><a href="#1926-supervised-machine-learning">19.26. 监督式机器学习 (supervised machine learning)</a></li>
<li><a href="#1927-synthetic-feature">19.27. 合成特征 (synthetic feature)</a></li>
</ul>
</li>
<li><a href="#20-t">20. T</a><ul>
<li><a href="#201-target">20.1. 目标 (target)</a></li>
<li><a href="#202-temporal-data">20.2. 时态数据 (temporal data)</a></li>
<li><a href="#203-tensor">20.3. 张量 (Tensor)</a></li>
<li><a href="#204-tpu-tensor-processing-unit">20.4. 张量处理单元 (TPU, Tensor Processing Unit)</a></li>
<li><a href="#205-tensor-rank">20.5. 张量等级 (Tensor rank)</a></li>
<li><a href="#206-tensor-shape">20.6. 张量形状 (Tensor shape)</a></li>
<li><a href="#207-tensor-size">20.7. 张量大小 (Tensor size)</a></li>
<li><a href="#208-tensorboard">20.8. TensorBoard</a></li>
<li><a href="#209-tensorflow">20.9. TensorFlow</a></li>
<li><a href="#2010-tensorflow-playground">20.10. TensorFlow Playground</a></li>
<li><a href="#2011-tensorflow-serving">20.11. TensorFlow Serving</a></li>
<li><a href="#2012-test-set">20.12. 测试集 (test set)</a></li>
<li><a href="#2013-tfexample">20.13. tf.Example</a></li>
<li><a href="#2014-time-series-analysis">20.14. 时间序列分析 (time series analysis)</a></li>
<li><a href="#2015-training">20.15. 训练 (training)</a></li>
<li><a href="#2016-training-set">20.16. 训练集 (training set)</a></li>
<li><a href="#2017-transfer-learning">20.17. 迁移学习 (transfer learning)</a></li>
<li><a href="#2018-translational-invariance">20.18. 平移不变性 (translational invariance)</a></li>
<li><a href="#2019-tn-true-negative">20.19. 负例 (TN, true negative)</a></li>
<li><a href="#2020-tp-true-positive">20.20. 正例 (TP, true positive)</a></li>
<li><a href="#2021-true-positive-rate-tp">20.21. 正例率（true positive rate, 简称 TP 率）</a></li>
</ul>
</li>
<li><a href="#21-u">21. U</a><ul>
<li><a href="#211-unlabeled-example">21.1. 无标签样本 (unlabeled example)</a></li>
<li><a href="#212-unsupervised-machine-learning">21.2. 非监督式机器学习 (unsupervised machine learning)</a></li>
</ul>
</li>
<li><a href="#22-v">22. V</a><ul>
<li><a href="#221-validation-set">22.1. 验证集 (validation set)</a></li>
</ul>
</li>
<li><a href="#23-w">23. W</a><ul>
<li><a href="#231-weight">23.1. 权重 (weight)</a></li>
<li><a href="#232-wide-model">23.2. 宽度模型 (wide model)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<hr />
<h2 id="2-a"><a class="toclink" href="#2-a">2. A</a><a class="headerlink" href="#2-a" title="Permanent link">#</a></h2>
<h3 id="21-ab-ab-testing"><a class="toclink" href="#21-ab-ab-testing">2.1. A/B 测试 (A/B testing)</a><a class="headerlink" href="#21-ab-ab-testing" title="Permanent link">#</a></h3>
<p>一种统计方法，用于将两种或多种技术进行比较，通常是将当前采用的技术与新技术进行比较。A/B 测试不仅旨在确定哪种技术的效果更好，而且还有助于了解相应差异是否具有显著的统计意义。A/B 测试通常是采用一种衡量方式对两种技术进行比较，但也适用于任意有限数量的技术和衡量方式。</p>
<h3 id="22-accuracy"><a class="toclink" href="#22-accuracy">2.2. 准确率 (accuracy)</a><a class="headerlink" href="#22-accuracy" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_model">分类模型</a>的正确预测所占的比例。在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#multi-class">多类别分类</a>中，准确率的定义如下：</p>
<p>
<script type="math/tex; mode=display">
\text{准确率} = \frac{\text{正确的预测数}}{\text{样本总数}}
</script>
</p>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>中，准确率的定义如下：</p>
<p>
<script type="math/tex; mode=display">
\text{准确率} = \frac{\text{正例数 + 负例数}}{\text{样本总数}}
</script>
</p>
<p>请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#TP">正例</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#TN">负例</a>。</p>
<h3 id="23-activation-function"><a class="toclink" href="#23-activation-function">2.3. 激活函数 (activation function)</a><a class="headerlink" href="#23-activation-function" title="Permanent link">#</a></h3>
<p>一种函数（例如 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#ReLU">ReLU</a> 或 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sigmoid_function">S 型函数</a>），用于对上一层的所有输入求加权和，然后生成一个输出值（通常为非线性值），并将其传递给下一层。</p>
<h3 id="24-adagrad"><a class="toclink" href="#24-adagrad">2.4. AdaGrad</a><a class="headerlink" href="#24-adagrad" title="Permanent link">#</a></h3>
<p>一种先进的梯度下降法，用于重新调整每个参数的梯度，以便有效地为每个参数指定独立的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#learning_rate">学习速率</a>。如需查看完整的解释，请参阅<a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">这篇论文</a>。</p>
<h3 id="25-roc-auc-area-under-the-roc-curve"><a class="toclink" href="#25-roc-auc-area-under-the-roc-curve">2.5. ROC 曲线下面积 (AUC, Area under the ROC Curve)</a><a class="headerlink" href="#25-roc-auc-area-under-the-roc-curve" title="Permanent link">#</a></h3>
<p>一种会考虑所有可能<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_threshold">分类阈值</a>的评估指标。</p>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#ROC">ROC 曲线</a>下面积是，对于随机选择的正类别样本确实为正类别，以及随机选择的负类别样本为正类别，分类器更确信前者的概率。</p>
<h2 id="3-b"><a class="toclink" href="#3-b">3. B</a><a class="headerlink" href="#3-b" title="Permanent link">#</a></h2>
<h3 id="31-backpropagation"><a class="toclink" href="#31-backpropagation">3.1. 反向传播算法 (backpropagation)</a><a class="headerlink" href="#31-backpropagation" title="Permanent link">#</a></h3>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>上执行<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>的主要算法。该算法会先按前向传播方式计算（并缓存）每个节点的输出值，然后再按反向传播遍历图的方式计算损失函数值相对于每个参数的<a href="https://en.wikipedia.org/wiki/Partial_derivative">偏导数</a>。</p>
<h3 id="32-baseline"><a class="toclink" href="#32-baseline">3.2. 基准 (baseline)</a><a class="headerlink" href="#32-baseline" title="Permanent link">#</a></h3>
<p>一种简单的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>或启发法，用作比较模型效果时的参考点。基准有助于模型开发者针对特定问题量化最低预期效果。</p>
<h3 id="33-batch"><a class="toclink" href="#33-batch">3.3. 批次 (batch)</a><a class="headerlink" href="#33-batch" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model_training">模型训练</a>的一次<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#iteration">迭代</a>（即一次<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient">梯度</a>更新）中使用的样本集。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#batch_size">批次大小</a>。</p>
<h3 id="34-batch-size"><a class="toclink" href="#34-batch-size">3.4. 批次大小 (batch size)</a><a class="headerlink" href="#34-batch-size" title="Permanent link">#</a></h3>
<p>一个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#batch">批次</a>中的样本数。例如，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#SGD">SGD</a> 的批次大小为 1，而<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#mini-batch">小批次</a>的大小通常介于 10 到 1000 之间。批次大小在训练和推断期间通常是固定的；不过，TensorFlow 允许使用动态批次大小。</p>
<h3 id="35-bias"><a class="toclink" href="#35-bias">3.5. 偏差 (bias)</a><a class="headerlink" href="#35-bias" title="Permanent link">#</a></h3>
<p>距离原点的截距或偏移。偏差（也称为偏差项）在机器学习模型中用 b 或 w~0~ 表示。例如，在下面的公式中，偏差为 b：</p>
<p>
<script type="math/tex; mode=display">
y' = b + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
</script>
</p>
<p>请勿与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#prediction_bias">预测偏差</a>混淆。</p>
<h3 id="36-binary-classification"><a class="toclink" href="#36-binary-classification">3.6. 二元分类 (binary classification)</a><a class="headerlink" href="#36-binary-classification" title="Permanent link">#</a></h3>
<p>一种分类任务，可输出两种互斥类别之一。例如，对电子邮件进行评估并输出"垃圾邮件"或"非垃圾邮件"的机器学习模型就是一个二元分类器。</p>
<h3 id="37-binning"><a class="toclink" href="#37-binning">3.7. 分箱 (binning)</a><a class="headerlink" href="#37-binning" title="Permanent link">#</a></h3>
<p>请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#bucketing">分桶</a>。</p>
<h3 id="38-bucketing"><a class="toclink" href="#38-bucketing">3.8. 分桶 (bucketing)</a><a class="headerlink" href="#38-bucketing" title="Permanent link">#</a></h3>
<p>将一个特征（通常是<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#continuous_feature">连续</a>特征）转换成多个二元特征（称为桶或箱），通常根据值区间进行转换。例如，您可以将温度区间分割为离散分箱，而不是将温度表示成单个连续的浮点特征。假设温度数据可精确到小数点后一位，则可以将介于 0.0 到 15.0 度之间的所有温度都归入一个分箱，将介于 15.1 到 30.0 度之间的所有温度归入第二个分箱，并将介于 30.1 到 50.0 度之间的所有温度归入第三个分箱。</p>
<h2 id="4-c"><a class="toclink" href="#4-c">4. C</a><a class="headerlink" href="#4-c" title="Permanent link">#</a></h2>
<h3 id="41-calibration-layer"><a class="toclink" href="#41-calibration-layer">4.1. 校准层 (calibration layer)</a><a class="headerlink" href="#41-calibration-layer" title="Permanent link">#</a></h3>
<p>一种预测后调整，通常是为了降低<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#prediction_bias">预测偏差</a>的影响。调整后的预测和概率应与观察到的标签集的分布一致。</p>
<h3 id="42-candidate-sampling"><a class="toclink" href="#42-candidate-sampling">4.2. 候选采样 (candidate sampling)</a><a class="headerlink" href="#42-candidate-sampling" title="Permanent link">#</a></h3>
<p>一种训练时进行的优化，会使用某种函数（例如 softmax）针对所有正类别标签计算概率，但对于负类别标签，则仅针对其随机样本计算概率。例如，如果某个样本的标签为"小猎犬"和"狗"，则候选采样将针对"小猎犬"和"狗"类别输出以及其他类别（猫、棒棒糖、栅栏）的随机子集计算预测概率和相应的损失项。这种采样基于的想法是，只要<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#positive_class">正类别</a>始终得到适当的正增强，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#negative_class">负类别</a>就可以从频率较低的负增强中进行学习，这确实是在实际中观察到的情况。候选采样的目的是，通过不针对所有负类别计算预测结果来提高计算效率。</p>
<h3 id="43-categorical-data"><a class="toclink" href="#43-categorical-data">4.3. 分类数据 (categorical data)</a><a class="headerlink" href="#43-categorical-data" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>，拥有一组离散的可能值。以某个名为 <code>house style</code> 的分类特征为例，该特征拥有一组离散的可能值（共三个），即 <code>Tudor, ranch, colonial</code>。通过将 <code>house style</code> 表示成分类数据，相应模型可以学习 <code>Tudor</code>、<code>ranch</code> 和 <code>colonial</code> 分别对房价的影响。</p>
<p>有时，离散集中的值是互斥的，只能将其中一个值应用于指定样本。例如，<code>car maker</code> 分类特征可能只允许一个样本有一个值 (<code>Toyota</code>)。在其他情况下，则可以应用多个值。一辆车可能会被喷涂多种不同的颜色，因此，<code>car color</code> 分类特征可能会允许单个样本具有多个值（例如 <code>red</code> 和 <code>white</code>）。</p>
<p>分类特征有时称为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#discrete_feature">离散特征</a>。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#numerical_data">数值数据</a>相对。</p>
<h3 id="44-centroid"><a class="toclink" href="#44-centroid">4.4. 形心 (centroid)</a><a class="headerlink" href="#44-centroid" title="Permanent link">#</a></h3>
<p>聚类的中心，由 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#k-means">k-means</a> 或 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#k-median">k-median</a> 算法决定。例如，如果 k 为 3，则 k-means 或 k-median 算法会找出 3 个形心。</p>
<h3 id="45-checkpoint"><a class="toclink" href="#45-checkpoint">4.5. 检查点 (checkpoint)</a><a class="headerlink" href="#45-checkpoint" title="Permanent link">#</a></h3>
<p>一种数据，用于捕获模型变量在特定时间的状态。借助检查点，可以导出模型<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#weight">权重</a>，跨多个会话执行训练，以及使训练在发生错误之后得以继续（例如作业抢占）。请注意，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#graph">图</a>本身不包含在检查点中。</p>
<h3 id="46-class"><a class="toclink" href="#46-class">4.6. 类别 (class)</a><a class="headerlink" href="#46-class" title="Permanent link">#</a></h3>
<p>为标签枚举的一组目标值中的一个。例如，在检测垃圾邮件的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>模型中，两种类别分别是"垃圾邮件"和"非垃圾邮件"。在识别狗品种的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#multi_class_classification">多类别分类</a>模型中，类别可以是"贵宾犬"、"小猎犬"、"哈巴犬"等等。</p>
<h3 id="47-class-imbalanced-data-set"><a class="toclink" href="#47-class-imbalanced-data-set">4.7. 分类不平衡的数据集 (class-imbalanced data set)</a><a class="headerlink" href="#47-class-imbalanced-data-set" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>问题，在此类问题中，两种类别的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>在出现频率方面具有很大的差距。例如，在某个疾病数据集中，0.0001 的样本具有正类别标签，0.9999 的样本具有负类别标签，这就属于分类不平衡问题；但在某个足球比赛预测器中，0.51 的样本的标签为其中一个球队赢，0.49 的样本的标签为另一个球队赢，这就不属于分类不平衡问题。</p>
<h3 id="48-classification-model"><a class="toclink" href="#48-classification-model">4.8. 分类模型 (classification model)</a><a class="headerlink" href="#48-classification-model" title="Permanent link">#</a></h3>
<p>一种机器学习模型，用于区分两种或多种离散类别。例如，某个自然语言处理分类模型可以确定输入的句子是法语、西班牙语还是意大利语。请与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regression_model">回归模型</a>进行比较。</p>
<h3 id="49-classification-threshold"><a class="toclink" href="#49-classification-threshold">4.9. 分类阈值 (classification threshold)</a><a class="headerlink" href="#49-classification-threshold" title="Permanent link">#</a></h3>
<p>一种标量值条件，应用于模型预测的得分，旨在将<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#positive_class">正类别</a>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#negative_class">负类别</a>区分开。将<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#logistic_regression">逻辑回归</a>结果映射到<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>时使用。以某个逻辑回归模型为例，该模型用于确定指定电子邮件是垃圾邮件的概率。如果分类阈值为 0.9，那么逻辑回归值高于 0.9 的电子邮件将被归类为"垃圾邮件"，低于 0.9 的则被归类为"非垃圾邮件"。</p>
<h3 id="410-clustering"><a class="toclink" href="#410-clustering">4.10. 聚类 (clustering)</a><a class="headerlink" href="#410-clustering" title="Permanent link">#</a></h3>
<p>将关联的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>分成一组，一般用于<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#unsupervised_machine_learning">非监督式学习</a>。在所有样本均分组完毕后，相关人员便可选择性地为每个聚类赋予含义。</p>
<p>聚类算法有很多。例如，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#k-means">k-means</a> 算法会基于样本与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#centroid">形心</a>的接近程度聚类样本，如下图所示：</p>
<p><img alt="聚类样本" src="https://developers.google.cn/machine-learning/glossary/images/Cluster.svg?hl=zh-CN" /></p>
<p>之后，研究人员便可查看这些聚类并进行其他操作，例如，将聚类 1 标记为"矮型树"，将聚类 2 标记为"全尺寸树"。</p>
<p>再举一个例子，例如基于样本与中心点距离的聚类算法，如下所示：</p>
<p><img alt="聚类算法" src="https://developers.google.cn/machine-learning/glossary/images/RingCluster.svg?hl=zh-CN" /></p>
<h3 id="411-collaborative-filtering"><a class="toclink" href="#411-collaborative-filtering">4.11. 协同过滤 (collaborative filtering)</a><a class="headerlink" href="#411-collaborative-filtering" title="Permanent link">#</a></h3>
<p>根据很多其他用户的兴趣来预测某位用户的兴趣。协同过滤通常用在推荐系统中。</p>
<h3 id="412-confusion-matrix"><a class="toclink" href="#412-confusion-matrix">4.12. 混淆矩阵 (confusion matrix)</a><a class="headerlink" href="#412-confusion-matrix" title="Permanent link">#</a></h3>
<p>一种 NxN 表格，用于总结<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_model">分类模型</a>的预测效果；即标签和模型预测的分类之间的关联。在混淆矩阵中，一个轴表示模型预测的标签，另一个轴表示实际标签。N 表示类别个数。在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>问题中，N=2。例如，下面显示了一个二元分类问题的混淆矩阵示例：</p>
<table>
<thead>
<tr>
<th></th>
<th>肿瘤（预测的标签）</th>
<th>非肿瘤（预测的标签）</th>
</tr>
</thead>
<tbody>
<tr>
<td>肿瘤（实际标签）</td>
<td>18</td>
<td>1</td>
</tr>
<tr>
<td>非肿瘤（实际标签）</td>
<td>6</td>
<td>452</td>
</tr>
</tbody>
</table>
<p>上面的混淆矩阵显示，在 19 个实际有肿瘤的样本中，该模型正确地将 18 个归类为有肿瘤（18 个正例），错误地将 1 个归类为没有肿瘤（1 个假负例）。同样，在 458 个实际没有肿瘤的样本中，模型归类正确的有 452 个（452 个负例），归类错误的有 6 个（6 个假正例）。</p>
<p>多类别分类问题的混淆矩阵有助于确定出错模式。例如，某个混淆矩阵可以揭示，某个经过训练以识别手写数字的模型往往会将 4 错误地预测为 9，将 7 错误地预测为 1。</p>
<p>混淆矩阵包含计算各种效果指标（包括<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#precision">精确率</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#recall">召回率</a>）所需的充足信息。</p>
<h3 id="413-continuous-feature"><a class="toclink" href="#413-continuous-feature">4.13. 连续特征 (continuous feature)</a><a class="headerlink" href="#413-continuous-feature" title="Permanent link">#</a></h3>
<p>一种浮点特征，可能值的区间不受限制。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#discrete_feature">离散特征</a>相对。</p>
<h3 id="414-convergence"><a class="toclink" href="#414-convergence">4.14. 收敛 (convergence)</a><a class="headerlink" href="#414-convergence" title="Permanent link">#</a></h3>
<p>通俗来说，收敛通常是指在训练期间达到的一种状态，即经过一定次数的迭代之后，训练<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>和验证损失在每次迭代中的变化都非常小或根本没有变化。也就是说，如果采用当前数据进行额外的训练将无法改进模型，模型即达到收敛状态。在深度学习中，损失值有时会在最终下降之前的多次迭代中保持不变或几乎保持不变，暂时形成收敛的假象。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#early_stopping">早停法</a>。</p>
<p>另请参阅 Boyd 和 Vandenberghe 合著的 <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex Optimization</a>（《凸优化》）。</p>
<h3 id="415-convex-function"><a class="toclink" href="#415-convex-function">4.15. 凸函数 (convex function)</a><a class="headerlink" href="#415-convex-function" title="Permanent link">#</a></h3>
<p>一种函数，函数图像以上的区域为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convex_set">凸集</a>。典型凸函数的形状类似于字母 U。例如，以下都是凸函数：</p>
<p><img alt="典型凸函数的形状类似于字母 U。" src="https://developers.google.cn/machine-learning/glossary/images/convex_functions.png?hl=zh-CN" /></p>
<p>相反，以下函数则不是凸函数。请注意图像上方的区域如何不是凸集：</p>
<p><img alt="非凸函数" src="https://developers.google.cn/machine-learning/glossary/images/nonconvex_function.svg?hl=zh-CN" /></p>
<p>严格凸函数只有一个局部最低点，该点也是全局最低点。经典的 U 形函数都是严格凸函数。不过，有些凸函数（例如直线）则不是这样。</p>
<p>很多常见的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss_functions">损失函数</a>（包括下列函数）都是凸函数：</p>
<ul>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L2_loss"><script type="math/tex">L_2</script> 损失函数</a></li>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Log_Loss">对数损失函数</a></li>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L1_regularization"><script type="math/tex">L_1</script> 正则化</a></li>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L2_regularization"><script type="math/tex">L_2</script> 正则化</a></li>
</ul>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>的很多变体都一定能找到一个接近严格凸函数最小值的点。同样，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#SGD">随机梯度下降法</a>的很多变体都有很高的可能性能够找到接近严格凸函数最小值的点（但并非一定能找到）。</p>
<p>两个凸函数的和（例如 <script type="math/tex">L_2</script> 损失函数 + <script type="math/tex">L_1</script> 正则化）也是凸函数。</p>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#deep_model">深度模型</a>绝不会是凸函数。值得注意的是，专门针对<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convex_optimization">凸优化</a>设计的算法往往总能在深度网络上找到非常好的解决方案，虽然这些解决方案并不一定对应于全局最小值。</p>
<h3 id="416-convex-optimization"><a class="toclink" href="#416-convex-optimization">4.16. 凸优化 (convex optimization)</a><a class="headerlink" href="#416-convex-optimization" title="Permanent link">#</a></h3>
<p>使用数学方法（例如<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>）寻找<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convex_function">凸函数</a>最小值的过程。机器学习方面的大量研究都是专注于如何通过公式将各种问题表示成凸优化问题，以及如何更高效地解决这些问题。</p>
<p>如需完整的详细信息，请参阅 Boyd 和 Vandenberghe 合著的 <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex Optimization</a>（《凸优化》）。</p>
<h3 id="417-convex-set"><a class="toclink" href="#417-convex-set">4.17. 凸集 (convex set)</a><a class="headerlink" href="#417-convex-set" title="Permanent link">#</a></h3>
<p>欧几里得空间的一个子集，其中任意两点之间的连线仍完全落在该子集内。例如，下面的两个图形都是凸集：</p>
<p><img alt="矩形和半椭圆形都是凸集。" src="https://developers.google.cn/machine-learning/glossary/images/convex_set.png?hl=zh-CN" /></p>
<p>相反，下面的两个图形都不是凸集：</p>
<p><img alt="缺少一块的饼图以及烟花图都是非凸集。" src="https://developers.google.cn/machine-learning/glossary/images/nonconvex_set.png?hl=zh-CN" /></p>
<h3 id="418-convolution"><a class="toclink" href="#418-convolution">4.18. 卷积 (convolution)</a><a class="headerlink" href="#418-convolution" title="Permanent link">#</a></h3>
<p>简单来说，卷积在数学中指两个函数的组合。在机器学习中，卷积结合使用卷积过滤器和输入矩阵来训练权重。</p>
<p>机器学习中的"卷积"一词通常是<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_operation">卷积运算</a>或<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_layer">卷积层</a>的简称。</p>
<p>如果没有卷积，机器学习算法就需要学习大张量中每个单元格各自的权重。例如，用 2K x 2K 图像训练的机器学习算法将被迫找出 400 万个单独的权重。而使用卷积，机器学习算法只需在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_filter">卷积过滤器</a>中找出每个单元格的权重，大大减少了训练模型所需的内存。在应用卷积过滤器后，它只需跨单元格进行复制，每个单元格都会与过滤器相乘。</p>
<h3 id="419-convolutional-filter"><a class="toclink" href="#419-convolutional-filter">4.19. 卷积过滤器 (convolutional filter)</a><a class="headerlink" href="#419-convolutional-filter" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_operation">卷积运算</a>中的两个参与方之一。（另一个参与方是输入矩阵切片。）卷积过滤器是一种矩阵，其<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#rank">等级</a>与输入矩阵相同，但形状小一些。以 28×28 的输入矩阵为例，过滤器可以是小于 28×28 的任何二维矩阵。</p>
<p>在图形操作中，卷积过滤器中的所有单元格通常按照固定模式设置为 1 和 0。在机器学习中，卷积过滤器通常先选择随机数字，然后由网络训练出理想值。</p>
<h3 id="420-convolutional-layer"><a class="toclink" href="#420-convolutional-layer">4.20. 卷积层 (convolutional layer)</a><a class="headerlink" href="#420-convolutional-layer" title="Permanent link">#</a></h3>
<p>深度神经网络的一个层，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_filter">卷积过滤器</a>会在其中传递输入矩阵。以下面的 3x3 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_filter">卷积过滤器</a>为例：</p>
<p><img alt="卷积" src="https://developers.google.cn/machine-learning/glossary/images/ConvolutionalFilter33.svg?hl=zh-CN" /></p>
<p>下面的动画显示了一个由 9 个卷积运算（涉及 5x5 输入矩阵）组成的卷积层。请注意，每个卷积运算都涉及一个不同的 3x3 输入矩阵切片。由此产生的 3×3 矩阵（右侧）就包含 9 个卷积运算的结果：</p>
<p><img alt="卷积层" src="https://developers.google.cn/machine-learning/glossary/images/AnimatedConvolution.gif?hl=zh-CN" /></p>
<h3 id="421-convolutional-neural-network"><a class="toclink" href="#421-convolutional-neural-network">4.21. 卷积神经网络 (convolutional neural network)</a><a class="headerlink" href="#421-convolutional-neural-network" title="Permanent link">#</a></h3>
<p>一种神经网络，其中至少有一层为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_layer">卷积层</a>。典型的卷积神经网络包含以下几层的组合：</p>
<ul>
<li>卷积层</li>
<li>池化层</li>
<li>密集层</li>
</ul>
<p>卷积神经网络在解决某些类型的问题（如图像识别）上取得了巨大成功。</p>
<h3 id="422-convolutional-operation"><a class="toclink" href="#422-convolutional-operation">4.22. 卷积运算 (convolutional operation)</a><a class="headerlink" href="#422-convolutional-operation" title="Permanent link">#</a></h3>
<p>如下所示的两步数学运算：</p>
<ol>
<li>对<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_filter">卷积过滤器</a>和输入矩阵切片执行元素级乘法。（输入矩阵切片与卷积过滤器具有相同的等级和大小。）</li>
<li>对生成的积矩阵中的所有值求和。</li>
</ol>
<p>以下面的 5x5 输入矩阵为例：</p>
<p><img alt="输入矩阵" src="https://developers.google.cn/machine-learning/glossary/images/ConvolutionalLayerInputMatrix.svg?hl=zh-CN" /></p>
<p>现在，以下面这个 2x2 卷积过滤器为例：</p>
<p><img alt="卷积过滤器" src="https://developers.google.cn/machine-learning/glossary/images/ConvolutionalLayerFilter.svg?hl=zh-CN" /></p>
<p>每个卷积运算都涉及一个 2x2 输入矩阵切片。例如，假设我们使用输入矩阵左上角的 2x2 切片。这样一来，对此切片进行卷积运算将如下所示：</p>
<p><img alt="卷积运算" src="https://developers.google.cn/machine-learning/glossary/images/ConvolutionalLayerOperation.svg?hl=zh-CN" /></p>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_layer">卷积层</a>由一系列卷积运算组成，每个卷积运算都针对不同的输入矩阵切片。</p>
<h3 id="423-cost"><a class="toclink" href="#423-cost">4.23. 成本 (cost)</a><a class="headerlink" href="#423-cost" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>的含义相同。</p>
<h3 id="424-cross-entropy"><a class="toclink" href="#424-cross-entropy">4.24. 交叉熵 (cross-entropy)</a><a class="headerlink" href="#424-cross-entropy" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Log_Loss">对数损失函数</a>向<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#multi-class">多类别分类问题</a>的一种泛化。交叉熵可以量化两种概率分布之间的差异。另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#perplexity">困惑度</a>。</p>
<h3 id="425-estimator-custom-estimator"><a class="toclink" href="#425-estimator-custom-estimator">4.25. 自定义 Estimator (custom Estimator)</a><a class="headerlink" href="#425-estimator-custom-estimator" title="Permanent link">#</a></h3>
<p>您按照<a href="https://tensorflow.google.cn/extend/estimators?hl=zh-CN">这些说明</a>自行编写的 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Estimators">Estimator</a>。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#pre-made_Estimator">预创建的 Estimator</a> 相对。</p>
<h2 id="5-d"><a class="toclink" href="#5-d">5. D</a><a class="headerlink" href="#5-d" title="Permanent link">#</a></h2>
<h3 id="51-data-analysis"><a class="toclink" href="#51-data-analysis">5.1. 数据分析 (data analysis)</a><a class="headerlink" href="#51-data-analysis" title="Permanent link">#</a></h3>
<p>根据样本、测量结果和可视化内容来理解数据。数据分析在首次收到数据集、构建第一个模型之前特别有用。此外，数据分析在理解实验和调试系统问题方面也至关重要。</p>
<h3 id="52-dataframe"><a class="toclink" href="#52-dataframe">5.2. DataFrame</a><a class="headerlink" href="#52-dataframe" title="Permanent link">#</a></h3>
<p>一种热门的数据类型，用于表示 Pandas 中的数据集。DataFrame 类似于表格。DataFrame 的每一列都有一个名称（标题），每一行都由一个数字标识。</p>
<h3 id="53-data-set"><a class="toclink" href="#53-data-set">5.3. 数据集 (data set)</a><a class="headerlink" href="#53-data-set" title="Permanent link">#</a></h3>
<p>一组<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>的集合。</p>
<h3 id="54-dataset-api-tfdata"><a class="toclink" href="#54-dataset-api-tfdata">5.4. Dataset API (tf.data)</a><a class="headerlink" href="#54-dataset-api-tfdata" title="Permanent link">#</a></h3>
<p>一种高级别的 TensorFlow API，用于读取数据并将其转换为机器学习算法所需的格式。<code>tf.data.Dataset</code> 对象表示一系列元素，其中每个元素都包含一个或多个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tensor">张量</a>。<code>tf.data.Iterator</code> 对象可获取 <code>Dataset</code> 中的元素。</p>
<p>如需详细了解 Dataset API，请参阅《TensorFlow 编程人员指南》中的<a href="https://tensorflow.google.cn/programmers_guide/datasets?hl=zh-CN">导入数据</a>。</p>
<h3 id="55-decision-boundary"><a class="toclink" href="#55-decision-boundary">5.5. 决策边界 (decision boundary)</a><a class="headerlink" href="#55-decision-boundary" title="Permanent link">#</a></h3>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>或<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#multi-class">多类别分类问题</a>中，模型学到的类别之间的分界线。例如，在以下表示某个二元分类问题的图片中，决策边界是橙色类别和蓝色类别之间的分界线：</p>
<p><img alt="两种类别之间明确定义的边界。" src="https://developers.google.cn/machine-learning/glossary/images/decision_boundary.png?hl=zh-CN" /></p>
<h3 id="56-dense-layer"><a class="toclink" href="#56-dense-layer">5.6. 密集层 (dense layer)</a><a class="headerlink" href="#56-dense-layer" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#fully_connected_layer">全连接层</a>的含义相同。</p>
<h3 id="57-deep-model"><a class="toclink" href="#57-deep-model">5.7. 深度模型 (deep model)</a><a class="headerlink" href="#57-deep-model" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>，其中包含多个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hidden_layer">隐藏层</a>。深度模型依赖于可训练的非线性关系。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#wide_model">宽度模型</a>相对。</p>
<h3 id="58-dense-feature"><a class="toclink" href="#58-dense-feature">5.8. 密集特征 (dense feature)</a><a class="headerlink" href="#58-dense-feature" title="Permanent link">#</a></h3>
<p>一种大部分值是非零值的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>，通常是浮点值<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tensor">张量</a>。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sparse_features">稀疏特征</a>相对。</p>
<h3 id="59-device"><a class="toclink" href="#59-device">5.9. 设备 (device)</a><a class="headerlink" href="#59-device" title="Permanent link">#</a></h3>
<p>一类可运行 TensorFlow 会话的硬件，包括 CPU、GPU 和 TPU。</p>
<h3 id="510-discrete-feature"><a class="toclink" href="#510-discrete-feature">5.10. 离散特征 (discrete feature)</a><a class="headerlink" href="#510-discrete-feature" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>，包含有限个可能值。例如，某个值只能是"动物"、"蔬菜"或"矿物"的特征便是一个离散特征（或分类特征）。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#continuous_feature">连续特征</a>相对。</p>
<h3 id="511-dropout-regularization"><a class="toclink" href="#511-dropout-regularization">5.11. 丢弃正则化 (dropout regularization)</a><a class="headerlink" href="#511-dropout-regularization" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regularization">正则化</a>的一种形式，在训练<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>方面非常有用。丢弃正则化的运作机制是，在一个梯度步长中移除从神经网络层中随机选择的固定数量的单元。丢弃的单元越多，正则化效果就越强。这类似于训练神经网络以模拟较小网络的指数级规模集成学习。如需完整的详细信息，请参阅 <a href="http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a>（《丢弃：一种防止神经网络过拟合的简单方法》）。</p>
<h3 id="512-dynamic-model"><a class="toclink" href="#512-dynamic-model">5.12. 动态模型 (dynamic model)</a><a class="headerlink" href="#512-dynamic-model" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>，以持续更新的方式在线接受训练。也就是说，数据会源源不断地进入这种模型。</p>
<h2 id="6-e"><a class="toclink" href="#6-e">6. E</a><a class="headerlink" href="#6-e" title="Permanent link">#</a></h2>
<h3 id="61-early-stopping"><a class="toclink" href="#61-early-stopping">6.1. 早停法 (early stopping)</a><a class="headerlink" href="#61-early-stopping" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regularization">正则化</a>方法，是指在训练损失仍可以继续降低之前结束模型训练。使用早停法时，您会在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#validation_set">验证数据集</a>的损失开始增大（也就是<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#generalization">泛化</a>效果变差）时结束模型训练。</p>
<h3 id="62-embeddings"><a class="toclink" href="#62-embeddings">6.2. 嵌套 (embeddings)</a><a class="headerlink" href="#62-embeddings" title="Permanent link">#</a></h3>
<p>一种分类特征，以连续值特征表示。通常，嵌套是指将高维度向量映射到低维度的空间。例如，您可以采用以下两种方式之一来表示英文句子中的单词：</p>
<ul>
<li>表示成包含百万个元素（高维度）的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sparse_features">稀疏向量</a>，其中所有元素都是整数。向量中的每个单元格都表示一个单独的英文单词，单元格中的值表示相应单词在句子中出现的次数。由于单个英文句子包含的单词不太可能超过 50 个，因此向量中几乎每个单元格都包含 0。少数非 0 的单元格中将包含一个非常小的整数（通常为 1），该整数表示相应单词在句子中出现的次数。</li>
<li>表示成包含数百个元素（低维度）的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#dense_feature">密集向量</a>，其中每个元素都存储一个介于 0 到 1 之间的浮点值。这就是一种嵌套。</li>
</ul>
<p>在 TensorFlow 中，会按<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#backpropagation">反向传播</a><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>训练嵌套，和训练<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>中的任何其他参数一样。</p>
<h3 id="63-erm-empirical-risk-minimization"><a class="toclink" href="#63-erm-empirical-risk-minimization">6.3. 经验风险最小化 (ERM, empirical risk minimization)</a><a class="headerlink" href="#63-erm-empirical-risk-minimization" title="Permanent link">#</a></h3>
<p>用于选择可以将基于训练集的损失降至最低的函数。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#SRM">结构风险最小化</a>相对。</p>
<h3 id="64-ensemble"><a class="toclink" href="#64-ensemble">6.4. 集成学习 (ensemble)</a><a class="headerlink" href="#64-ensemble" title="Permanent link">#</a></h3>
<p>多个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>的预测结果的并集。您可以通过以下一项或多项来创建集成学习：</p>
<ul>
<li>不同的初始化</li>
<li>不同的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hyperparameter">超参数</a></li>
<li>不同的整体结构</li>
</ul>
<p><a href="https://tensorflow.google.cn/tutorials/wide_and_deep?hl=zh-CN">深度模型和宽度模型</a>属于一种集成学习。</p>
<h3 id="65-epoch"><a class="toclink" href="#65-epoch">6.5. 周期 (epoch)</a><a class="headerlink" href="#65-epoch" title="Permanent link">#</a></h3>
<p>在训练时，整个数据集的一次完整遍历，以便不漏掉任何一个样本。因此，一个周期表示（<code>N</code>/<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#batch_size">批次大小</a>）次训练<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#iteration">迭代</a>，其中 <code>N</code> 是样本总数。</p>
<h3 id="66-estimator"><a class="toclink" href="#66-estimator">6.6. Estimator</a><a class="headerlink" href="#66-estimator" title="Permanent link">#</a></h3>
<p><code>tf.Estimator</code> 类的一个实例，用于封装负责构建 TensorFlow 图并运行 TensorFlow 会话的逻辑。您可以创建<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#custom_estimator">自定义 Estimator</a>（如需相关介绍，请<a href="https://tensorflow.google.cn/extend/estimators?hl=zh-CN">点击此处</a>），也可以实例化其他人<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#pre-made_Estimator">预创建的 Estimator</a>。</p>
<h3 id="67-example"><a class="toclink" href="#67-example">6.7. 样本 (example)</a><a class="headerlink" href="#67-example" title="Permanent link">#</a></h3>
<p>数据集的一行。一个样本包含一个或多个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>，此外还可能包含一个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>。另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#labeled_example">有标签样本</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#unlabeled_example">无标签样本</a>。</p>
<h2 id="7-f"><a class="toclink" href="#7-f">7. F</a><a class="headerlink" href="#7-f" title="Permanent link">#</a></h2>
<h3 id="71-fn-false-negative"><a class="toclink" href="#71-fn-false-negative">7.1. 假负例 (FN, false negative)</a><a class="headerlink" href="#71-fn-false-negative" title="Permanent link">#</a></h3>
<p>被模型错误地预测为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#negative_class">负类别</a>的样本。例如，模型推断出某封电子邮件不是垃圾邮件（负类别），但该电子邮件其实是垃圾邮件。</p>
<h3 id="72-fp-false-positive"><a class="toclink" href="#72-fp-false-positive">7.2. 假正例 (FP, false positive)</a><a class="headerlink" href="#72-fp-false-positive" title="Permanent link">#</a></h3>
<p>被模型错误地预测为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#positive_class">正类别</a>的样本。例如，模型推断出某封电子邮件是垃圾邮件（正类别），但该电子邮件其实不是垃圾邮件。</p>
<h3 id="73-false-positive-rate-fp"><a class="toclink" href="#73-false-positive-rate-fp">7.3. 假正例率（false positive rate, 简称 FP 率）</a><a class="headerlink" href="#73-false-positive-rate-fp" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#ROC">ROC 曲线</a>中的 x 轴。FP 率的定义如下：</p>
<p>
<script type="math/tex; mode=display">
\text{假正例率} = \frac{\text{假正例数}}{\text{假正例数 + 负例数}}
</script>
</p>
<h3 id="74-feature"><a class="toclink" href="#74-feature">7.4. 特征 (feature)</a><a class="headerlink" href="#74-feature" title="Permanent link">#</a></h3>
<p>在进行<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#prediction">预测</a>时使用的输入变量。</p>
<h3 id="75-tffeature_column"><a class="toclink" href="#75-tffeature_column">7.5. 特征列 (tf.feature_column)</a><a class="headerlink" href="#75-tffeature_column" title="Permanent link">#</a></h3>
<p>指定模型应该如何解读特定特征的一种函数。此类函数的输出结果是所有 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Estimators">Estimators</a> 构造函数的必需参数。</p>
<p>借助 <code>tf.feature_column</code> 函数，模型可对输入特征的不同表示法轻松进行实验。有关详情，请参阅《TensorFlow 编程人员指南》中的<a href="https://tensorflow.google.cn/get_started/feature_columns?hl=zh-CN">特征列</a>一章。</p>
<p>"特征列"是 Google 专用的术语。特征列在 Yahoo/Microsoft 使用的 <a href="https://en.wikipedia.org/wiki/Vowpal_Wabbit">VW</a> 系统中称为"命名空间"，也称为<a href="https://www.csie.ntu.edu.tw/~cjlin/libffm/">场</a>。</p>
<h3 id="76-feature-cross"><a class="toclink" href="#76-feature-cross">7.6. 特征组合 (feature cross)</a><a class="headerlink" href="#76-feature-cross" title="Permanent link">#</a></h3>
<p>通过将单独的特征进行组合（求笛卡尔积）而形成的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#synthetic_feature">合成特征</a>。特征组合有助于表达非线性关系。</p>
<h3 id="77-feature-engineering"><a class="toclink" href="#77-feature-engineering">7.7. 特征工程 (feature engineering)</a><a class="headerlink" href="#77-feature-engineering" title="Permanent link">#</a></h3>
<p>指以下过程：确定哪些<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>可能在训练模型方面非常有用，然后将日志文件及其他来源的原始数据转换为所需的特征。在 TensorFlow 中，特征工程通常是指将原始日志文件条目转换为 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tf.Example">tf.Example</a> 协议缓冲区。另请参阅 <a href="https://github.com/tensorflow/transform">tf.Transform</a>。</p>
<p>特征工程有时称为特征提取。</p>
<h3 id="78-feature-set"><a class="toclink" href="#78-feature-set">7.8. 特征集 (feature set)</a><a class="headerlink" href="#78-feature-set" title="Permanent link">#</a></h3>
<p>训练机器学习模型时采用的一组<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>。例如，对于某个用于预测房价的模型，邮政编码、房屋面积以及房屋状况可以组成一个简单的特征集。</p>
<h3 id="79-feature-spec"><a class="toclink" href="#79-feature-spec">7.9. 特征规范 (feature spec)</a><a class="headerlink" href="#79-feature-spec" title="Permanent link">#</a></h3>
<p>用于描述如何从 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tf.Example">tf.Example</a> 协议缓冲区提取<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>数据。由于 tf.Example 协议缓冲区只是一个数据容器，因此您必须指定以下内容：</p>
<ul>
<li>要提取的数据（即特征的键）</li>
<li>数据类型（例如 float 或 int）</li>
<li>长度（固定或可变）</li>
</ul>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Estimators">Estimator API</a> 提供了一些可用来根据给定 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature_columns">FeatureColumns</a> 列表生成特征规范的工具。</p>
<h3 id="710-few-shot-learning"><a class="toclink" href="#710-few-shot-learning">7.10. 少量样本学习 (few-shot learning)</a><a class="headerlink" href="#710-few-shot-learning" title="Permanent link">#</a></h3>
<p>一种机器学习方法（通常用于对象分类），旨在仅通过少量训练样本学习有效的分类器。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#one-shot_learning">单样本学习</a>。</p>
<h3 id="711-softmax-full-softmax"><a class="toclink" href="#711-softmax-full-softmax">7.11. 完整 softmax (full softmax)</a><a class="headerlink" href="#711-softmax-full-softmax" title="Permanent link">#</a></h3>
<p>请参阅 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#softmax">softmax</a>。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#candidate_sampling">候选采样</a>相对。</p>
<h3 id="712-fully-connected-layer"><a class="toclink" href="#712-fully-connected-layer">7.12. 全连接层 (fully connected layer)</a><a class="headerlink" href="#712-fully-connected-layer" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hidden_layer">隐藏层</a>，其中的每个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#node">节点</a>均与下一个隐藏层中的每个节点相连。</p>
<p>全连接层又称为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#dense_layer">密集层</a>。</p>
<h2 id="8-g"><a class="toclink" href="#8-g">8. G</a><a class="headerlink" href="#8-g" title="Permanent link">#</a></h2>
<h3 id="81-generalization"><a class="toclink" href="#81-generalization">8.1. 泛化 (generalization)</a><a class="headerlink" href="#81-generalization" title="Permanent link">#</a></h3>
<p>指的是模型依据训练时采用的数据，针对以前未见过的新数据做出正确预测的能力。</p>
<h3 id="82-generalized-linear-model"><a class="toclink" href="#82-generalized-linear-model">8.2. 广义线性模型 (generalized linear model)</a><a class="headerlink" href="#82-generalized-linear-model" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#least_squares_regression">最小二乘回归</a>模型（基于<a href="https://en.wikipedia.org/wiki/Gaussian_noise">高斯噪声</a>）向其他类型的模型（基于其他类型的噪声，例如<a href="https://en.wikipedia.org/wiki/Shot_noise">泊松噪声</a>或分类噪声）进行的一种泛化。广义线性模型的示例包括：</p>
<ul>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#logistic_regression">逻辑回归</a></li>
<li>多类别回归</li>
<li>最小二乘回归</li>
</ul>
<p>可以通过<a href="https://en.wikipedia.org/wiki/Convex_optimization">凸优化</a>找到广义线性模型的参数。</p>
<p>广义线性模型具有以下特性：</p>
<ul>
<li>最优的最小二乘回归模型的平均预测结果等于训练数据的平均标签。</li>
<li>最优的逻辑回归模型预测的平均概率等于训练数据的平均标签。</li>
</ul>
<p>广义线性模型的功能受其特征的限制。与深度模型不同，广义线性模型无法"学习新特征"。</p>
<h3 id="83-gradient"><a class="toclink" href="#83-gradient">8.3. 梯度 (gradient)</a><a class="headerlink" href="#83-gradient" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#partial_derivative">偏导数</a>相对于所有自变量的向量。在机器学习中，梯度是模型函数偏导数的向量。梯度指向最高速上升的方向。</p>
<h3 id="84-gradient-clipping"><a class="toclink" href="#84-gradient-clipping">8.4. 梯度裁剪 (gradient clipping)</a><a class="headerlink" href="#84-gradient-clipping" title="Permanent link">#</a></h3>
<p>在应用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient">梯度</a>值之前先设置其上限。梯度裁剪有助于确保数值稳定性以及防止<a href="http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15%20Exploding%20and%20Vanishing%20Gradients.pdf">梯度爆炸</a>。</p>
<h3 id="85-gradient-descent"><a class="toclink" href="#85-gradient-descent">8.5. 梯度下降法 (gradient descent)</a><a class="headerlink" href="#85-gradient-descent" title="Permanent link">#</a></h3>
<p>一种通过计算并且减小梯度将<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>降至最低的技术，它以训练数据为条件，来计算损失相对于模型参数的梯度。通俗来说，梯度下降法以迭代方式调整参数，逐渐找到<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#weight">权重</a>和偏差的最佳组合，从而将损失降至最低。</p>
<h3 id="86-graph"><a class="toclink" href="#86-graph">8.6. 图 (graph)</a><a class="headerlink" href="#86-graph" title="Permanent link">#</a></h3>
<p>TensorFlow 中的一种计算规范。图中的节点表示操作。边缘具有方向，表示将某项操作的结果（一个<a href="https://tensorflow.google.cn/api_docs/python/tf/Tensor?hl=zh-CN">张量</a>）作为一个操作数传递给另一项操作。可以使用 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#TensorBoard">TensorBoard</a> 直观呈现图。</p>
<h2 id="9-h"><a class="toclink" href="#9-h">9. H</a><a class="headerlink" href="#9-h" title="Permanent link">#</a></h2>
<h3 id="91-heuristic"><a class="toclink" href="#91-heuristic">9.1. 启发法 (heuristic)</a><a class="headerlink" href="#91-heuristic" title="Permanent link">#</a></h3>
<p>一种非最优但实用的问题解决方案，足以用于进行改进或从中学习。</p>
<h3 id="92-hidden-layer"><a class="toclink" href="#92-hidden-layer">9.2. 隐藏层 (hidden layer)</a><a class="headerlink" href="#92-hidden-layer" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>中的合成层，介于<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#input_layer">输入层</a>（即特征）和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#output_layer">输出层</a>（即预测）之间。神经网络包含一个或多个隐藏层。</p>
<h3 id="93-hinge-loss"><a class="toclink" href="#93-hinge-loss">9.3. 合页损失函数 (hinge loss)</a><a class="headerlink" href="#93-hinge-loss" title="Permanent link">#</a></h3>
<p>一系列用于<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_model">分类</a>的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>函数，旨在找到距离每个训练样本都尽可能远的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#decision_boundary">决策边界</a>，从而使样本和边界之间的裕度最大化。<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#KSVMs">KSVM</a> 使用合页损失函数（或相关函数，例如平方合页损失函数）。对于二元分类，合页损失函数的定义如下：</p>
<p>
<script type="math/tex; mode=display">
loss = \max{(0, 1 - (y' * y))}
</script>
</p>
<p>其中"y'"表示分类器模型的原始输出：</p>
<p>
<script type="math/tex; mode=display">
y' = b + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
</script>
</p>
<p>"y"表示真标签，值为 -1 或 +1。</p>
<p>因此，合页损失与 (y * y') 的关系图如下所示：</p>
<p><img alt="合页损失函数" src="https://developers.google.cn/machine-learning/glossary/images/hinge-loss.svg?hl=zh-CN" /></p>
<h3 id="94-holdout-data"><a class="toclink" href="#94-holdout-data">9.4. 维持数据 (holdout data)</a><a class="headerlink" href="#94-holdout-data" title="Permanent link">#</a></h3>
<p>训练期间故意不使用（"维持"）的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>。<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#validation_set">验证数据集</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#test_set">测试数据集</a>都属于维持数据。维持数据有助于评估模型向训练时所用数据之外的数据进行泛化的能力。与基于训练数据集的损失相比，基于维持数据集的损失有助于更好地估算基于未见过的数据集的损失。</p>
<h3 id="95-hyperparameter"><a class="toclink" href="#95-hyperparameter">9.5. 超参数 (hyperparameter)</a><a class="headerlink" href="#95-hyperparameter" title="Permanent link">#</a></h3>
<p>在模型训练的连续过程中，您调节的"旋钮"。例如，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#learning_rate">学习速率</a>就是一种超参数。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#parameter">参数</a>相对。</p>
<h3 id="96-hyperplane"><a class="toclink" href="#96-hyperplane">9.6. 超平面 (hyperplane)</a><a class="headerlink" href="#96-hyperplane" title="Permanent link">#</a></h3>
<p>将一个空间划分为两个子空间的边界。例如，在二维空间中，直线就是一个超平面，在三维空间中，平面则是一个超平面。在机器学习中更典型的是：超平面是分隔高维度空间的边界。<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#KSVMs">核支持向量机</a>利用超平面将正类别和负类别区分开来（通常是在极高维度空间中）。</p>
<h2 id="10-i"><a class="toclink" href="#10-i">10. I</a><a class="headerlink" href="#10-i" title="Permanent link">#</a></h2>
<h3 id="101-iid-independently-and-identically-distributed"><a class="toclink" href="#101-iid-independently-and-identically-distributed">10.1. 独立同等分布 (i.i.d, independently and identically distributed)</a><a class="headerlink" href="#101-iid-independently-and-identically-distributed" title="Permanent link">#</a></h3>
<p>从不会改变的分布中提取的数据，其中提取的每个值都不依赖于之前提取的值。i.i.d. 是机器学习的<a href="https://en.wikipedia.org/wiki/Ideal_gas">理想气体</a> - 一种实用的数学结构，但在现实世界中几乎从未发现过。例如，某个网页的访问者在短时间内的分布可能为 i.i.d.，即分布在该短时间内没有变化，且一位用户的访问行为通常与另一位用户的访问行为无关。不过，如果将时间窗口扩大，网页访问者的分布可能呈现出季节性变化。</p>
<h3 id="102-inference"><a class="toclink" href="#102-inference">10.2. 推断 (inference)</a><a class="headerlink" href="#102-inference" title="Permanent link">#</a></h3>
<p>在机器学习中，推断通常指以下过程：通过将训练过的模型应用于<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#unlabeled_example">无标签样本</a>来做出预测。在统计学中，推断是指在某些观测数据条件下拟合分布参数的过程。（请参阅<a href="https://en.wikipedia.org/wiki/Statistical_inference">维基百科中有关统计学推断的文章</a>。）</p>
<h3 id="103-input-function"><a class="toclink" href="#103-input-function">10.3. 输入函数 (input function)</a><a class="headerlink" href="#103-input-function" title="Permanent link">#</a></h3>
<p>在 TensorFlow 中，用于将输入数据返回到 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Estimators">Estimator</a> 的训练、评估或预测方法的函数。例如，训练输入函数会返回<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#training_set">训练集</a>中的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#batch">一批</a>特征和标签。</p>
<h3 id="104-input-layer"><a class="toclink" href="#104-input-layer">10.4. 输入层 (input layer)</a><a class="headerlink" href="#104-input-layer" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>中的第一层（接收输入数据的层）。</p>
<h3 id="105-instance"><a class="toclink" href="#105-instance">10.5. 实例 (instance)</a><a class="headerlink" href="#105-instance" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>的含义相同。</p>
<h3 id="106-interpretability"><a class="toclink" href="#106-interpretability">10.6. 可解释性 (interpretability)</a><a class="headerlink" href="#106-interpretability" title="Permanent link">#</a></h3>
<p>模型的预测可解释的难易程度。深度模型通常不可解释，也就是说，很难对深度模型的不同层进行解释。相比之下，线性回归模型和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#wide_model">宽度模型</a>的可解释性通常要好得多。</p>
<h3 id="107-inter-rater-agreement"><a class="toclink" href="#107-inter-rater-agreement">10.7. 评分者间一致性信度 (inter-rater agreement)</a><a class="headerlink" href="#107-inter-rater-agreement" title="Permanent link">#</a></h3>
<p>一种衡量指标，用于衡量在执行某项任务时评分者达成一致的频率。如果评分者未达成一致，则可能需要改进任务说明。有时也称为注释者间一致性信度或评分者间可靠性信度。另请参阅 <a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen's kappa</a>（最热门的评分者间一致性信度衡量指标之一）。</p>
<h3 id="108-iteration"><a class="toclink" href="#108-iteration">10.8. 迭代 (iteration)</a><a class="headerlink" href="#108-iteration" title="Permanent link">#</a></h3>
<p>模型的权重在训练期间的一次更新。迭代包含计算参数在单<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#batch">批次</a>数据上的梯度损失。</p>
<h2 id="11-k"><a class="toclink" href="#11-k">11. K</a><a class="headerlink" href="#11-k" title="Permanent link">#</a></h2>
<h3 id="111-k-means"><a class="toclink" href="#111-k-means">11.1. k-means</a><a class="headerlink" href="#111-k-means" title="Permanent link">#</a></h3>
<p>一种热门的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#clustering">聚类</a>算法，用于对非监督式学习中的样本进行分组。k-means 算法基本上会执行以下操作：</p>
<ul>
<li>以迭代方式确定最佳的 k 中心点（称为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#centroid">形心</a>）。</li>
<li>将每个样本分配到最近的形心。与同一个形心距离最近的样本属于同一个组。</li>
</ul>
<p>k-means 算法会挑选形心位置，以最大限度地减小每个样本与其最接近形心之间的距离的累积平方。</p>
<p>以下面的小狗高度与小狗宽度的关系图为例：</p>
<p><img alt="关系图" src="https://developers.google.cn/machine-learning/glossary/images/DogDimensions.svg?hl=zh-CN" /></p>
<p>如果 k=3，则 k-means 算法会确定三个形心。每个样本都被分配到与其最接近的形心，最终产生三个组：</p>
<p><img alt="k-means" src="https://developers.google.cn/machine-learning/glossary/images/DogDimensionsKMeans.svg?hl=zh-CN" /></p>
<p>假设制造商想要确定小、中和大号狗毛衣的理想尺寸。在该聚类中，三个形心用于标识每只狗的平均高度和平均宽度。因此，制造商可能应该根据这三个形心确定毛衣尺寸。请注意，聚类的形心通常不是聚类中的样本。</p>
<p>上图显示了 k-means 应用于仅具有两个特征（高度和宽度）的样本。请注意，k-means 可以跨多个特征为样本分组。</p>
<h3 id="112-k-median"><a class="toclink" href="#112-k-median">11.2. k-median</a><a class="headerlink" href="#112-k-median" title="Permanent link">#</a></h3>
<p>与 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#k-means">k-means</a> 紧密相关的聚类算法。两者的实际区别如下：</p>
<ul>
<li>对于 k-means，确定形心的方法是，最大限度地减小候选形心与它的每个样本之间的距离平方和。</li>
<li>对于 k-median，确定形心的方法是，最大限度地减小候选形心与它的每个样本之间的距离总和。</li>
</ul>
<p>请注意，距离的定义也有所不同：</p>
<ul>
<li>k-means 采用从形心到样本的<a href="https://en.wikipedia.org/wiki/Euclidean_distance">欧几里得距离</a>。（在二维空间中，欧几里得距离即使用勾股定理来计算斜边。）例如，(2,2) 与 (5,-2) 之间的 k-means 距离为：</li>
</ul>
<p>
<script type="math/tex; mode=display">
\text{欧几里德距离} = \sqrt[]{(2 - 5)^2 + (2 - (-2))^2} = 5
</script>
</p>
<ul>
<li>k-median 采用从形心到样本的<a href="https://en.wikipedia.org/wiki/Taxicab_geometry">曼哈顿距离</a>。这个距离是每个维度中绝对差异值的总和。例如，(2,2) 与 (5,-2) 之间的 k-median 距离为：</li>
</ul>
<p>
<script type="math/tex; mode=display">
\text{曼哈顿距离} = |2 - 5| + |2 - (-2)| = 7
</script>
</p>
<h3 id="113-keras"><a class="toclink" href="#113-keras">11.3. Keras</a><a class="headerlink" href="#113-keras" title="Permanent link">#</a></h3>
<p>一种热门的 Python 机器学习 API。<a href="https://keras.io/">Keras</a> 能够在多种深度学习框架上运行，其中包括 TensorFlow（在该框架上，Keras 作为 <a href="https://tensorflow.google.cn/api_docs/python/tf/keras?hl=zh-CN">tf.keras</a> 提供）。</p>
<h3 id="114-ksvm-kernel-support-vector-machines"><a class="toclink" href="#114-ksvm-kernel-support-vector-machines">11.4. 核支持向量机 (KSVM, Kernel Support Vector Machines)</a><a class="headerlink" href="#114-ksvm-kernel-support-vector-machines" title="Permanent link">#</a></h3>
<p>一种分类算法，旨在通过将输入数据向量映射到更高维度的空间，来最大化<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#positive_class">正类别</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#negative_class">负类别</a>之间的裕度。以某个输入数据集包含一百个特征的分类问题为例。为了最大化正类别和负类别之间的裕度，KSVM 可以在内部将这些特征映射到百万维度的空间。KSVM 使用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hinge-loss">合页损失函数</a>。</p>
<h2 id="12-l"><a class="toclink" href="#12-l">12. L</a><a class="headerlink" href="#12-l" title="Permanent link">#</a></h2>
<h3 id="121-l_1-l_1-loss"><a class="toclink" href="#121-l_1-l_1-loss">12.1. <script type="math/tex">L_1</script> 损失函数 (<script type="math/tex">L_1</script> loss)</a><a class="headerlink" href="#121-l_1-l_1-loss" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>函数，基于模型预测的值与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的实际值之差的绝对值。与 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#squared_loss"><script type="math/tex">L_2</script> 损失函数</a>相比，<script type="math/tex">L_1</script> 损失函数对离群值的敏感性弱一些。</p>
<h3 id="122-l_1-l_1-regularization"><a class="toclink" href="#122-l_1-l_1-regularization">12.2. <script type="math/tex">L_1</script> 正则化 (<script type="math/tex">L_1</script> regularization)</a><a class="headerlink" href="#122-l_1-l_1-regularization" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regularization">正则化</a>，根据权重的绝对值的总和来惩罚权重。在依赖<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sparse_features">稀疏特征</a>的模型中，<script type="math/tex">L_1</script> 正则化有助于使不相关或几乎不相关的特征的权重正好为 0，从而将这些特征从模型中移除。与 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L2_regularization"><script type="math/tex">L_2</script> 正则化</a>相对。</p>
<h3 id="123-l_2-l_2-loss"><a class="toclink" href="#123-l_2-l_2-loss">12.3. <script type="math/tex">L_2</script> 损失函数 (<script type="math/tex">L_2</script> loss)</a><a class="headerlink" href="#123-l_2-l_2-loss" title="Permanent link">#</a></h3>
<p>请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#squared_loss">平方损失函数</a>。</p>
<h3 id="124-l_2-l_2-regularization"><a class="toclink" href="#124-l_2-l_2-regularization">12.4. <script type="math/tex">L_2</script> 正则化 (<script type="math/tex">L_2</script> regularization)</a><a class="headerlink" href="#124-l_2-l_2-regularization" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regularization">正则化</a>，根据权重的平方和来惩罚权重。<script type="math/tex">L_2</script> 正则化有助于使离群值（具有较大正值或较小负值）权重接近于 0，但又不正好为 0。（与 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L1_regularization">L1 正则化</a>相对。）在线性模型中，<script type="math/tex">L_2</script> 正则化始终可以改进泛化。</p>
<h3 id="125-label"><a class="toclink" href="#125-label">12.5. 标签 (label)</a><a class="headerlink" href="#125-label" title="Permanent link">#</a></h3>
<p>在监督式学习中，标签指<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>的"答案"或"结果"部分。有标签数据集中的每个样本都包含一个或多个特征以及一个标签。例如，在房屋数据集中，特征可能包括卧室数、卫生间数以及房龄，而标签则可能是房价。在垃圾邮件检测数据集中，特征可能包括主题行、发件人以及电子邮件本身，而标签则可能是"垃圾邮件"或"非垃圾邮件"。</p>
<h3 id="126-labeled-example"><a class="toclink" href="#126-labeled-example">12.6. 有标签样本 (labeled example)</a><a class="headerlink" href="#126-labeled-example" title="Permanent link">#</a></h3>
<p>包含<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的样本。在监督式训练中，模型从有标签样本中学习规律。</p>
<h3 id="127-lambda"><a class="toclink" href="#127-lambda">12.7. lambda</a><a class="headerlink" href="#127-lambda" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regularization_rate">正则化率</a>的含义相同。</p>
<p>（多含义术语，我们在此关注的是该术语在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regularization">正则化</a>中的定义。）</p>
<h3 id="128-layer"><a class="toclink" href="#128-layer">12.8. 层 (layer)</a><a class="headerlink" href="#128-layer" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>中的一组<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neuron">神经元</a>，负责处理一组输入特征，或一组神经元的输出。</p>
<p>此外还指 TensorFlow 中的抽象层。层是 Python 函数，以<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tensor">张量</a>和配置选项作为输入，然后生成其他张量作为输出。当必要的张量组合起来后，用户便可以通过<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model_function">模型函数</a>将结果转换为 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Estimators">Estimator</a>。</p>
<h3 id="129-layers-api-tflayers"><a class="toclink" href="#129-layers-api-tflayers">12.9. Layers API (tf.layers)</a><a class="headerlink" href="#129-layers-api-tflayers" title="Permanent link">#</a></h3>
<p>一种 TensorFlow API，用于以层组合的方式构建<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#deep_model">深度</a>神经网络。通过 Layers API，您可以构建不同类型的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#layer">层</a>，例如：</p>
<ul>
<li>通过 <code>tf.layers.Dense</code> 构建<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#fully_connected_layer">全连接层</a>。</li>
<li>通过 <code>tf.layers.Conv2D</code> 构建卷积层。</li>
</ul>
<p>在编写<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#custom_estimator">自定义 Estimator</a> 时，您可以编写"层"对象来定义所有<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hidden_layers">隐藏层</a>的特征。</p>
<p>Layers API 遵循 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Keras">Keras</a> layers API 规范。也就是说，除了前缀不同以外，Layers API 中的所有函数均与 Keras layers API 中的对应函数具有相同的名称和签名。</p>
<h3 id="1210-learning-rate"><a class="toclink" href="#1210-learning-rate">12.10. 学习速率 (learning rate)</a><a class="headerlink" href="#1210-learning-rate" title="Permanent link">#</a></h3>
<p>在训练模型时用于梯度下降的一个标量。在每次迭代期间，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>都会将学习速率与梯度相乘。得出的乘积称为梯度步长。</p>
<p>学习速率是一个重要的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hyperparameter">超参数</a>。</p>
<h3 id="1211-least-squares-regression"><a class="toclink" href="#1211-least-squares-regression">12.11. 最小二乘回归 (least squares regression)</a><a class="headerlink" href="#1211-least-squares-regression" title="Permanent link">#</a></h3>
<p>一种通过最小化 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L2_loss"><script type="math/tex">L_2</script> 损失</a>训练出的线性回归模型。</p>
<h3 id="1212-linear-regression"><a class="toclink" href="#1212-linear-regression">12.12. 线性回归 (linear regression)</a><a class="headerlink" href="#1212-linear-regression" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#regression_model">回归模型</a>，通过将输入特征进行线性组合输出连续值。</p>
<h3 id="1213-logistic-regression"><a class="toclink" href="#1213-logistic-regression">12.13. 逻辑回归 (logistic regression)</a><a class="headerlink" href="#1213-logistic-regression" title="Permanent link">#</a></h3>
<p>一种模型，通过将 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sigmoid_function">S 型函数</a>应用于线性预测，生成分类问题中每个可能的离散标签值的概率。虽然逻辑回归经常用于<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>问题，但也可用于<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#multi-class">多类别</a>分类问题（其叫法变为多类别逻辑回归或多项回归）。</p>
<h3 id="1214-logits"><a class="toclink" href="#1214-logits">12.14. 对数 (logits)</a><a class="headerlink" href="#1214-logits" title="Permanent link">#</a></h3>
<p>分类模型生成的原始（非标准化）预测向量，通常会传递给标准化函数。如果模型要解决多类别分类问题，则对数通常变成 <a href="https://tensorflow.google.cn/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2?hl=zh-CN">softmax 函数</a>的输入。之后，softmax 函数会生成一个（标准化）概率向量，对应于每个可能的类别。</p>
<p>此外，对数有时也称为 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sigmoid_function">S 型函数</a>的元素级反函数。如需了解详细信息，请参阅 <a href="https://tensorflow.google.cn/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits?hl=zh-CN">tf.nn.sigmoid_cross_entropy_with_logits</a>。</p>
<h3 id="1215-log-loss"><a class="toclink" href="#1215-log-loss">12.15. 对数损失函数 (Log Loss)</a><a class="headerlink" href="#1215-log-loss" title="Permanent link">#</a></h3>
<p>二元<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#logistic_regression">逻辑回归</a>中使用的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>函数。</p>
<h3 id="1216-log-odds"><a class="toclink" href="#1216-log-odds">12.16. 对数几率 (log-odds)</a><a class="headerlink" href="#1216-log-odds" title="Permanent link">#</a></h3>
<p>某个事件几率的对数。</p>
<p>如果事件涉及二元概率，则几率指的是成功概率 (p) 与失败概率 (1-p) 之比。例如，假设某个给定事件的成功概率为 90％，失败概率为 10％。在这种情况下，几率的计算公式如下：</p>
<p>
<script type="math/tex; mode=display">
\text{几率} = \frac{p}{(1- p)} = \frac{0.9}{0.1} = 9
</script>
</p>
<p>简单来说，对数几率即几率的对数。按照惯例，"对数"指自然对数，但对数的基数其实可以是任何大于 1 的数。若遵循惯例，上述示例的对数几率应为：</p>
<p>
<script type="math/tex; mode=display">
\text{对数几率} = \ln(9) = 2.2
</script>
</p>
<p>对数几率是 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sigmoid_function">S 型函数</a>的反函数。</p>
<h3 id="1217-loss"><a class="toclink" href="#1217-loss">12.17. 损失 (Loss)</a><a class="headerlink" href="#1217-loss" title="Permanent link">#</a></h3>
<p>一种衡量指标，用于衡量模型的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#prediction">预测</a>偏离其<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的程度。或者更悲观地说是衡量模型有多差。要确定此值，模型必须定义损失函数。例如，线性回归模型通常将<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#MSE">均方误差</a>用作损失函数，而逻辑回归模型则使用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Log_Loss">对数损失函数</a>。</p>
<h2 id="13-m"><a class="toclink" href="#13-m">13. M</a><a class="headerlink" href="#13-m" title="Permanent link">#</a></h2>
<h3 id="131-machine-learning"><a class="toclink" href="#131-machine-learning">13.1. 机器学习 (machine learning)</a><a class="headerlink" href="#131-machine-learning" title="Permanent link">#</a></h3>
<p>一种程序或系统，用于根据输入数据构建（训练）预测模型。这种系统会利用学到的模型根据从分布（训练该模型时使用的同一分布）中提取的新数据（以前从未见过的数据）进行实用的预测。机器学习还指与这些程序或系统相关的研究领域。</p>
<h3 id="132-mse-mean-squared-error"><a class="toclink" href="#132-mse-mean-squared-error">13.2. 均方误差 (MSE, Mean Squared Error)</a><a class="headerlink" href="#132-mse-mean-squared-error" title="Permanent link">#</a></h3>
<p>每个样本的平均平方损失。MSE 的计算方法是<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#squared_loss">平方损失</a>除以<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>数。<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#TensorFlow_Playground">TensorFlow Playground</a> 显示的"训练损失"值和"测试损失"值都是 MSE。</p>
<h3 id="133-metric"><a class="toclink" href="#133-metric">13.3. 指标 (metric)</a><a class="headerlink" href="#133-metric" title="Permanent link">#</a></h3>
<p>您关心的一个数值。可能可以也可能不可以直接在机器学习系统中得到优化。您的系统尝试优化的指标称为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#objective">目标</a>。</p>
<h3 id="134-metrics-api-tfmetrics"><a class="toclink" href="#134-metrics-api-tfmetrics">13.4. Metrics API (tf.metrics)</a><a class="headerlink" href="#134-metrics-api-tfmetrics" title="Permanent link">#</a></h3>
<p>一种用于评估模型的 TensorFlow API。例如，<code>tf.metrics.accuracy</code> 用于确定模型的预测与标签匹配的频率。在编写<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#custom_estimator">自定义 Estimator</a> 时，您可以调用 Metrics API 函数来指定应如何评估您的模型。</p>
<h3 id="135-mini-batch"><a class="toclink" href="#135-mini-batch">13.5. 小批次 (mini-batch)</a><a class="headerlink" href="#135-mini-batch" title="Permanent link">#</a></h3>
<p>从整批<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>内随机选择并在训练或推断过程的一次迭代中一起运行的一小部分样本。小批次的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#batch_size">批次大小</a>通常介于 10 到 1000 之间。与基于完整的训练数据计算损失相比，基于小批次数据计算损失要高效得多。</p>
<h3 id="136-sgd-mini-batch-stochastic-gradient-descent"><a class="toclink" href="#136-sgd-mini-batch-stochastic-gradient-descent">13.6. 小批次随机梯度下降法 (SGD, mini-batch stochastic gradient descent)</a><a class="headerlink" href="#136-sgd-mini-batch-stochastic-gradient-descent" title="Permanent link">#</a></h3>
<p>一种采用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#mini-batch">小批次</a>样本的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>。也就是说，小批次 SGD 会根据一小部分训练数据来估算梯度。<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#SGD">Vanilla SGD</a> 使用的小批次的大小为 1。</p>
<h3 id="137-ml"><a class="toclink" href="#137-ml">13.7. ML</a><a class="headerlink" href="#137-ml" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#machine_learning">机器学习</a>的缩写。</p>
<h3 id="138-model"><a class="toclink" href="#138-model">13.8. 模型 (model)</a><a class="headerlink" href="#138-model" title="Permanent link">#</a></h3>
<p>机器学习系统从训练数据学到的内容的表示形式。多含义术语，可以理解为下列两种相关含义之一：</p>
<ul>
<li>一种 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#TensorFlow">TensorFlow</a> 图，用于表示预测的计算结构。</li>
<li>该 TensorFlow 图的特定权重和偏差，通过<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model_training">训练</a>决定。</li>
</ul>
<h3 id="139-model-function"><a class="toclink" href="#139-model-function">13.9. 模型函数 (model function)</a><a class="headerlink" href="#139-model-function" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Estimators">Estimator</a> 中的函数，用于实现机器学习训练、评估和推断。例如，模型函数的训练部分可以处理以下任务：定义深度神经网络的拓扑并确定其<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#optimizer">优化器</a>函数。如果使用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#pre-made_Estimator">预创建的 Estimator</a>，则有人已为您编写了模型函数。如果使用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#custom_estimator">自定义 Estimator</a>，则必须自行编写模型函数。</p>
<p>有关编写模型函数的详细信息，请参阅<a href="https://tensorflow.google.cn/get_started/custom_estimators?hl=zh-CN">创建自定义 Estimator</a>。</p>
<h3 id="1310-model-training"><a class="toclink" href="#1310-model-training">13.10. 模型训练 (model training)</a><a class="headerlink" href="#1310-model-training" title="Permanent link">#</a></h3>
<p>确定最佳<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>的过程。</p>
<h3 id="1311-momentum"><a class="toclink" href="#1311-momentum">13.11. 动量 (Momentum)</a><a class="headerlink" href="#1311-momentum" title="Permanent link">#</a></h3>
<p>一种先进的梯度下降法，其中学习步长不仅取决于当前步长的导数，还取决于之前一步或多步的步长的导数。动量涉及计算梯度随时间而变化的指数级加权移动平均值，与物理学中的动量类似。动量有时可以防止学习过程被卡在局部最小的情况。</p>
<h3 id="1312-multi-class-classification"><a class="toclink" href="#1312-multi-class-classification">13.12. 多类别分类 (multi-class classification)</a><a class="headerlink" href="#1312-multi-class-classification" title="Permanent link">#</a></h3>
<p>区分两种以上类别的分类问题。例如，枫树大约有 128 种，因此，确定枫树种类的模型就属于多类别模型。反之，仅将电子邮件分为两类（"垃圾邮件"和"非垃圾邮件"）的模型属于<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类模型</a>。</p>
<h3 id="1313-multinomial-classification"><a class="toclink" href="#1313-multinomial-classification">13.13. 多项分类 (multinomial classification)</a><a class="headerlink" href="#1313-multinomial-classification" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#multi-class">多类别分类</a>的含义相同。</p>
<h2 id="14-n"><a class="toclink" href="#14-n">14. N</a><a class="headerlink" href="#14-n" title="Permanent link">#</a></h2>
<h3 id="141-nan-nan-trap"><a class="toclink" href="#141-nan-nan-trap">14.1. NaN 陷阱 (NaN trap)</a><a class="headerlink" href="#141-nan-nan-trap" title="Permanent link">#</a></h3>
<p>模型中的一个数字在训练期间变成 <a href="https://en.wikipedia.org/wiki/NaN">NaN</a>，这会导致模型中的很多或所有其他数字最终也会变成 NaN。</p>
<p>NaN 是"非数字"的缩写。</p>
<h3 id="142-negative-class"><a class="toclink" href="#142-negative-class">14.2. 负类别 (negative class)</a><a class="headerlink" href="#142-negative-class" title="Permanent link">#</a></h3>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>中，一种类别称为正类别，另一种类别称为负类别。正类别是我们要寻找的类别，负类别则是另一种可能性。例如，在医学检查中，负类别可以是"非肿瘤"。在电子邮件分类器中，负类别可以是"非垃圾邮件"。另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#positive_class">正类别</a>。</p>
<h3 id="143-neural-network"><a class="toclink" href="#143-neural-network">14.3. 神经网络 (neural network)</a><a class="headerlink" href="#143-neural-network" title="Permanent link">#</a></h3>
<p>一种模型，灵感来源于脑部结构，由多个层构成（至少有一个是<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hidden_layer">隐藏层</a>），每个层都包含简单相连的单元或<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neuron">神经元</a>（具有非线性关系）。</p>
<h3 id="144-neuron"><a class="toclink" href="#144-neuron">14.4. 神经元 (neuron)</a><a class="headerlink" href="#144-neuron" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>中的节点，通常会接收多个输入值并生成一个输出值。神经元通过将<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#activation_function">激活函数</a>（非线性转换）应用于输入值的加权和来计算输出值。</p>
<h3 id="145-node"><a class="toclink" href="#145-node">14.5. 节点 (node)</a><a class="headerlink" href="#145-node" title="Permanent link">#</a></h3>
<p>多含义术语，可以理解为下列两种含义之一：</p>
<ul>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hidden_layer">隐藏层</a>中的神经元。</li>
<li>TensorFlow <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#graph">图</a>中的操作。</li>
</ul>
<h3 id="146-normalization"><a class="toclink" href="#146-normalization">14.6. 标准化 (normalization)</a><a class="headerlink" href="#146-normalization" title="Permanent link">#</a></h3>
<p>将实际的值区间转换为标准的值区间（通常为 -1 到 +1 或 0 到 1）的过程。例如，假设某个特征的自然区间是 800 到 6000。通过减法和除法运算，您可以将这些值标准化为位于 -1 到 +1 区间内。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#scaling">缩放</a>。</p>
<h3 id="147-numerical-data"><a class="toclink" href="#147-numerical-data">14.7. 数值数据 (numerical data)</a><a class="headerlink" href="#147-numerical-data" title="Permanent link">#</a></h3>
<p>用整数或实数表示的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>。例如，在房地产模型中，您可能会用数值数据表示房子大小（以平方英尺或平方米为单位）。如果用数值数据表示特征，则可以表明特征的值相互之间具有数学关系，并且与标签可能也有数学关系。例如，如果用数值数据表示房子大小，则可以表明面积为 200 平方米的房子是面积为 100 平方米的房子的两倍。此外，房子面积的平方米数可能与房价存在一定的数学关系。</p>
<p>并非所有整数数据都应表示成数值数据。例如，世界上某些地区的邮政编码是整数，但在模型中，不应将整数邮政编码表示成数值数据。这是因为邮政编码 <code>20000</code> 在效力上并不是邮政编码 10000 的两倍（或一半）。此外，虽然不同的邮政编码确实与不同的房地产价值有关，但我们也不能假设邮政编码为 20000 的房地产在价值上是邮政编码为 10000 的房地产的两倍。邮政编码应表示成<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#categorical_data">分类数据</a>。</p>
<p>数值特征有时称为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#continuous_feature">连续特征</a>。</p>
<h3 id="148-numpy"><a class="toclink" href="#148-numpy">14.8. Numpy</a><a class="headerlink" href="#148-numpy" title="Permanent link">#</a></h3>
<p>一个<a href="http://www.numpy.org/">开放源代码数学库</a>，在 Python 中提供高效的数组操作。<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#pandas">Pandas</a> 建立在 Numpy 之上。</p>
<h2 id="15-o"><a class="toclink" href="#15-o">15. O</a><a class="headerlink" href="#15-o" title="Permanent link">#</a></h2>
<h3 id="151-objective"><a class="toclink" href="#151-objective">15.1. 目标 (objective)</a><a class="headerlink" href="#151-objective" title="Permanent link">#</a></h3>
<p>算法尝试优化的指标。</p>
<h3 id="152-offline-inference"><a class="toclink" href="#152-offline-inference">15.2. 离线推断 (offline inference)</a><a class="headerlink" href="#152-offline-inference" title="Permanent link">#</a></h3>
<p>生成一组<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#prediction">预测</a>，存储这些预测，然后根据需求检索这些预测。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#online_inference">在线推断</a>相对。</p>
<h3 id="153-one-hot-encoding"><a class="toclink" href="#153-one-hot-encoding">15.3. 独热编码 (one-hot encoding)</a><a class="headerlink" href="#153-one-hot-encoding" title="Permanent link">#</a></h3>
<p>一种稀疏向量，其中：</p>
<ul>
<li>一个元素设为 1。</li>
<li>所有其他元素均设为 0。</li>
</ul>
<p>独热编码常用于表示拥有有限个可能值的字符串或标识符。例如，假设某个指定的植物学数据集记录了 15000 个不同的物种，其中每个物种都用独一无二的字符串标识符来表示。在特征工程过程中，您可能需要将这些字符串标识符编码为独热向量，向量的大小为 15000。</p>
<h3 id="154-one-shot-learning"><a class="toclink" href="#154-one-shot-learning">15.4. 单样本学习（one-shot learning，通常用于对象分类）</a><a class="headerlink" href="#154-one-shot-learning" title="Permanent link">#</a></h3>
<p>一种机器学习方法，通常用于对象分类，旨在通过单个训练样本学习有效的分类器。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#few-shot_learning">少量样本学习</a>。</p>
<h3 id="155-one-vs-all"><a class="toclink" href="#155-one-vs-all">15.5. 一对多 (one-vs.-all)</a><a class="headerlink" href="#155-one-vs-all" title="Permanent link">#</a></h3>
<p>假设某个分类问题有 N 种可能的解决方案，一对多解决方案将包含 N 个单独的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类器</a> - 一个二元分类器对应一种可能的结果。例如，假设某个模型用于区分样本属于动物、蔬菜还是矿物，一对多解决方案将提供下列三个单独的二元分类器：</p>
<ul>
<li>动物和非动物</li>
<li>蔬菜和非蔬菜</li>
<li>矿物和非矿物</li>
</ul>
<h3 id="156-online-inference"><a class="toclink" href="#156-online-inference">15.6. 在线推断 (online inference)</a><a class="headerlink" href="#156-online-inference" title="Permanent link">#</a></h3>
<p>根据需求生成<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#prediction">预测</a>。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#offline_inference">离线推断</a>相对。</p>
<h3 id="157-op-operation"><a class="toclink" href="#157-op-operation">15.7. 操作 (op, Operation)</a><a class="headerlink" href="#157-op-operation" title="Permanent link">#</a></h3>
<p>TensorFlow 图中的节点。在 TensorFlow 中，任何创建、操纵或销毁<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tensor">张量</a>的过程都属于操作。例如，矩阵相乘就是一种操作，该操作以两个张量作为输入，并生成一个张量作为输出。</p>
<h3 id="158-optimizer"><a class="toclink" href="#158-optimizer">15.8. 优化器 (optimizer)</a><a class="headerlink" href="#158-optimizer" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>的一种具体实现。TensorFlow 的优化器基类是 <a href="https://tensorflow.google.cn/api_docs/python/tf/train/Optimizer?hl=zh-CN">tf.train.Optimizer</a>。不同的优化器可能会利用以下一个或多个概念来增强梯度下降法在指定<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#training_set">训练集</a>中的效果：</p>
<ul>
<li><a href="https://tensorflow.google.cn/api_docs/python/tf/train/MomentumOptimizer?hl=zh-CN">动量</a> (Momentum)</li>
<li>更新频率（<a href="https://tensorflow.google.cn/api_docs/python/tf/train/AdagradOptimizer?hl=zh-CN">AdaGrad</a> = ADAptive GRADient descent；<a href="https://tensorflow.google.cn/api_docs/python/tf/train/AdamOptimizer?hl=zh-CN">Adam</a> = ADAptive with Momentum；RMSProp）</li>
<li>稀疏性/正则化 (<a href="https://tensorflow.google.cn/api_docs/python/tf/train/FtrlOptimizer?hl=zh-CN">Ftrl</a>)</li>
<li>更复杂的数学方法（<a href="https://tensorflow.google.cn/api_docs/python/tf/train/ProximalGradientDescentOptimizer?hl=zh-CN">Proximal</a>，等等）</li>
</ul>
<p>甚至还包括 <a href="https://arxiv.org/abs/1606.04474">NN 驱动的优化器</a>。</p>
<h3 id="159-outlier"><a class="toclink" href="#159-outlier">15.9. 离群值 (outlier)</a><a class="headerlink" href="#159-outlier" title="Permanent link">#</a></h3>
<p>与大多数其他值差别很大的值。在机器学习中，下列所有值都是离群值。</p>
<ul>
<li>绝对值很高的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#weight">权重</a>。</li>
<li>与实际值相差很大的预测值。</li>
<li>值比平均值高大约 3 个标准偏差的输入数据。</li>
</ul>
<p>离群值常常会导致模型训练出现问题。</p>
<h3 id="1510-output-layer"><a class="toclink" href="#1510-output-layer">15.10. 输出层 (output layer)</a><a class="headerlink" href="#1510-output-layer" title="Permanent link">#</a></h3>
<p>神经网络的"最后"一层，也是包含答案的层。</p>
<h3 id="1511-overfitting"><a class="toclink" href="#1511-overfitting">15.11. 过拟合 (overfitting)</a><a class="headerlink" href="#1511-overfitting" title="Permanent link">#</a></h3>
<p>创建的模型与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#training_set">训练数据</a>过于匹配，以致于模型无法根据新数据做出正确的预测。</p>
<h2 id="16-p"><a class="toclink" href="#16-p">16. P</a><a class="headerlink" href="#16-p" title="Permanent link">#</a></h2>
<h3 id="161-pandas"><a class="toclink" href="#161-pandas">16.1. Pandas</a><a class="headerlink" href="#161-pandas" title="Permanent link">#</a></h3>
<p>面向列的数据分析 API。很多机器学习框架（包括 TensorFlow）都支持将 Pandas 数据结构作为输入。请参阅 <a href="http://pandas.pydata.org/">Pandas 文档</a>。</p>
<h3 id="162-parameter"><a class="toclink" href="#162-parameter">16.2. 参数 (parameter)</a><a class="headerlink" href="#162-parameter" title="Permanent link">#</a></h3>
<p>机器学习系统自行训练的模型的变量。例如，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#weight">权重</a>就是一种参数，它们的值是机器学习系统通过连续的训练迭代逐渐学习到的。与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hyperparameter">超参数</a>相对。</p>
<h3 id="163-ps-parameter-server"><a class="toclink" href="#163-ps-parameter-server">16.3. 参数服务器 (PS, Parameter Server)</a><a class="headerlink" href="#163-ps-parameter-server" title="Permanent link">#</a></h3>
<p>一种作业，负责在分布式设置中跟踪模型<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#parameter">参数</a>。</p>
<h3 id="164-parameter-update"><a class="toclink" href="#164-parameter-update">16.4. 参数更新 (parameter update)</a><a class="headerlink" href="#164-parameter-update" title="Permanent link">#</a></h3>
<p>在训练期间（通常是在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>的单次迭代中）调整模型<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#parameter">参数</a>的操作。</p>
<h3 id="165-partial-derivative"><a class="toclink" href="#165-partial-derivative">16.5. 偏导数 (partial derivative)</a><a class="headerlink" href="#165-partial-derivative" title="Permanent link">#</a></h3>
<p>一种导数，除一个变量之外的所有变量都被视为常量。例如，f(x, y) 对 x 的偏导数就是 f(x) 的导数（即，使 y 保持恒定）。f 对 x 的偏导数仅关注 x 如何变化，而忽略公式中的所有其他变量。</p>
<h3 id="166-partitioning-strategy"><a class="toclink" href="#166-partitioning-strategy">16.6. 划分策略 (partitioning strategy)</a><a class="headerlink" href="#166-partitioning-strategy" title="Permanent link">#</a></h3>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Parameter_Server">参数服务器</a>间分割变量的算法。</p>
<h3 id="167-performance"><a class="toclink" href="#167-performance">16.7. 性能 (performance)</a><a class="headerlink" href="#167-performance" title="Permanent link">#</a></h3>
<p>多含义术语，具有以下含义：</p>
<ul>
<li>在软件工程中的传统含义。即：相应软件的运行速度有多快（或有多高效）？</li>
<li>在机器学习中的含义。在机器学习领域，性能旨在回答以下问题：相应<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>的准确度有多高？即模型在预测方面的表现有多好？</li>
</ul>
<h3 id="168-perplexity"><a class="toclink" href="#168-perplexity">16.8. 困惑度 (perplexity)</a><a class="headerlink" href="#168-perplexity" title="Permanent link">#</a></h3>
<p>一种衡量指标，用于衡量<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>能够多好地完成任务。例如，假设任务是读取用户使用智能手机键盘输入字词时输入的前几个字母，然后列出一组可能的完整字词。此任务的困惑度 (P) 是：为了使列出的字词中包含用户尝试输入的实际字词，您需要提供的猜测项的个数。</p>
<p>困惑度与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#cross-entropy">交叉熵</a>的关系如下：</p>
<p>
<script type="math/tex; mode=display">
p = 2^{-\text{交叉熵}}
</script>
</p>
<h3 id="169-pipeline"><a class="toclink" href="#169-pipeline">16.9. 流水线 (pipeline)</a><a class="headerlink" href="#169-pipeline" title="Permanent link">#</a></h3>
<p>机器学习算法的基础架构。流水线包括收集数据、将数据放入训练数据文件、训练一个或多个模型，以及将模型导出到生产环境。</p>
<h3 id="1610-pooling"><a class="toclink" href="#1610-pooling">16.10. 池化 (pooling)</a><a class="headerlink" href="#1610-pooling" title="Permanent link">#</a></h3>
<p>将一个或多个由前趋的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#convolutional_layer">卷积层</a>创建的矩阵压缩为较小的矩阵。池化通常是取整个池化区域的最大值或平均值。以下面的 3x3 矩阵为例：</p>
<p><img alt="矩阵" src="https://developers.google.cn/machine-learning/glossary/images/PoolingStart.svg?hl=zh-CN" /></p>
<p>池化运算与卷积运算类似：将矩阵分割为多个切片，然后按<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#stride">步长</a>逐个运行卷积运算。例如，假设池化运算按 1x1 步长将卷积矩阵分割为 2x2 个切片。如下图所示，进行了四个池化运算。假设每个池化运算都选择该切片中四个值的最大值：</p>
<p><img alt="池化" src="https://developers.google.cn/machine-learning/glossary/images/PoolingConvolution.svg?hl=zh-CN" /></p>
<p>池化有助于在输入矩阵中实现<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#translational_invariance">平移不变性</a>。</p>
<p>对于视觉应用来说，池化的更正式名称为空间池化。时间序列应用通常将池化称为时序池化。按照不太正式的说法，池化通常称为下采样或降采样。</p>
<h3 id="1611-positive-class"><a class="toclink" href="#1611-positive-class">16.11. 正类别 (positive class)</a><a class="headerlink" href="#1611-positive-class" title="Permanent link">#</a></h3>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#binary_classification">二元分类</a>中，两种可能的类别分别被标记为正类别和负类别。正类别结果是我们要测试的对象。（不可否认的是，我们会同时测试这两种结果，但只关注正类别结果。）例如，在医学检查中，正类别可以是"肿瘤"。在电子邮件分类器中，正类别可以是"垃圾邮件"。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#negative_class">负类别</a>相对。</p>
<h3 id="1612-precision"><a class="toclink" href="#1612-precision">16.12. 精确率 (precision)</a><a class="headerlink" href="#1612-precision" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_model">分类模型</a>指标。精确率指模型正确预测<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#positive_class">正类别</a>的频率，即：</p>
<p>
<script type="math/tex; mode=display">
\text{精确率} = \frac{正例数}{正例数 + 假正例数}
</script>
</p>
<h3 id="1613-prediction"><a class="toclink" href="#1613-prediction">16.13. 预测 (prediction)</a><a class="headerlink" href="#1613-prediction" title="Permanent link">#</a></h3>
<p>模型在收到输入<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>后的输出。</p>
<h3 id="1614-prediction-bias"><a class="toclink" href="#1614-prediction-bias">16.14. 预测偏差 (prediction bias)</a><a class="headerlink" href="#1614-prediction-bias" title="Permanent link">#</a></h3>
<p>一种值，用于表明<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#prediction">预测</a>平均值与数据集中<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的平均值相差有多大。</p>
<h3 id="1615-estimator-pre-made-estimator"><a class="toclink" href="#1615-estimator-pre-made-estimator">16.15. 预创建的 Estimator (pre-made Estimator)</a><a class="headerlink" href="#1615-estimator-pre-made-estimator" title="Permanent link">#</a></h3>
<p>其他人已建好的 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Estimator">Estimator</a>。TensorFlow 提供了一些预创建的 Estimator，包括 <code>DNNClassifier</code>、<code>DNNRegressor</code> 和 <code>LinearClassifier</code>。您可以按照<a href="https://tensorflow.google.cn/extend/estimators?hl=zh-CN">这些说明</a>构建自己预创建的 Estimator。</p>
<h3 id="1616-pre-trained-model"><a class="toclink" href="#1616-pre-trained-model">16.16. 预训练模型 (pre-trained model)</a><a class="headerlink" href="#1616-pre-trained-model" title="Permanent link">#</a></h3>
<p>已经过训练的模型或模型组件（例如<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#embeddings">嵌套</a>）。有时，您需要将预训练的嵌套馈送到<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>。在其他时候，您的模型将自行训练嵌套，而不依赖于预训练的嵌套。</p>
<h3 id="1617-prior-belief"><a class="toclink" href="#1617-prior-belief">16.17. 先验信念 (prior belief)</a><a class="headerlink" href="#1617-prior-belief" title="Permanent link">#</a></h3>
<p>在开始采用相应数据进行训练之前，您对这些数据抱有的信念。例如，<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L2_regularization"><script type="math/tex">L_2</script> 正则化</a>依赖的先验信念是<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#weight">权重</a>应该很小且应以 0 为中心呈正态分布。</p>
<h2 id="17-q"><a class="toclink" href="#17-q">17. Q</a><a class="headerlink" href="#17-q" title="Permanent link">#</a></h2>
<h3 id="171-queue"><a class="toclink" href="#171-queue">17.1. 队列 (queue)</a><a class="headerlink" href="#171-queue" title="Permanent link">#</a></h3>
<p>一种 TensorFlow <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#Operation">操作</a>，用于实现队列数据结构。通常用于 I/O 中。</p>
<h2 id="18-r"><a class="toclink" href="#18-r">18. R</a><a class="headerlink" href="#18-r" title="Permanent link">#</a></h2>
<h3 id="181-rank"><a class="toclink" href="#181-rank">18.1. 等级 (rank)</a><a class="headerlink" href="#181-rank" title="Permanent link">#</a></h3>
<p>机器学习中的一个多含义术语，可以理解为下列含义之一：</p>
<ul>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tensor">张量</a>中的维数。例如，标量等级为 0，向量等级为 1，矩阵等级为 2。</li>
<li>在将类别从最高到最低进行排序的机器学习问题中，类别的顺序位置。例如，行为排序系统可以将狗狗的奖励从最高（牛排）到最低（枯萎的羽衣甘蓝）进行排序。</li>
</ul>
<h3 id="182-rater"><a class="toclink" href="#182-rater">18.2. 评分者 (rater)</a><a class="headerlink" href="#182-rater" title="Permanent link">#</a></h3>
<p>为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>提供<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的人。有时称为"注释者"。</p>
<h3 id="183-recall"><a class="toclink" href="#183-recall">18.3. 召回率 (recall)</a><a class="headerlink" href="#183-recall" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_model">分类模型</a>指标，用于回答以下问题：在所有可能的正类别标签中，模型正确地识别出了多少个？即：</p>
<p>
<script type="math/tex; mode=display">
\text{召回率} = \frac{正例数}{正例数 + 假负例数}
</script>
</p>
<h3 id="184-relu-rectified-linear-unit"><a class="toclink" href="#184-relu-rectified-linear-unit">18.4. 修正线性单元 (ReLU, Rectified Linear Unit)</a><a class="headerlink" href="#184-relu-rectified-linear-unit" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#activation_function">激活函数</a>，其规则如下：</p>
<ul>
<li>如果输入为负数或 0，则输出 0。</li>
<li>如果输入为正数，则输出等于输入。</li>
</ul>
<h3 id="185-regression-model"><a class="toclink" href="#185-regression-model">18.5. 回归模型 (regression model)</a><a class="headerlink" href="#185-regression-model" title="Permanent link">#</a></h3>
<p>一种模型，能够输出连续的值（通常为浮点值）。请与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_model">分类模型</a>进行比较，分类模型会输出离散值，例如"黄花菜"或"虎皮百合"。</p>
<h3 id="186-regularization"><a class="toclink" href="#186-regularization">18.6. 正则化 (regularization)</a><a class="headerlink" href="#186-regularization" title="Permanent link">#</a></h3>
<p>对模型复杂度的惩罚。正则化有助于防止出现<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#overfitting">过拟合</a>，包含以下类型：</p>
<ul>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L1_regularization"><script type="math/tex">L_1</script> 正则化</a></li>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L2_regularization"><script type="math/tex">L_2</script> 正则化</a></li>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#dropout_regularization">丢弃正则化</a></li>
<li><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#early_stopping">早停法</a>（这不是正式的正则化方法，但可以有效限制过拟合）</li>
</ul>
<h3 id="187-regularization-rate"><a class="toclink" href="#187-regularization-rate">18.7. 正则化率 (regularization rate)</a><a class="headerlink" href="#187-regularization-rate" title="Permanent link">#</a></h3>
<p>一种标量值，以 lambda 表示，用于指定正则化函数的相对重要性。从下面简化的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>公式中可以看出正则化率的影响：</p>
<p>
<script type="math/tex; mode=display">
\min(\text{损失方程} + \lambda \text{正则化方程})
</script>
</p>
<p>提高正则化率可以减少<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#overfitting">过拟合</a>，但可能会使模型的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#accuracy">准确率</a>降低。</p>
<h3 id="188-representation"><a class="toclink" href="#188-representation">18.8. 表示法 (representation)</a><a class="headerlink" href="#188-representation" title="Permanent link">#</a></h3>
<p>将数据映射到实用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>的过程。</p>
<h3 id="189-receiver-operating-characteristic-roc"><a class="toclink" href="#189-receiver-operating-characteristic-roc">18.9. 受试者工作特征曲线（receiver operating characteristic，简称 ROC 曲线）</a><a class="headerlink" href="#189-receiver-operating-characteristic-roc" title="Permanent link">#</a></h3>
<p>不同<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#classification_threshold">分类阈值</a>下的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#TP_rate">正例率</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#FP_rate">假正例率</a>构成的曲线。另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#AUC">曲线下面积</a>。</p>
<h3 id="1810-root-directory"><a class="toclink" href="#1810-root-directory">18.10. 根目录 (root directory)</a><a class="headerlink" href="#1810-root-directory" title="Permanent link">#</a></h3>
<p>您指定的目录，用于托管多个模型的 TensorFlow 检查点和事件文件的子目录。</p>
<h3 id="1811-rmse-root-mean-squared-error"><a class="toclink" href="#1811-rmse-root-mean-squared-error">18.11. 均方根误差 (RMSE, Root Mean Squared Error)</a><a class="headerlink" href="#1811-rmse-root-mean-squared-error" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#MSE">均方误差</a>的平方根。</p>
<h3 id="1812-rotational-invariance"><a class="toclink" href="#1812-rotational-invariance">18.12. 旋转不变性 (rotational invariance)</a><a class="headerlink" href="#1812-rotational-invariance" title="Permanent link">#</a></h3>
<p>在图像分类问题中，即使图像的方向发生变化，算法也能成功地对图像进行分类。例如，无论网球拍朝上、侧向还是朝下放置，该算法仍然可以识别它。请注意，并非总是希望旋转不变；例如，倒置的"9"不应分类为"9"。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#translational_invariance">平移不变性</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#size_invariance">大小不变性</a>。</p>
<h2 id="19-s"><a class="toclink" href="#19-s">19. S</a><a class="headerlink" href="#19-s" title="Permanent link">#</a></h2>
<h3 id="191-savedmodel"><a class="toclink" href="#191-savedmodel">19.1. SavedModel</a><a class="headerlink" href="#191-savedmodel" title="Permanent link">#</a></h3>
<p>保存和恢复 TensorFlow 模型时建议使用的格式。SavedModel 是一种独立于语言且可恢复的序列化格式，使较高级别的系统和工具可以创建、使用和转换 TensorFlow 模型。</p>
<p>如需完整的详细信息，请参阅《TensorFlow 编程人员指南》中的<a href="https://tensorflow.google.cn/programmers_guide/saved_model?hl=zh-CN">保存和恢复</a>。</p>
<h3 id="192-saver"><a class="toclink" href="#192-saver">19.2. Saver</a><a class="headerlink" href="#192-saver" title="Permanent link">#</a></h3>
<p>一种 <a href="https://tensorflow.google.cn/api_docs/python/tf/train/Saver?hl=zh-CN">TensorFlow 对象</a>，负责保存模型检查点。</p>
<h3 id="193-scaling"><a class="toclink" href="#193-scaling">19.3. 缩放 (scaling)</a><a class="headerlink" href="#193-scaling" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature_engineering">特征工程</a>中的一种常用做法，是指对某个特征的值区间进行调整，使之与数据集中其他特征的值区间一致。例如，假设您希望数据集中所有浮点特征的值都位于 0 到 1 区间内，如果某个特征的值位于 0 到 500 区间内，您就可以通过将每个值除以 500 来缩放该特征。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#normalization">标准化</a>。</p>
<h3 id="194-scikit-learn"><a class="toclink" href="#194-scikit-learn">19.4. scikit-learn</a><a class="headerlink" href="#194-scikit-learn" title="Permanent link">#</a></h3>
<p>一个热门的开放源代码机器学习平台。请访问 <a href="http://www.scikit-learn.org/">www.scikit-learn.org</a>。</p>
<h3 id="195-semi-supervised-learning"><a class="toclink" href="#195-semi-supervised-learning">19.5. 半监督式学习 (semi-supervised learning)</a><a class="headerlink" href="#195-semi-supervised-learning" title="Permanent link">#</a></h3>
<p>训练模型时采用的数据中，某些训练样本有标签，而其他样本则没有标签。半监督式学习采用的一种技术是推断无标签样本的标签，然后使用推断出的标签进行训练，以创建新模型。如果获得有标签样本需要高昂的成本，而无标签样本则有很多，那么半监督式学习将非常有用。</p>
<h3 id="196-sequence-model"><a class="toclink" href="#196-sequence-model">19.6. 序列模型 (sequence model)</a><a class="headerlink" href="#196-sequence-model" title="Permanent link">#</a></h3>
<p>一种模型，其输入具有序列依赖性。例如，根据之前观看过的一系列视频对观看的下一个视频进行预测。</p>
<h3 id="197-tfsession"><a class="toclink" href="#197-tfsession">19.7. 会话 (tf.session)</a><a class="headerlink" href="#197-tfsession" title="Permanent link">#</a></h3>
<p>封装了 TensorFlow 运行时状态的对象，用于运行全部或部分<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#graph">图</a>。在使用底层 TensorFlow API 时，您可以直接创建并管理一个或多个 <code>tf.session</code> 对象。在使用 Estimator API 时，Estimator 会为您创建会话对象。</p>
<h3 id="198-s-sigmoid-function"><a class="toclink" href="#198-s-sigmoid-function">19.8. S 型函数 (sigmoid function)</a><a class="headerlink" href="#198-s-sigmoid-function" title="Permanent link">#</a></h3>
<p>一种函数，可将逻辑回归输出或多项回归输出（对数几率）映射到概率，以返回介于 0 到 1 之间的值。S 型函数的公式如下：</p>
<p>
<script type="math/tex; mode=display">
y = \frac{1}{1 + e^{-\sigma}}
</script>
</p>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#logistic_regression">逻辑回归</a>问题中， 非常简单：</p>
<p>
<script type="math/tex; mode=display">
\sigma = b + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
</script>
</p>
<p>换句话说，S 型函数可将 <script type="math/tex">\sigma</script> 转换为介于 0 到 1 之间的概率。</p>
<p>在某些<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>中，S 型函数可作为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#activation_function">激活函数</a>使用。</p>
<h3 id="199-size-invariance"><a class="toclink" href="#199-size-invariance">19.9. 大小不变性 (size invariance)</a><a class="headerlink" href="#199-size-invariance" title="Permanent link">#</a></h3>
<p>在图像分类问题中，即使图像的大小发生变化，算法也能成功地对图像进行分类。例如，无论一只猫以 200 万像素还是 20 万像素呈现，该算法仍然可以识别它。请注意，即使是最好的图像分类算法，在大小不变性方面仍然会存在切实的限制。例如，对于仅以 20 像素呈现的猫图像，算法（或人）不可能正确对其进行分类。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#translational_invariance">平移不变性</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#rotational_invariance">旋转不变性</a>。</p>
<h3 id="1910-softmax"><a class="toclink" href="#1910-softmax">19.10. softmax</a><a class="headerlink" href="#1910-softmax" title="Permanent link">#</a></h3>
<p>一种函数，可提供<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#multi-class">多类别分类模型</a>中每个可能类别的概率。这些概率的总和正好为 1.0。例如，softmax 可能会得出某个图像是狗、猫和马的概率分别是 0.9、0.08 和 0.02。（也称为完整 softmax。）</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#candidate_sampling">候选采样</a>相对。</p>
<h3 id="1911-sparse-feature"><a class="toclink" href="#1911-sparse-feature">19.11. 稀疏特征 (sparse feature)</a><a class="headerlink" href="#1911-sparse-feature" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>向量，其中的大多数值都为 0 或为空。例如，某个向量包含一个为 1 的值和一百万个为 0 的值，则该向量就属于稀疏向量。再举一个例子，搜索查询中的单词也可能属于稀疏特征 - 在某种指定语言中有很多可能的单词，但在某个指定的查询中仅包含其中几个。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#dense_feature">密集特征</a>相对。</p>
<h3 id="1912-sparse-representation"><a class="toclink" href="#1912-sparse-representation">19.12. 稀疏表示法 (sparse representation)</a><a class="headerlink" href="#1912-sparse-representation" title="Permanent link">#</a></h3>
<p>一种张量<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#representation">表示法</a>，仅存储非零元素。</p>
<p>例如，英语中包含约一百万个单词。表示一个英语句子中所用单词的数量，考虑以下两种方式：</p>
<ul>
<li>要采用密集表示法来表示此句子，则必须为所有一百万个单元格设置一个整数，然后在大部分单元格中放入 0，在少数单元格中放入一个非常小的整数。</li>
<li>要采用稀疏表示法来表示此句子，则仅存储象征句子中实际存在的单词的单元格。因此，如果句子只包含 20 个独一无二的单词，那么该句子的稀疏表示法将仅在 20 个单元格中存储一个整数。</li>
</ul>
<p>例如，假设以两种方式来表示句子"Dogs wag tails."。如下表所示，密集表示法将使用约一百万个单元格；稀疏表示法则只使用 3 个单元格：</p>
<p>
<script type="math/tex; mode=display">
\text{密集表示法}
</script>
</p>
<table>
<thead>
<tr>
<th>单元格编号</th>
<th>单词</th>
<th>出现次数</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>a</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>aardvark</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>aargh</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>aarti</td>
<td>0</td>
</tr>
<tr>
<td>... 出现次数为 0 的另外 140391 个单词</td>
<td></td>
<td></td>
</tr>
<tr>
<td>140395</td>
<td>dogs</td>
<td>1</td>
</tr>
<tr>
<td>... 出现次数为 0 的 633062 个单词</td>
<td></td>
<td></td>
</tr>
<tr>
<td>773458</td>
<td>tails</td>
<td>1</td>
</tr>
<tr>
<td>... 出现次数为 0 的 189136 个单词</td>
<td></td>
<td></td>
</tr>
<tr>
<td>962594</td>
<td>wag</td>
<td>1</td>
</tr>
<tr>
<td>... 出现次数为 0 的很多其他单词</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>
<script type="math/tex; mode=display">
\text{稀疏表示法}
</script>
</p>
<table>
<thead>
<tr>
<th>单元格编号</th>
<th>单词</th>
<th>出现次数</th>
</tr>
</thead>
<tbody>
<tr>
<td>140395</td>
<td>dogs</td>
<td>1</td>
</tr>
<tr>
<td>773458</td>
<td>tails</td>
<td>1</td>
</tr>
<tr>
<td>962594</td>
<td>wag</td>
<td>1</td>
</tr>
</tbody>
</table>
<h3 id="1913-sparsity"><a class="toclink" href="#1913-sparsity">19.13. 稀疏性 (sparsity)</a><a class="headerlink" href="#1913-sparsity" title="Permanent link">#</a></h3>
<p>向量或矩阵中设置为 0（或空）的元素数除以该向量或矩阵中的条目总数。以一个 10x10 矩阵（其中 98 个单元格都包含 0）为例。稀疏性的计算方法如下：</p>
<p>
<script type="math/tex; mode=display">
\text{稀疏性} = \frac{98}{100} = 0.98
</script>
</p>
<p>特征稀疏性是指特征向量的稀疏性；模型稀疏性是指模型权重的稀疏性。</p>
<h3 id="1914-spatial-pooling"><a class="toclink" href="#1914-spatial-pooling">19.14. 空间池化 (spatial pooling)</a><a class="headerlink" href="#1914-spatial-pooling" title="Permanent link">#</a></h3>
<p>请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#pooling">池化</a>。</p>
<h3 id="1915-squared-hinge-loss"><a class="toclink" href="#1915-squared-hinge-loss">19.15. 平方合页损失函数 (squared hinge loss)</a><a class="headerlink" href="#1915-squared-hinge-loss" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hinge-loss">合页损失函数</a>的平方。与常规合页损失函数相比，平方合页损失函数对离群值的惩罚更严厉。</p>
<h3 id="1916-squared-loss"><a class="toclink" href="#1916-squared-loss">19.16. 平方损失函数 (squared loss)</a><a class="headerlink" href="#1916-squared-loss" title="Permanent link">#</a></h3>
<p>在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#linear_regression">线性回归</a>中使用的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#loss">损失</a>函数（也称为 <script type="math/tex">L_2</script> 损失函数）。该函数可计算模型为有标签<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#example">样本</a>预测的值和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的实际值之差的平方。由于取平方值，因此该损失函数会放大不佳预测的影响。也就是说，与 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#L1_loss"><script type="math/tex">L_1</script> 损失函数</a>相比，平方损失函数对离群值的反应更强烈。</p>
<h3 id="1917-static-model"><a class="toclink" href="#1917-static-model">19.17. 静态模型 (static model)</a><a class="headerlink" href="#1917-static-model" title="Permanent link">#</a></h3>
<p>离线训练的一种模型。</p>
<h3 id="1918-stationarity"><a class="toclink" href="#1918-stationarity">19.18. 平稳性 (stationarity)</a><a class="headerlink" href="#1918-stationarity" title="Permanent link">#</a></h3>
<p>数据集中数据的一种属性，表示数据分布在一个或多个维度保持不变。这种维度最常见的是时间，即表明平稳性的数据不随时间而变化。例如，从 9 月到 12 月，表明平稳性的数据没有发生变化。</p>
<h3 id="1919-step"><a class="toclink" href="#1919-step">19.19. 步 (step)</a><a class="headerlink" href="#1919-step" title="Permanent link">#</a></h3>
<p>对一个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#batch">批次</a>的向前和向后评估。</p>
<h3 id="1920-step-size"><a class="toclink" href="#1920-step-size">19.20. 步长 (step size)</a><a class="headerlink" href="#1920-step-size" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#learning_rate">学习速率</a>的含义相同。</p>
<h3 id="1921-sgd-stochastic-gradient-descent"><a class="toclink" href="#1921-sgd-stochastic-gradient-descent">19.21. 随机梯度下降法 (SGD, stochastic gradient descent)</a><a class="headerlink" href="#1921-sgd-stochastic-gradient-descent" title="Permanent link">#</a></h3>
<p>批次大小为 1 的一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#gradient_descent">梯度下降法</a>。换句话说，SGD 依赖于从数据集中随机均匀选择的单个样本来计算每步的梯度估算值。</p>
<h3 id="1922-srm-structural-risk-minimization"><a class="toclink" href="#1922-srm-structural-risk-minimization">19.22. 结构风险最小化 (SRM, structural risk minimization)</a><a class="headerlink" href="#1922-srm-structural-risk-minimization" title="Permanent link">#</a></h3>
<p>一种算法，用于平衡以下两个目标：</p>
<ul>
<li>期望构建最具预测性的模型（例如损失最低）。</li>
<li>期望使模型尽可能简单（例如强大的正则化）。</li>
</ul>
<p>例如，旨在将基于训练集的损失和正则化降至最低的函数就是一种结构风险最小化算法。</p>
<p>如需更多信息，请参阅 <a href="http://www.svms.org/srm/">http://www.svms.org/srm/</a>。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#ERM">经验风险最小化</a>相对。</p>
<h3 id="1923-stride"><a class="toclink" href="#1923-stride">19.23. 步长 (stride)</a><a class="headerlink" href="#1923-stride" title="Permanent link">#</a></h3>
<p>在卷积运算或池化中，下一个系列的输入切片的每个维度中的增量。例如，下面的动画演示了卷积运算过程中的一个 (1,1) 步长。因此，下一个输入切片是从上一个输入切片向右移动一个步长的位置开始。当运算到达右侧边缘时，下一个切片将回到最左边，但是下移一个位置。</p>
<p><img alt="步长" src="https://developers.google.cn/machine-learning/glossary/images/AnimatedConvolution.gif?hl=zh-CN" /></p>
<p>前面的示例演示了一个二维步长。如果输入矩阵为三维，那么步长也将是三维。</p>
<h3 id="1924-subsampling"><a class="toclink" href="#1924-subsampling">19.24. 下采样 (subsampling)</a><a class="headerlink" href="#1924-subsampling" title="Permanent link">#</a></h3>
<p>请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#pooling">池化</a>。</p>
<h3 id="1925-summary"><a class="toclink" href="#1925-summary">19.25. 总结 (summary)</a><a class="headerlink" href="#1925-summary" title="Permanent link">#</a></h3>
<p>在 TensorFlow 中的某一<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#step">步</a>计算出的一个值或一组值，通常用于在训练期间跟踪模型指标。</p>
<h3 id="1926-supervised-machine-learning"><a class="toclink" href="#1926-supervised-machine-learning">19.26. 监督式机器学习 (supervised machine learning)</a><a class="headerlink" href="#1926-supervised-machine-learning" title="Permanent link">#</a></h3>
<p>根据输入数据及其对应的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>来训练<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>。监督式机器学习类似于学生通过研究一系列问题及其对应的答案来学习某个主题。在掌握了问题和答案之间的对应关系后，学生便可以回答关于同一主题的新问题（以前从未见过的问题）。请与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#unsupervised_machine_learning">非监督式机器学习</a>进行比较。</p>
<h3 id="1927-synthetic-feature"><a class="toclink" href="#1927-synthetic-feature">19.27. 合成特征 (synthetic feature)</a><a class="headerlink" href="#1927-synthetic-feature" title="Permanent link">#</a></h3>
<p>一种<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>，不在输入特征之列，而是从一个或多个输入特征衍生而来。合成特征包括以下类型：</p>
<ul>
<li>对连续特征进行<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#bucketing">分桶</a>，以分为多个区间分箱。</li>
<li>将一个特征值与其他特征值或其本身相乘（或相除）。</li>
<li>创建一个<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature_cross">特征组合</a>。</li>
</ul>
<p>仅通过<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#normalization">标准化</a>或<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#scaling">缩放</a>创建的特征不属于合成特征。</p>
<h2 id="20-t"><a class="toclink" href="#20-t">20. T</a><a class="headerlink" href="#20-t" title="Permanent link">#</a></h2>
<h3 id="201-target"><a class="toclink" href="#201-target">20.1. 目标 (target)</a><a class="headerlink" href="#201-target" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的含义相同。</p>
<h3 id="202-temporal-data"><a class="toclink" href="#202-temporal-data">20.2. 时态数据 (temporal data)</a><a class="headerlink" href="#202-temporal-data" title="Permanent link">#</a></h3>
<p>在不同时间点记录的数据。例如，记录的一年中每一天的冬外套销量就属于时态数据。</p>
<h3 id="203-tensor"><a class="toclink" href="#203-tensor">20.3. 张量 (Tensor)</a><a class="headerlink" href="#203-tensor" title="Permanent link">#</a></h3>
<p>TensorFlow 程序中的主要数据结构。张量是 N 维（其中 N 可能非常大）数据结构，最常见的是标量、向量或矩阵。张量的元素可以包含整数值、浮点值或字符串值。</p>
<h3 id="204-tpu-tensor-processing-unit"><a class="toclink" href="#204-tpu-tensor-processing-unit">20.4. 张量处理单元 (TPU, Tensor Processing Unit)</a><a class="headerlink" href="#204-tpu-tensor-processing-unit" title="Permanent link">#</a></h3>
<p>一种 ASIC（应用专用集成电路），用于优化 TensorFlow 程序的性能。</p>
<h3 id="205-tensor-rank"><a class="toclink" href="#205-tensor-rank">20.5. 张量等级 (Tensor rank)</a><a class="headerlink" href="#205-tensor-rank" title="Permanent link">#</a></h3>
<p>请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#rank">等级</a>。</p>
<h3 id="206-tensor-shape"><a class="toclink" href="#206-tensor-shape">20.6. 张量形状 (Tensor shape)</a><a class="headerlink" href="#206-tensor-shape" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tensor">张量</a>在各种维度中包含的元素数。例如，张量 [5, 10] 在一个维度中的形状为 5，在另一个维度中的形状为 10。</p>
<h3 id="207-tensor-size"><a class="toclink" href="#207-tensor-size">20.7. 张量大小 (Tensor size)</a><a class="headerlink" href="#207-tensor-size" title="Permanent link">#</a></h3>
<p><a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#tensor">张量</a>包含的标量总数。例如，张量 [5, 10] 的大小为 50。</p>
<h3 id="208-tensorboard"><a class="toclink" href="#208-tensorboard">20.8. TensorBoard</a><a class="headerlink" href="#208-tensorboard" title="Permanent link">#</a></h3>
<p>一个信息中心，用于显示在执行一个或多个 TensorFlow 程序期间保存的摘要信息。</p>
<h3 id="209-tensorflow"><a class="toclink" href="#209-tensorflow">20.9. TensorFlow</a><a class="headerlink" href="#209-tensorflow" title="Permanent link">#</a></h3>
<p>一个大型的分布式机器学习平台。该术语还指 TensorFlow 堆栈中的基本 API 层，该层支持对数据流图进行一般计算。</p>
<p>虽然 TensorFlow 主要应用于机器学习领域，但也可用于需要使用数据流图进行数值计算的非机器学习任务。</p>
<h3 id="2010-tensorflow-playground"><a class="toclink" href="#2010-tensorflow-playground">20.10. TensorFlow Playground</a><a class="headerlink" href="#2010-tensorflow-playground" title="Permanent link">#</a></h3>
<p>一款用于直观呈现不同的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hyperparameters">超参数</a>对模型（主要是神经网络）训练的影响的程序。要试用 TensorFlow Playground，请前往 <a href="http://playground.tensorflow.org/?hl=zh-CN">http://playground.tensorflow.org</a>。</p>
<h3 id="2011-tensorflow-serving"><a class="toclink" href="#2011-tensorflow-serving">20.11. TensorFlow Serving</a><a class="headerlink" href="#2011-tensorflow-serving" title="Permanent link">#</a></h3>
<p>一个平台，用于将训练过的模型部署到生产环境。</p>
<h3 id="2012-test-set"><a class="toclink" href="#2012-test-set">20.12. 测试集 (test set)</a><a class="headerlink" href="#2012-test-set" title="Permanent link">#</a></h3>
<p>数据集的子集，用于在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>经由验证集的初步验证之后测试模型。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#training_set">训练集</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#validation_set">验证集</a>相对。</p>
<h3 id="2013-tfexample"><a class="toclink" href="#2013-tfexample">20.13. tf.Example</a><a class="headerlink" href="#2013-tfexample" title="Permanent link">#</a></h3>
<p>一种标准<a href="https://developers.google.cn/protocol-buffers/?hl=zh-CN">协议缓冲区</a>，旨在描述用于机器学习模型训练或推断的输入数据。</p>
<h3 id="2014-time-series-analysis"><a class="toclink" href="#2014-time-series-analysis">20.14. 时间序列分析 (time series analysis)</a><a class="headerlink" href="#2014-time-series-analysis" title="Permanent link">#</a></h3>
<p>机器学习和统计学的一个子领域，旨在分析<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#temporal_data">时态数据</a>。很多类型的机器学习问题都需要时间序列分析，其中包括分类、聚类、预测和异常检测。例如，您可以利用时间序列分析根据历史销量数据预测未来每月的冬外套销量。</p>
<h3 id="2015-training"><a class="toclink" href="#2015-training">20.15. 训练 (training)</a><a class="headerlink" href="#2015-training" title="Permanent link">#</a></h3>
<p>确定构成模型的理想<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#parameter">参数</a>的过程。</p>
<h3 id="2016-training-set"><a class="toclink" href="#2016-training-set">20.16. 训练集 (training set)</a><a class="headerlink" href="#2016-training-set" title="Permanent link">#</a></h3>
<p>数据集的子集，用于训练模型。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#validation_set">验证集</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#test_set">测试集</a>相对。</p>
<h3 id="2017-transfer-learning"><a class="toclink" href="#2017-transfer-learning">20.17. 迁移学习 (transfer learning)</a><a class="headerlink" href="#2017-transfer-learning" title="Permanent link">#</a></h3>
<p>将信息从一个机器学习任务迁移到另一个机器学习任务。例如，在多任务学习中，一个模型可以完成多项任务，例如针对不同任务具有不同输出节点的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#deep_model">深度模型</a>。迁移学习可能涉及将知识从较简单任务的解决方案迁移到较复杂的任务，或者将知识从数据较多的任务迁移到数据较少的任务。</p>
<p>大多数机器学习系统都只能完成一项任务。迁移学习是迈向人工智能的一小步；在人工智能中，单个程序可以完成多项任务。</p>
<h3 id="2018-translational-invariance"><a class="toclink" href="#2018-translational-invariance">20.18. 平移不变性 (translational invariance)</a><a class="headerlink" href="#2018-translational-invariance" title="Permanent link">#</a></h3>
<p>在图像分类问题中，即使图像中对象的位置发生变化，算法也能成功对图像进行分类。例如，无论一只狗位于画面正中央还是画面左侧，该算法仍然可以识别它。</p>
<p>另请参阅<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#size_invariance">大小不变性</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#rotational_invariance">旋转不变性</a>。</p>
<h3 id="2019-tn-true-negative"><a class="toclink" href="#2019-tn-true-negative">20.19. 负例 (TN, true negative)</a><a class="headerlink" href="#2019-tn-true-negative" title="Permanent link">#</a></h3>
<p>被模型正确地预测为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#negative_class">负类别</a>的样本。例如，模型推断出某封电子邮件不是垃圾邮件，而该电子邮件确实不是垃圾邮件。</p>
<h3 id="2020-tp-true-positive"><a class="toclink" href="#2020-tp-true-positive">20.20. 正例 (TP, true positive)</a><a class="headerlink" href="#2020-tp-true-positive" title="Permanent link">#</a></h3>
<p>被模型正确地预测为<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#positive_class">正类别</a>的样本。例如，模型推断出某封电子邮件是垃圾邮件，而该电子邮件确实是垃圾邮件。</p>
<h3 id="2021-true-positive-rate-tp"><a class="toclink" href="#2021-true-positive-rate-tp">20.21. 正例率（true positive rate, 简称 TP 率）</a><a class="headerlink" href="#2021-true-positive-rate-tp" title="Permanent link">#</a></h3>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#recall">召回率</a>的含义相同，即：</p>
<p>
<script type="math/tex; mode=display">
\text{正例率} = \frac{正例数}{正例数 + 假负例数}
</script>
</p>
<p>正例率是 <a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#ROC">ROC 曲线</a>的 y 轴。</p>
<h2 id="21-u"><a class="toclink" href="#21-u">21. U</a><a class="headerlink" href="#21-u" title="Permanent link">#</a></h2>
<h3 id="211-unlabeled-example"><a class="toclink" href="#211-unlabeled-example">21.1. 无标签样本 (unlabeled example)</a><a class="headerlink" href="#211-unlabeled-example" title="Permanent link">#</a></h3>
<p>包含<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>但没有<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#label">标签</a>的样本。无标签样本是用于进行<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#inference">推断</a>的输入内容。在<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#semi-supervised_learning">半监督式</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#unsupervised_machine_learning">非监督式</a>学习中，在训练期间会使用无标签样本。</p>
<h3 id="212-unsupervised-machine-learning"><a class="toclink" href="#212-unsupervised-machine-learning">21.2. 非监督式机器学习 (unsupervised machine learning)</a><a class="headerlink" href="#212-unsupervised-machine-learning" title="Permanent link">#</a></h3>
<p>训练<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#model">模型</a>，以找出数据集（通常是无标签数据集）中的规律。</p>
<p>非监督式机器学习最常见的用途是将数据分为不同的聚类，使相似的样本位于同一组中。例如，非监督式机器学习算法可以根据音乐的各种属性将歌曲分为不同的聚类。所得聚类可以作为其他机器学习算法（例如音乐推荐服务）的输入。在很难获取真标签的领域，聚类可能会非常有用。例如，在反滥用和反欺诈等领域，聚类有助于人们更好地了解相关数据。</p>
<p>非监督式机器学习的另一个例子是<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">主成分分析 (PCA)</a>。例如，通过对包含数百万购物车中物品的数据集进行主成分分析，可能会发现有柠檬的购物车中往往也有抗酸药。</p>
<p>请与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#supervised_machine_learning">监督式机器学习</a>进行比较。</p>
<h2 id="22-v"><a class="toclink" href="#22-v">22. V</a><a class="headerlink" href="#22-v" title="Permanent link">#</a></h2>
<h3 id="221-validation-set"><a class="toclink" href="#221-validation-set">22.1. 验证集 (validation set)</a><a class="headerlink" href="#221-validation-set" title="Permanent link">#</a></h3>
<p>数据集的一个子集，从训练集分离而来，用于调整<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hyperparameter">超参数</a>。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#training_set">训练集</a>和<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#test_set">测试集</a>相对。</p>
<h2 id="23-w"><a class="toclink" href="#23-w">23. W</a><a class="headerlink" href="#23-w" title="Permanent link">#</a></h2>
<h3 id="231-weight"><a class="toclink" href="#231-weight">23.1. 权重 (weight)</a><a class="headerlink" href="#231-weight" title="Permanent link">#</a></h3>
<p>线性模型中<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature">特征</a>的系数，或深度网络中的边。训练线性模型的目标是确定每个特征的理想权重。如果权重为 0，则相应的特征对模型来说没有任何贡献。</p>
<h3 id="232-wide-model"><a class="toclink" href="#232-wide-model">23.2. 宽度模型 (wide model)</a><a class="headerlink" href="#232-wide-model" title="Permanent link">#</a></h3>
<p>一种线性模型，通常有很多<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#sparse_features">稀疏输入特征</a>。我们之所以称之为"宽度模型"，是因为这是一种特殊类型的<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#neural_network">神经网络</a>，其大量输入均直接与输出节点相连。与深度模型相比，宽度模型通常更易于调试和检查。虽然宽度模型无法通过<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#hidden_layer">隐藏层</a>来表示非线性关系，但可以利用<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#feature_cross">特征组合</a>、<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#bucketing">分桶</a>等转换以不同的方式为非线性关系建模。</p>
<p>与<a href="https://developers.google.cn/machine-learning/glossary/?hl=zh-CN#deep_model">深度模型</a>相对。</p>
<hr />
<p>联系邮箱：curren_wong@163.com</p>
<p>CSDN：<a href="https://me.csdn.net/qq_41729780">https://me.csdn.net/qq_41729780</a></p>
<p>知乎：<a href="https://zhuanlan.zhihu.com/c_1225417532351741952">https://zhuanlan.zhihu.com/c_1225417532351741952</a></p>
<p>公众号：复杂网络与机器学习</p>
<p>欢迎关注/转载，有问题欢迎通过邮箱交流。</p>
<p><img alt="二维码" src="../../../img/WeChat/QRCode.jpg" />
11
111</p>
<p>1</p>
<p>1
1asdaskhasdklja</p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../2.XGBoost%E7%9A%84%E7%BA%AFPython%E5%AE%9E%E7%8E%B0/" title="2.XGBoost的纯Python实现" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                2.XGBoost的纯Python实现
              </span>
            </div>
          </a>
        
        
          <a href="../../%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/%E5%85%B6%E4%BB%96/1.%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA/" title="1.输入输出" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                1.输入输出
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org" target="_blank" rel="noopener">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.c33a9706.js"></script>
      
      <script>app.initialize({version:"1.1",url:{base:"../../.."}})</script>
      
        <script src="../../../js/katex.min.js"></script>
      
        <script src="../../../js/mathtex-script-type.min.js"></script>
      
        <script src="../../../js/copy-tex.min.js"></script>
      
        <script src="../../../js/auto-render.min.js"></script>
      
        <script src="../../../js/jquery-3.4.1.min.js"></script>
      
        <script src="../../../js/d3.min.js"></script>
      
        <script src="../../../js/d3-flextree.js"></script>
      
        <script src="../../../js/view.mindmap.js"></script>
      
        <script src="../../../js/emoji.min.js"></script>
      
        <script src="../../../js/mermaid.min.js"></script>
      
        <script src="../../../js/highlight.pack.js"></script>
      
        <script src="https://cdn1.lncld.net/static/js/av-min-1.5.0.js"></script>
      
        <script src="https://jerryz.sgp1.cdn.digitaloceanspaces.com/lib/hit-kounter/hit-kounter-lc-0.3.0.js"></script>
      
        <script src="../../../js/readingtime.js"></script>
      
        <script src="../../../js/extra.js"></script>
      
    
  </body>
</html>